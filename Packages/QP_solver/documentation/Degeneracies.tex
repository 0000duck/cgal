\documentclass[a4paper]{article}
\usepackage{html}
\usepackage[dvips]{graphics,color,epsfig}
\usepackage{path}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{algpseudocode}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\F}{\ensuremath{\mathbb{F}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\Q}{\ensuremath{\mathbb{Q}}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}

\newcommand{\MBI}[1]{\ensuremath{M_{#1}^{-1}}}
\newcommand{\RMBI}[1]{\ensuremath{\check{M}_{#1}^{-1}}}

\newcommand{\pmu}[2]{\ensuremath{p_{\mu_{j}}^{(#1)}(\varepsilon, #2)}}
\newcommand{\px}[3]{\ensuremath{p_{x_{#1}}^{(#2)}(\varepsilon, #3)}}

\newtheorem{lemma}{Lemma}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}



\title{Degeneracy}
\author{}
%
\begin{document}
\maketitle
\section{Row rank and column rank assumption}
The QP-solver so far assumes nondegeneracy of the quadratic program to
solve~\cite{Sven}, page 19. For ease of reference we will restate the
nondegeneracy assumptions, that is given the QP,
%\begin{equation}
\begin{eqnarray}
\label{def:QP}
(QP)\quad minimize&  c^{T}x + x^{T} D x      	&  \nonumber \\
s.t.	 & \sum_{j=1}^{n}a_{ij}x_{j} = b_{i}	& i \in E  \nonumber \\
	 & \sum_{j=1}^{n}a_{ij}x_{j} \leq b_{i} & i \in I^{\leq} \\
	 & \sum_{j=1}^{n}a_{ij}x_{j} \geq b_{i} & i \in I^{\geq}  \nonumber \\
 	 & x_{j} \geq 0				& j \in \{1 \ldots n \}
	 \nonumber
\end{eqnarray}
%\end{equation}
where $I:= I^{\leq} \cup I^{\geq}$ and
$\left| E \right| + \left| I \right| = m$,
the following conditions
\begin{assumption} \label{ass:nondegeneracy}
Nondegeneracy

\begin{enumerate}
\item $Rank\left( A \right) = m$
\item The subsystem $A_{G}x_{G} = b$ has only solutions for sets $G \subseteq
\left[ n \right]$ with $\left|G \right| \geq m$.
\end{enumerate}
\end{assumption}
must be met. In the following we will show how these
assumptions can be dropped. To this end we will first describe how the auxiliary
problem is set up. 
\section{The auxiliary problem}
The auxiliary problem is constructed by augmenting the constraint matrix $A$
with columns corresponding to slack and artificial variables. The slack columns
are added in the standard way. For each of the equality constraints 
$\sum_{j=1}^{n} {a_{i j}x_{j}} = b_{i}, i \in E$ the original matrix $A$
is augmented by an artificial column
\begin{equation} \label{def:art_col}
 \tilde{a} =  \left\{
	        \begin{array}{ll}
  		  -e_{i} & \mbox{if $b_{i} < 0$} \\
		   e_{i}  & \mbox{otherwise,}
	        \end{array}
 	       \right.
\end{equation}
where $e_{i}$ denotes the $i$-th column of the identity matrix.
If the set of inequality constraints with infeasible origin
$I_{inf}:=\{i \in I^{\leq} \left| \right. b_{i} < 0 \} \cup 
  \{i \in I^{\geq} \left| \right. b_{i} > 0 \}$
 is nonempty the original matrix $A$
is augmented by a special artificial column $\tilde{a}^{s}$, defined as 
\begin{equation}\label{def:spec_art_col}
  \tilde{a}^{s}_{i} =  \left\{
	                 \begin{array}{ll}
  		           -1 & \mbox{if $i \in I^{\leq}, b_{i} < 0$} \\
		            1 & \mbox{if $i \in I^{\geq}, b_{i} > 0$} \\
		            0 & \mbox{otherwise}
	                 \end{array}
 	               \right.
\end{equation}
If we denote by $O$ the index set of original variables, by $S$ the index set
of slack variables, by $art$ the index set of artificial variables and by
$\tilde{A}$ the original constraint matrix $A$ augmented in the above way
the auxiliary problem may be expressed as
\begin{eqnarray*}
 \mbox{minimize} &  \tilde{c}^{T}x      & 	  \\
	s.t.	 & \tilde{A}x = b_{i}	& i \in \{1 \ldots m \}      \\
		 & x_{j} \geq 0	  	& j \in O \cup S \cup art  
\end{eqnarray*}
where
\begin{equation} \label{def:aux_c}
 \tilde{c}_{j} =  \left\{
	            \begin{array}{ll}
  		      0      & \mbox{if $j \in O \cup S$} \\
		      > 0 & \mbox{if $j \in art$}
	            \end{array}
 	          \right.
\end{equation}
For later use we introduce the bijection $\sigma$ defined as
\begin{equation}
\sigma: S \cup art \setminus \{\tilde{a}^{s}\} \rightarrow I \cup E
\end{equation}
which maps the slack and artificial variables to their inequality and equality
constraints. 
\subsection{Initialization of the auxiliary problem}
Since only constraints which are satisfied with equality determine the values of
the basic variables with respect to a given basis only the equality constraints
as well as the currently active inequality constraints are
considered (see also ~\cite{Sven}, Section 2.4).
To this end the set of basic variables $B$ is partitioned into original and
slack variables, that is
$B=B_{O} \cup B_{S}$, where $B_O \subseteq O \cup art$,
and the set of inequality constraints $I$ is partitioned as
$I=S_{B} \cup S_{N}$, where $S_{B}:=\sigma(B_{S})$
and
$S_{N}:=\sigma(S \setminus B_{S})$, if $\sigma$ denotes the bijection
$S \rightarrow I$.
The set of active constraints
$C=E \cup S_{N}$ is
introduced, such that a `reduced' basis matrix $\check{A}_{B}$
with respect to $B$ is defined as
\begin{equation}
\label{def:red_basis_phaseI}
 \check{A}_{B}:=\tilde{A}_{C, B_{O}}
\end{equation}
Note that for degenerate bases active constraints do not neccessarily occur in
the index set $C$ only.
For later use, we introduce $A_{B}$ for the unreduced basis,
\begin{equation}
\label{def:basis_phaseI}
  A_{B}:= \tilde{A}_{C \cup S_{B}, B_{O} \cup B_{S}}
\end{equation}

Let $i_{0} \in I_{inf}$ be the index of a constraint that has a most infeasible
origin, that is 
\[
  \left| b_{i_{0}} \right| \geq  \left|b_{i}\right|, \quad i \in I_{inf}
\]
then $B_{O}$, $B_{S}$ are initialized
as
\begin{eqnarray}
  \label{def:B_O_init}
  B_{O}^{0} & := & art  \\
  \label{def:B_S_init}
  B_{S}^{0} & := & \sigma^{-1} \left( I \right)  \setminus
  \{ \sigma^{-1} \left( i_{0} \right) \}
\end{eqnarray}
and the initial set of basic and nonbasic constraints $S_{B}$ and $S_{N}$ as
\begin{eqnarray}
  \label{def:S_B_init}
  S_{B}^{0} & := & I \setminus \{ i_{0}  \} \\
  \label{def:S_N_init}
  S_{N}^{0} & := & \{ i_{0} \} 
\end{eqnarray}
\subsection{Expelling artificial variables from the Basis}
At the end of phase I some artificial variables may remain in the basis.
In that case, if the original problem is to be feasible, the basis has to be
degenerate.
Chv\'{a}tal~\cite{Chvatal}, Chapter 8, describes a procedure that,
given a system $Ax = b$ and an optimal
basis $B$, computes a subsystem $A'x = b'$ of constraints with $A'$ having full
row rank and a basis $B'$ such that the set of feasible solutions for both
systems is the same. The procedure tries to pivot the artificial variables out of
the basis, the constraints corresponding to the artificial variables that can
not be driven out of the basis in this manner can be removed without changing
the solution set of the system.

Since the proof for the equality of the solution sets of $Ax = b$ and
$A'x = b'$ only works if the special artificial variable can be pivoted out of
the basis we show first that this can always be achieved.

For the sake of notational convenience we assume here that the index set of the
artificial variables $art\setminus \{\tilde{a}^{s}\}$ is defined as
$art\setminus \{\tilde{a}^{s}\}=\{l+1 \ldots l+\left|E\right| \}$,
$l \geq n$ and that the basic artificial variable $x_{i}$ appears in the
basis heading $B_{O}$ at position $i-l$. 
\subsubsection{The special artificial variable}
Suppose the special artificial variable is the $k$-th entry in the basis
heading $B$. Then 
\[ 
  r = e_{k}^{T} \check{A}_{B}^{-1}
\]
denotes the corresponding row of the basis inverse and
the nonbasic variable $x_{j}$ can be pivoted into the basis
with the special artificial variable leaving iff 
\begin{equation} \label{eq:piv_precond}
e_{k}^{T}\check{A}_{B}^{-1}\tilde{A}_{C,j} \neq 0
\end{equation}
This can easily be verified by considering the corresponding eta matrix
whose $k$-th column is $\check{A}_{B}^{-1}\tilde{A}_{C,j}$ and whose determinant
is nonzero iff condition (\ref{eq:piv_precond}) holds.
Since $r \check{A}_{B} = e_{k}^{T}$, there exists by definition of 
the special artificial column $\tilde{a}^{s}$ and the fact that $B$ is a basis
at least one
$i \in I_{inf} \cap S_{N} \supset \emptyset$ such that
$r_{i} \neq 0$, which in turn implies that condition
(\ref{eq:piv_precond}) holds for some nonbasic
$j = \sigma^{-1} \left( i \right)$.

\subsubsection{Pivoting the artificial variables out of the basis}
The procedure described in~\cite{Chvatal} is outlined in
algorithm~(\ref{alg:expel_art_var}). We avoid iterating
over sets that change during the computation, we only use member tests on such
sets. The primitive $update(j,i)$
updates the reduced basis inverse $\check{A}_{B}^{-1}$ with the entering
variable $x_{j}$ and leaving variable $x_{i}$ and updates the basis heading
accordingly. The procedure claims that every solution of 
\begin{equation}
\sum_{j=1}^{n}a_{ij}x_{j}=b_{i} \quad i \in E
\end{equation}
is also a solution of
\begin{equation}
\sum_{j=1}^{n}a_{ij}x_{j}=b_{i} \quad i \in E \setminus J
\end{equation}
the proof of which we omit here.
\begin{algorithm}
\caption{Expel artificial variables from basis}
\label{alg:expel_art_var}
\begin{algorithmic}[0]
\ForAll{$i \in art$}
    \If{$i \in B_{O}$}
        \State $r \gets e_{i}^{T}\check{A}_{B}^{-1}$
        \ForAll{$j \in O \cup S$}
	    \If{$j \in N$}
	       \If{$r\tilde{A}_{C,j}\neq 0$}
		    \State $update(j,i)$
                \EndIf
	    \EndIf
        \EndFor
    \EndIf
\EndFor
\State $J \gets \sigma(B_{O} \cap art)$
\end{algorithmic}
\end{algorithm}
\subsubsection{Removing the remaining artificial variables and their
constraints}
\marginpar{art vars and their constr removed this way will never be eligible
again}
Since for the remaining basic artificial variables $x_{i}$,
$i \in B_{O} \cap art$
\begin{equation}
e_{i}^{T}\check{A}_{B}^{-1}\tilde{A}_{N} = 0 
\end{equation}
holds,
we may, according to the procedure described in~\cite{Chvatal}, remove
the artificial variable $x_{i}$ together with its constraint
$A_{\sigma(i), \bullet}$ without changing the set of feasible solutions.
This can be achieved by applying a slightly modified update
of type U8, defined in Section~6.3.2 in~\cite{Sven}. An $U8(j,i)$ update is a
LP-update and replaces an original variable $x_{i}$, $i \in B_{O}$ in the basis
by a slack variable $x_{j}$, $j \in S \setminus B_{S}$,
thus $S_{N}$ and $B_{O}$, or more generally, the sets
$C=E \cup S_{N}$ and $B_{O}$ each decrease by one element. Thus the reduced
basis matrix $\check{A}_{B}$ is shrunk by the
row $\left(\check{A}_{B}\right)_{\sigma(j), \bullet}$ and
the column $\left(\check{A}_{B}\right)_{\bullet, i}$. Provided the
update mechanism is general enough to handle variables $x_{j}$, $j \in art$ as
well instead of $x_{j}$, $j \in S \setminus B_{S}$ only, or equivalently,
the update mechanism is capable of
removing rows $\left(\check{A}_{B}\right)_{\sigma(j)}$ with $\sigma(j) \in E$
as well instead of $\sigma(j) \in S_{N}$ only, we can use the update $U8(i,i)$
for our purposes.
Of course the update of the basis headings needs appropriate modification
in this case, that is, $B_{O}^{\prime}:=B_{O} \setminus \{i\}$ and
$E^{\prime}:=E \setminus \{ \sigma(i)\}$, if $\check{A}_{B^{\prime}}$ denotes
the basis matrix after the update.

\subsubsection{Dropping the row rank assumption}
\marginpar{express in terms of precondition}
Due to performance reasons alluded to in the last subsection above the feature
of removing redundant equalities is provided only with the compile time tag
\texttt{Has\_no\_inequalities} set to true. So if the constraint matrix $A$ has
only equality constraints, $I=\emptyset$ in Definition~(\ref{def:QP}) and the
constraint matrix is suspected not to have full rank one can use the
compile time tag \texttt{Has\_no\_inequalities} set to true at the price of
some small performance penalty. If on the other hand the compile time tag is
set to false in this case the solver aborts in case $Rank(A)<m$.  

\section{The lexicographic method}
In order to being able to drop the second condition of
Assumption~(\ref{ass:nondegeneracy}) we use a variation of the lexicographic
method. Since the standard lexicographic method enlarges the feasible region
in the explicit constraints with respect to the original problem by perturbing
the right hand side, it is only applicable for inequality
constraints. Even if this obstacle can be overcome for equality constraints we
may still have artificial variables in the optimal basis of the auxiliary
problem, pivoting them out of the basis as described above may render the
perturbed problem infeasible, since the pivots here are no longer degenerate.

Instead of altering the explicit constraints we enlarge the feasible region by
perturbing the implicit constraints from $x_{j} \geq 0$ to $x_{j} \geq
-\varepsilon^{j}$ in Definition~(\ref{def:QP}) with $0 < \varepsilon < 1$, such
that the perturbed problem is defined as
\begin{eqnarray}
\label{def:QP_eps}
(QP_{\varepsilon})\quad minimize&  c^{T}x + x^{T} D x   & \nonumber \\
s.t.	 & \sum_{j=1}^{n}a_{ij}x_{j} = b_{i}	& i \in E \nonumber \\
	 & \sum_{j=1}^{n}a_{ij}x_{j} \leq b_{i} & i \in I^{\leq} \\
	 & \sum_{j=1}^{n}a_{ij}x_{j} \geq b_{i} & i \in I^{\geq} \nonumber \\
	 & x \geq \epsilon				& \nonumber  
\end{eqnarray}
if we define $\epsilon$ as
\begin{equation}
\label{def:epsilon}
\epsilon_{j}:= -\varepsilon^{j}, \quad j \in \{1 \dots n \}
\end{equation}
All the entities whose definitions differ for the perturbed and
unperturbed problem  will be denoted as functions of $\varepsilon$,
such that setting $\varepsilon =0$ will yield the corresponding definitions
for the unperturbed problem.
Values will be considered as polynomials in $\varepsilon$,
$p(\varepsilon)=\sum_{k=0}^{l}p_{k}\varepsilon^{k}$, and values are compared
lexicographically in ascending order of the exponents of $\varepsilon$. As
a consequence degenerate bases are no longer possible and therefore cycling is
avoided.   

As will be shown later this variant of the lexicographic method has the
additional
advantage that artificial variables,  in case the original problem is feasible,
will only remain in the optimal basis of the
auxiliary problem, if they can be
removed together with their constraint, thus
pivoting artificial variables out of the basis is never neccessary.
  
\subsection{The auxiliary problem for the lexicographic method}
The slack columns are added in the standard way.
Similar to Definition~\ref{def:art_col}, for each equality constraint the constraint
matrix $A$ is augmented by an artificial column
\[
 \tilde{a} =  \left\{
	        \begin{array}{ll}
  		  -e_{i} &
		    \mbox{if $l_{c}\left(
		      b_{i} + \sum_{j=1}^{n}a_{ij}\varepsilon^{j}\right)< 0$}\\
		   e_{i}  & \mbox{otherwise}
	        \end{array}
 	       \right.
\]
If the set of inequality constraints with infeasible origin
\[
  I_{Inf}:=\{i \in I^{\leq}\left|\right. l_{c}\left(b_{i} +
    \sum_{j=1}^{n}a_{ij}\varepsilon^{j}\right) < 0\} \cup
    \{i \in I^{\geq}\left|\right. l_{c}\left(b_{i} +
    \sum_{j=1}^{n}a_{ij}\varepsilon^{j}\right) > 0\}
\]
is nonempty, the original constraint matrix is likewise augmented by a special
artificial column $\tilde{a}_{i}^{s}$ defined as
\[
  \tilde{a}^{s}_{i} =  \left\{
	                 \begin{array}{ll}
  		           -1 & \mbox{if $i \in I^{\leq},
			    l_{c}\left(b_{i} +
			     \sum_{j=1}^{n}a_{ij}\varepsilon^{j}\right) < 0$}\\
		            1 & \mbox{if $i \in I^{\geq},
			    l_{c}\left(b_{i} +
			      \sum_{j=1}^{n}a_{ij}\varepsilon^{j}\right)> 0$}\\
		            0 & \mbox{otherwise}
	                 \end{array}
 	               \right.
\]
The auxiliary problem is then defined as
\begin{eqnarray}
\label{def:aux_prob}
 \mbox{minimize} &  \tilde{c}^{T}x(\varepsilon)   & 	  \nonumber \\
	s.t.	 & \tilde{A}x(\varepsilon) = b_{i} & i \in \{1 \ldots m \}   \\
		 & x_{j}(\varepsilon) \geq -\varepsilon^{j} &
		   j \in O \cup S \cup art \nonumber 
\end{eqnarray}
with $\tilde{c}$ defined as in Definition~\ref{def:aux_c} and the additional
requirement that 
\begin{equation}
\label{req:order_eps}
\max_{i \in O \cup S}i < \min_{i \in art}i
\end{equation} 
holds.
\subsection{Initialization of the auxiliary problem for the lexicographic
method}
The auxiliary problem is initialized as before, that is $B_{O}^{0}$ and
$B_{S}^{0}$ are defined as in Definitions~(\ref{def:B_O_init}),
(\ref{def:B_S_init}) and $S_{B}^{0}$ and $S_{N}^{0}$ are defined as in
Definitions~(\ref{def:S_B_init}),(\ref{def:S_N_init}), the only difference being
the fact that the most infeasible origin $i_{0} \in I_{Inf}$ defined as
\begin{equation*}
  \left|b_{i_{0}} + \sum_{j=1}^{n}a_{i_{0}j}\varepsilon^{j} \right|
    >
    \left|b_{i} + \sum_{j=1}^{n}a_{ij}\varepsilon^{j} \right|
    \quad i \in I_{inf},
\end{equation*}
is now unique.

\subsection{Resolving ties in phaseI}
\label{sec:Res_ties_phaseI}
\subsubsection{LP-case}
Let $B$ be the current basis and $j \in N$ be the entering variable
and define $\hat{N}:= N \setminus\{j\}$ and
$q:= A_{B}^{-1}\tilde{A}_{\bullet,j}$.
Let $i_{1}, i_{2} \in B$ be
involved in a tie in the unperturbed problem, that is
\begin{equation*}
  \min_{i \in B: q_{x_{i}} > 0}
  \frac{\left(A_{B}^{-1}b\right)_{x_{i}}}{q_{x_{i}}}
  =
  \frac{\left(A_{B}^{-1}b\right)_{x_{i_{1}}}}{q_{x_{i_{1}}}}
  =
  \frac{\left(A_{B}^{-1}b\right)_{x_{i_{2}}}}{q_{x_{i_{2}}}}
\end{equation*}
by Definition~(\ref{def:aux_prob}),  we then have to compare
polynomials in $\varepsilon$ of the following form in the perturbed problem
\begin{eqnarray}
\tilde{p}_{x_{i}}^{(L)}\left(\varepsilon, B\right) & := &
  \frac{\varepsilon^{i}
  - \left(A_{B}^{-1}\tilde{A}_{N}\right)_{x_{i}}
  \epsilon_{N}}{q_{x_{i}}} \nonumber \\
\label{def:p_x_i_tilde}
 & = &
  \frac{\varepsilon^{i}
  - \left(A_{B}^{-1}\tilde{A}_{\hat{N}}\right)_{x_{i}}
  \epsilon_{\hat{N}}}{q_{x_{i}}}
  + \varepsilon^{j}
\end{eqnarray}
Note, that always either $\tilde{p}_{x_{i_{1}}}^{(L)}
\left(\varepsilon, B\right) <
\tilde{p}_{x_{i_{2}}}^{(L)}\left(\varepsilon, B\right)$ or
$\tilde{p}_{x_{i_{1}}}^{(L)}\left(\varepsilon, B\right) >
\tilde{p}_{x_{i_{2}}}^{(L)}\left(\varepsilon, B\right)$, even if
$x_{i_{1}}(\varepsilon) = x_{i_{2}}(\varepsilon)$,
since the terms $\frac{\varepsilon^{i_{1}}}{q_{x_{i_{1}}}}$ and
$\frac{\varepsilon^{i_{2}}}{q_{x_{i_{1}}}}$ are unique to
$\tilde{p}_{x_{i_{1}}}^{(L)}\left(\varepsilon, B\right)$ and
$\tilde{p}_{x_{i_{2}}}^{(L)}\left(\varepsilon, B\right)$. 

\subsubsection{QP-case}
In preparation of phaseII the QP-case in phaseI uses the QP-machinery for $D=0$.
The basis $M_{B}$ in phaseI is, given the basis heading
$\left[C \cup S_{B}, B_{O} \cup B_{S} \right]$,
according to \cite{Sven} Section~2.3.1, Equation~2.5, defined as
\begin{equation}
\label{def:M_B_phaseI}
M_{B}
\left(\begin{array}{c}
        \lambda \\
	\hline
	x_{B}^{*}
      \end{array}
\right)
=
\left(\begin{array}{c}
        b \\
	\hline
	-c_{B}
       \end{array}
\right)
\quad
M_{B}:=
\left(\begin{array}{c|c}
        0 & A_{B} \\
	\hline
	A_{B}^{T} & 0 
       \end{array}
\right)
\end{equation}
such that $M_{B}^{-1}$ is defined as
\begin{equation}
\label{def:M_B_inv_phaseI}
M_{B}^{-1}:=
\left(\begin{array}{c|c}
        0 & {A_{B}^{-1}}^{T} \\
	\hline
	A_{B}^{-1} & 0
       \end{array}
\right)
\end{equation}
Assume $B$ to be the current basis and $j \in N$ the entering variable and
define $\hat{N}$ as above $q$ is according to \cite{Sven}, Section~2.3.2,
Equation~2.2 defined as
\begin{equation}
\label{def:q_phaseI}
q:= M_{B}^{-1}
\left(\begin{array}{c}
        \tilde{A}_{\bullet, j} \\
	\hline
        0
      \end{array}
\right)
=
\left(\begin{array}{c}
        0 \\
	\hline
	A_{B}^{-1}\tilde{A}_{\bullet, j}
       \end{array}
\right)
\end{equation}
Using $\tilde{c}_{B}=0$ in Definition~(\ref{def:M_B_phaseI})
we can express $i_{1}$, $i_{2}$ involved in a tie in the unperturbed problem
as
\begin{equation*}
\min_{i \in B: q_{x_{i}}>0}
\frac{
\left(M_{B}^{-1}
  \left(\begin{array}{c}
          b \\
	  \hline
	  0
        \end{array}
  \right)
\right)_{x_{i}}
}{q_{x_{i}}}
=
\frac{
\left(M_{B}^{-1}
  \left(\begin{array}{c}
          b \\
	  \hline
	  0
        \end{array}
  \right)
\right)_{x_{i_{1}}}
}{q_{x_{i_{1}}}}
=
\frac{
\left(M_{B}^{-1}
  \left(\begin{array}{c}
          b \\
	  \hline
	  0
        \end{array}
  \right)
\right)_{x_{i_{2}}}
}{q_{x_{i_{2}}}}
\end{equation*}
such that by Definition~(\ref{def:aux_prob}) we have to compare polynomials
in $\varepsilon$ of the following form in the perturbed problem
\begin{equation}
\label{def:p_x_i_tilde_Q_1}
\tilde{p}_{x_{i}}^{(Q)}\left(\varepsilon, B\right) :=
\frac{
 \varepsilon^{i}
 -\left(M_{B}^{-1}
   \left(\begin{array}{c}
           \tilde{A}_{N} \\
	   \hline
	    0
         \end{array}
   \right)
  \right)_{x_{i}}
 \epsilon_{N}
}{q_{x_{i}}}
\end{equation}
which is, using Definitions~(\ref{def:M_B_inv_phaseI}) and
(\ref{def:q_phaseI}) the same as
Definition~(\ref{def:p_x_i_tilde}),
but for some shift in the indexing function.

\subsubsection{The maximum number of coefficient comparisons needed for the tie
resolution in phaseI}
Note, that due to the uniqueness of the terms
$\frac{\varepsilon^{i}}{q_{x_{i}}}$ to
$p_{x_{i}}^{(L)}(\varepsilon, B)$ and
$p_{x_{i}}^{(Q)}(\varepsilon, B)$
we need at most compare coefficients of
powers of $\varepsilon$ with exponent up to
\begin{equation}
\label{def:u_T}
u_{T}(B):=\max_{i \in B_{T}} i
\end{equation}
if $B_{T} \subseteq B$ denotes the set of basic variables involved in a tie.
Therefore, the maximum number of coefficient comparisons needed is given by
\begin{equation}
r_{1}:=\left|\{1 \ldots u_{T}(B)\} \cap N\right|
\end{equation} 
 
\subsection{Transition to phaseII}
\subsubsection{Expelling artificial variables from the basis}
\marginpar{variable index issue: subsubsection not yet adapted}
Let $N_{0}:=N \cup \{0\}$ denote the set of nonbasic variables extended by zero
with $\tilde{A}_{\bullet, 0}:=b$. Define 
\begin{eqnarray*}
  l_{B}\left(i\right):=\min_{j \in Z_{i}} j & \text{where}&
  Z_{i}:=\{ j \in N_{0} \left| \right.
  \left(\tilde{A}_{B}^{-1}\tilde{A}_{\bullet,j}\right)_{i} \neq 0 \}
\end{eqnarray*}  
\begin{lemma}
Let $x_{B}(\varepsilon)$ be the optimal solution of the auxiliary problem and
$B \cap art \neq \emptyset$. Then for $i \in B \cap art$ either
$l_{B}\left(i\right) = 0$ or $l_{B}\left(i\right) > 0$,
$(\tilde{A}_{B}^{-1}\tilde{A}_{\bullet ,j})_{i} = 0$
for $j \in N \setminus art$.
\end{lemma}
\begin{proof}
We only consider $l_{B}\left(i\right) > 0$ for all $i \in B \cap art$, for
$l_{B}\left(i\right) = 0$ for some $i \in B \cap art$ implies infeasibility of
the unperturbed problem. 
Since $x_{B}(\varepsilon) = \tilde{A}_{B}^{-1}b - \tilde{A}_{B}^{-1}
\tilde{A}_{N}\epsilon_{N}$
and the implicit constraints are $x_{j}(\varepsilon) \geq -\varepsilon^{j}$
for variable $x_{j}(\varepsilon)$, feasibility requires
for some variable $i \in B \cap art$ either $l_{B}\left(i\right) < i$,
$(\tilde{A}_{B}^{-1}\tilde{A}_{\bullet, l_{B}\left(i\right)})_{i} >
0$ or
$l_{B}\left(i\right) > i$. Let
\begin{equation*}
  \ell:= \min_{i \in B \cap art} l_{B}\left(i\right),
\end{equation*}
if $\ell \in N \setminus art$,
then by definition of $\tilde{c}_{B}$ and $\ell$,
$\tilde{c}_{B}\tilde{A}_{B}^{-1}\tilde{A}_{\bullet, \ell} > 0$,
in contradiction to optimality which requires
$\tilde{c}_{\ell} \geq
\tilde{c}_{B}\tilde{A}_{B}^{-1}\tilde{A}_{\bullet, \ell}$,
since $\tilde{c}_{\ell}=0$ for 
$\ell \in N \setminus art$.
So $\ell \in N \cap art$, which by requirement~(\ref{req:order_eps}) implies
$(\tilde{A}_{B}^{-1}\tilde{A}_{\bullet, j})_{i}=0$, for
$i \in B \cap art$ and $j \in N \setminus art$. 
\end{proof}

\subsubsection{Removing nonbasic artificial variables}
\marginpar{variable index issue: subsubsection adapted}
In order to remove a nonbasic artificial variable $x_{j}(\varepsilon)$ we
have to increase its value from its current value $-\varepsilon^{j+1}$ to zero,
without the basic variables becoming infeasible.
Since
\begin{equation*} 
\frac{
  \left(
    \tilde{A}_{B}^{-1}b-\tilde{A}_{B}^{-1}\tilde{A}_{N}\epsilon_{N}
  \right)_{i}
  + \varepsilon^{i+1}
}
{\left(\tilde{A}_{B}^{-1}\tilde{A}_{N}\right)_{i, j}}
> 
\varepsilon^{j+1},
\quad \text{for} \quad \left(\tilde{A}_{B}^{-1}\tilde{A}_{N}\right)_{i, j} >0
\end{equation*}
holds for any $i \in B$ and $j \in N$ with $i < j$,
by the requirement~(\ref{req:order_eps}) this increment is always possible
with respect to basic variables $x_{i}(\varepsilon)$ with
$i \in B \setminus art$, thus, the only variables
that may become infeasible while increasing the value of some
$x_{j}(\varepsilon)$ with $j \in N \cap art$ are the basic artificial variables
$x_{i}(\varepsilon)$ with $i \in B \cap art$, $j<i$ and
$(\tilde{A}_{B}^{-1}\tilde{A})_{i,j} >0$. So given a basis, if we define
\begin{equation}
l:=\min_{j \in N \cap art}j, \quad u:=\max_{i \in B \cap art}i
\end{equation}
then $x_{i}$ with $\{i \in B \cap art\left|\right. i < l\}$ remain feasible for
any increase $\varepsilon^{j+1}$ for $x_{j}(\varepsilon)$ with
$j \in N \cap art$ and $x_{j}$ with $\{j \in N \cap art\left|\right. j > u\}$
may be increased to zero without rendering any basic variable
$x_{i}$ with $i \in B \cap art$ infeasible. Thus critical regarding
feasibility are increases by $\varepsilon^{j+1}$ of nonbasic variables
$x_{j}(\varepsilon)$ with $j \in art_{N}^{\leq u}$, where
$art_{N}^{\leq u}:= \{j \in N \cap art\left|\right. j \leq u\}$
with respect to basic variables $x_{i}(\varepsilon)$ with
$i \in art_{B}^{\geq l}$, where
$art_{B}^{\geq l}:=\{j \in B \cap art: j \geq l\}$.
\subsubsection{Removing basic artificial variables}

\subsection{The lexicographic method in phaseII}
Since the nonbasic variables are no longer zero, the objective function as well as
the values of the basic variables are no longer independent of the nonbasic
variables; we therefore for the sake of explicitness restate the perturbed
variants of (UQP($B$)), (QP($B$)) and their KKT conditions for optimality
as well as the perturbed variant of the definition of QP-basis.

\begin{lemma}{KKT conditions for $(QP(B_{\varepsilon}))$}
\label{lemma:KKT_QP(B)_epsilon}
A feasible solution $x^{*}(\varepsilon) \in \mathbb{R}^{n}$ to the quadratic
program
\begin{eqnarray*}
  \mbox{$(QP(B_{\varepsilon}))$} & minimize & c_{B \cup N}^{T}
    x_{B \cup N}(\varepsilon)
    + x_{B \cup N}^{T}(\varepsilon) 
    D_{B \cup N, B \cup N} x_{B \cup N}(\varepsilon) \\
    & s.t. & A_{B}x_{B}(\varepsilon) = b - A_{N}x_{N}(\varepsilon)  \\
    & & I_{N}x_{N}(\varepsilon) = \epsilon_{N}  \\
    & & x_{B}(\varepsilon) \geq \epsilon_{B}
\end{eqnarray*}
with $D$ symmetric, is optimal iff there exists an $m$-vector
$\lambda(\varepsilon)$ and an $\left|B\right|$-vector $\mu(\varepsilon) \geq 0$
such that
\begin{eqnarray}
  c_{B}^{T} + 2x_{B}^{*^{\scriptstyle{T}}}(\varepsilon)D_{B,B} +
  2\epsilon_{N}^{T}D_{N,B} & = &
  -\lambda^{T}(\varepsilon)A_{B} + \mu_{B}^{T}(\varepsilon)I_{B} \\
  \mu_{B}^{T}(\varepsilon) \left( -I_{B}x_{B}^{*}(\varepsilon) +
    \epsilon_{B} \right) & = & 0
\end{eqnarray}
\end{lemma}

Likewise, the KKT conditions for $(UQP(B_{\varepsilon}))$ are
\begin{lemma}{KKT conditions for $(UQP(B_{\varepsilon}))$}
\label{lemma:KKT_UQP(B)_epsilon}
A feasible solution $x^{*}(\varepsilon) \in \mathbb{R}^{n}$ to the
unconstrained quadratic program
\begin{eqnarray*}
  \mbox{$(UQP(B_{\varepsilon}))$} & minimize & c_{B \cup N}^{T}
    x_{B \cup N}(\varepsilon)
    + x_{B \cup N}^{T}(\varepsilon) D_{B \cup N, B \cup N}
    x_{B \cup N}(\varepsilon) \\
    & s.t. & A_{B}x_{B}(\varepsilon) = b - A_{N}x_{N}(\varepsilon)  \\
    & & I_{N}x_{N}(\varepsilon) = \epsilon_{N}  
\end{eqnarray*}
with $D$ symmetric, is optimal iff there exists an $m$-vector
$\lambda(\varepsilon)$ such that
\begin{eqnarray}
  c_{B}^{T} + 2x_{B}^{*^{\scriptstyle{T}}}(\varepsilon)D_{B,B} +
  2\epsilon_{N}^{T}D_{N,B} & = &
    -\lambda^{T}(\varepsilon)A_{B}
\end{eqnarray}
\end{lemma}

\begin{lemma}
\label{lemma:strict}
Any vector $x_{B \cup N}(\varepsilon)$, $x_{B}(\varepsilon) > \epsilon_{B}$
satisfying
\begin{eqnarray}
A_{B}x_{B}(\varepsilon) & = & b - A_{N}x_{N}(\varepsilon) \\
x_{N}(\varepsilon) &  = & \epsilon_{N}
\end{eqnarray}
is an optimal solution to $(QP(B_{\varepsilon}))$, iff it is an optimal
solution to $(UQP(B_{\varepsilon}))$.
\end{lemma}

\begin{proof}
For $x_{B}(\varepsilon) > \epsilon_{B}$ the second condition of
Lemma~\ref{lemma:KKT_QP(B)_epsilon} implies $\mu_{B}^{T}(\varepsilon)=0$.
Thus, the first condition of Lemma~\ref{lemma:KKT_QP(B)_epsilon} and the
single condition of Lemma~\ref{lemma:KKT_UQP(B)_epsilon} are equivalent.
On the other hand any optimal solution to $(UQP(B_{\varepsilon}))$ with
$x_{B}(\varepsilon) > \epsilon_{B}$ is feasible and optimal to
$(QP(B_{\varepsilon}))$ too, since the feasible region of the latter is
completely contained in the feasible region of $(UQP(B_{\varepsilon}))$.
\end{proof}

And last but not least the perturbed variant of the definition of a $QP$-basis:
\begin{definition}
A subset $B$ of the variables of a quadratic program in standard form defines
a $QP_{\varepsilon}$-basis iff
\begin{enumerate}
  \item the unconstrained subproblem
    \begin{eqnarray}
      \mbox{(UQP($B_{\epsilon}$))} & minimize & c_{B \cup N}^{T}
       x_{B \cup N}(\varepsilon) 
        + x_{B \cup N}^{T}(\varepsilon)D_{B \cup N, B \cup N}
	x_{B \cup N}(\varepsilon)  \nonumber\\
\label{eq:QP_eps_basis_feasibility_B}
      & s.t.  &A_{B} x_{B}(\varepsilon) = b - A_{N}x_{N}(\varepsilon)  \\
\label{eq:QP_eps_basis_feasibility_N}
           &  &I_{N} x_{N}(\varepsilon) = \epsilon_{N}   
    \end{eqnarray}
    has an unique optimal solution $x_{B}^{*}(\varepsilon) > \epsilon_{B}$ and 
  \item $A_{B}$ has full row rank, $rank(A_{B})=m$. 
\end{enumerate}
\end{definition}
In the following subsections we will mimic the arguments of \cite{Sven},
Sections (2.3.1), (2.3.2) for the perturbed problem.

\subsubsection{Pricing}
Testing whether a nonbasic variable $x_{j}(\varepsilon)$ can improve the
current solution $x_{B}^{*}(\varepsilon)$ by entering the current
$QP_{\varepsilon}$-basis $B$ is done as follows.
Let $\hat{B}:=B \cup \{j\}$ and consider the subproblem
\begin{eqnarray*}
  \mbox{(QP($\hat{B}_{\varepsilon}$))} &minimize& c_{\hat{B} \cup \hat{N}}^{T}
    x_{\hat{B} \cup \hat{N}}(\varepsilon) +
    x_{\hat{B} \cup \hat{N}}^{T}(\varepsilon)
    D_{\hat{B} \cup \hat{N}}x_{\hat{B} \cup \hat{N}}(\varepsilon)
      \\
    & s.t. & A_{\hat{B}}x_{\hat{B}}(\varepsilon) = b - A_{\hat{N}}
    x_{\hat{N}}(\varepsilon)  \\
    & & I_{\hat{N}}x_{\hat{N}}(\varepsilon) = \epsilon_{\hat{N}} \\
    & & x_{\hat{B}}(\varepsilon) \geq \epsilon_{\hat{B}}  
\end{eqnarray*}
By Lemma~\ref{lemma:KKT_QP(B)_epsilon} for the above,
$x_{\hat{B}}^{*}(\varepsilon)$ is an optimal solution
iff there exists vectors $\lambda(\varepsilon)$ and
$\mu(\varepsilon) \geq 0$ such that
\begin{eqnarray}
\label{eq:KKT_lagrange_id}
  c_{\hat{B}}^{T} + 2x_{\hat{B}}^{*^{\scriptstyle{T}}}(\varepsilon)D_{\hat{B}, \hat{B}} +
  2\epsilon_{\hat{N}}^{T}D_{\hat{N}, \hat{B}}& = &
  -\lambda^{T}(\varepsilon)A_{\hat{B}} 
  + \mu_{\hat{B}}^{T}(\varepsilon)I_{\hat{B}}  \\
\label{eq:KKT_compl_slackness}
  \mu_{\hat{B}}^{T}(\varepsilon)
  \left(-I_{\hat{B}}x_{\hat{B}}^{*}(\varepsilon)
  + \epsilon_{\hat{B}}\right) & = & 0
\end{eqnarray}
Since $x_{B}^{*}(\varepsilon)> \epsilon_{B}$, $\mu_{B}(\varepsilon)=0$ holds
using~(\ref{eq:KKT_compl_slackness}). Isolating $x_{j}^{*}(\varepsilon)$
in~(\ref{eq:KKT_lagrange_id}) and grouping into $B$ and $j$ components yields
\begin{eqnarray}
\label{eq:KKT_lagrange_id_B}
  c_{B}^{T} + {2x_{B}^{*}}^{T}(\varepsilon)D_{B,B}
  + 2\epsilon_{\hat{N}}^{T}D_{\hat{N},B}
  + 2x_{j}^{*}(\varepsilon)D_{B,j}^{T} & = & -\lambda^{T}(\varepsilon) A_{B} \\
\label{eq:KKT_lagrange_id_j}
  c_{j} + 2{x_{B}^{*}}^{T}(\varepsilon)D_{B,j}
  + 2x_{j}^{*}(\varepsilon)D_{j,j}
  + 2\epsilon_{\hat{N}}^{T}D_{\hat{N},j} & = &
  -\lambda^{T}(\varepsilon) A_{j} + \mu_{j}(\varepsilon)
\end{eqnarray}
Equation~(\ref{eq:KKT_lagrange_id_B}) together with the
feasibility constraints~(\ref{eq:QP_eps_basis_feasibility_B}),
(\ref{eq:QP_eps_basis_feasibility_N}) of
$(UQP(B_{\epsilon}))$ and the fact that $N:=\hat{N} \cup \{j\}$ determine
$\lambda(\varepsilon)$, given $x_{B}^{*}(\varepsilon)$ and
$x_{j}^{*}(\varepsilon) = -\varepsilon^{j}$, by the linear equation system
\begin{equation}
M_{B}\left(
        \begin{array}{c}
          \lambda(\varepsilon)  \\
          \hline
           x_{B}^{*}(\varepsilon)
        \end{array}
     \right)   
=
\left(
    \begin{array}{c}
        b \\
	\hline
	-c_{B}
     \end{array}
\right)
-
\left(
    \begin{array}{c}
        A_{N}  \\
	\hline
	2D_{B,N}
     \end{array}
\right)\epsilon_{N}
\end{equation}
with $M_{B}$ defined as
\begin{equation}
\label{def:M_B}
M_{B}:=\left(
           \begin{array}{c|c}
	       0 & A_{B} \\
	       \hline
	       A_{B}^{T} & 2D_{B,B}
	   \end{array}
	\right)
\end{equation}
By the definition of $QP_{\varepsilon}$-basis, $x_{B}^{*}(\varepsilon)$
is the unique optimal
solution to $(UQP(B_{\varepsilon}))$ and $A_{B}$ has full row rank. Thus, also
$\lambda(\varepsilon)$ is unique and $M_{B}$ is regular,
therefore $M_{B}^{-1}$ exists. Note,
that $M_{B}$ is the same as in the unperturbed problem.
 
\subsubsection{Ratio Test Step 1}
Starting with a $QP_{\varepsilon}$-basis $B$ and an entering variable
$x_{j}(\varepsilon)$,
we want to find a new basis $B^{\prime} \subseteq B \cup \{j\}$ with
better objective function value.
Define $\hat{B}:=B \cup \{j\}$, then $x_{\hat{B}}^{*}(\varepsilon)$ with
$x_{j}^{*}=-\varepsilon^{j}$ is the optimal solution to
\begin{eqnarray*}
(UQP_{j}^{t}(\hat{B}_{\varepsilon})) & minimize &
  c_{\hat{B} \cup \hat{N}}^{T}x_{\hat{B} \cup \hat{N}}(\varepsilon)
  + x_{\hat{B} \cup \hat{N}}^{T}(\varepsilon)
  D_{\hat{B} \cup \hat{N},\hat{B} \cup \hat{N}}
  x_{\hat{B} \cup \hat{N}}(\varepsilon)  \\
  & s.t & A_{\hat{B}}x_{\hat{B}}(\varepsilon) =
  b - A_{\hat{N}}x_{\hat{N}}(\varepsilon) \\
  & & I_{\hat{N}}x_{\hat{N}}(\varepsilon) = \epsilon_{\hat{N}} \\
  & & x_{j}(\varepsilon) = - \varepsilon^{j} + t
\end{eqnarray*}
for $t=0$. $(UQP_{j}^{t}(\hat{B}_{\varepsilon}))$ has a unique solution
$x_{\hat{B}}^{*}(\varepsilon, t)$ for each value of t, given by
\begin{equation}
\label{eq:UQP_j_t_opt_explicit}
M_{B}\left(\begin{array}{c}
              \lambda\left(\varepsilon, t\right) \\
	      \hline
	      x_{B}^{*}\left(\varepsilon, t\right) \\
	    \end{array}
      \right)
=
\left(\begin{array}{c}
         b \\
	 \hline
	 -c_{B} \\
      \end{array}
\right)
-
\left(\begin{array}{c}
         A_{N} \\
	 \hline
	 2D_{B,N} \\
       \end{array}
\right) \epsilon_{N}
-t
\left(\begin{array}{c}
         A_{j} \\
	 \hline
	 2D_{B,j} \\
      \end{array}
\right)
\end{equation}
and $x_{j}^{*}\left(\varepsilon,t\right)= -\varepsilon^{j} + t$. This follows
from the KKT conditions given by Lemma~\ref{lemma:KKT_UQP(B)_epsilon} for the
reformulation of $(UQP_{j}^{t}(\hat{B}_{\varepsilon}))$ as
\begin{eqnarray*}
(UQP_{j}^{t}(\hat{B}_{\varepsilon})) 
  & minimize & c_{B \cup N}^{T} x_{B \cup N}(\varepsilon) +
  x_{B \cup N}^{T}(\varepsilon)D_{B \cup N, B \cup N}
  x_{B \cup N}(\varepsilon) \\
  & s.t. & A_{B}x_{B}(\varepsilon) = b - A_{N}x_{N}(\varepsilon)  \\
  && I_{N}x_{N}(\varepsilon) = \epsilon_{N}^{j}
\end{eqnarray*}
with $\epsilon_{N}^{j}:=\epsilon_{N} + te_{j}$, and the regularity of
$M_{B}$. 
While increasing $t$ starting from zero, either some basic variable $i \in B$
may become $x_{i}(\varepsilon)=-\varepsilon^{i}$ or a local minimum of the
objective function, that is $\mu_{j}(\varepsilon)$ in
Equation~(\ref{eq:KKT_lagrange_id_j}) becomes zero, is reached.
We will show later that these two events never happen simultaneously for the
perturbed problem.
In order to derive $\mu_{j}\left(\varepsilon, t\right)$, define
\begin{eqnarray}
\label{def:sol_eps_zero_I}
\left(\begin{array}{c}
         \lambda\left(\varepsilon, 0\right) \\
	 \hline
	 x_{B}^{*}\left(\varepsilon, 0\right)
       \end{array}
\right)
&:=&M_{B}^{-1}
\left[
  \left(\begin{array}{c}
           b \\
	   \hline
	   -c_{B}
	\end{array}
   \right)
   -
   \left(\begin{array}{c}
           A_{N}  \\
	   \hline
	   2D_{B,N}
	 \end{array}
   \right)\epsilon_{N}
\right] 
\\
\left(\begin{array}{c}
         q_{\lambda} \\
	 \hline
	 q_{x}
       \end{array}
\right)
&:=&M_{B}^{-1}
\left(\begin{array}{c}
        A_{j} \\
	\hline
	2D_{B,j}
       \end{array}
\right)
\end{eqnarray}
such that Equation~(\ref{eq:UQP_j_t_opt_explicit}) becomes
\begin{equation}
\label{eq:UQP_j_t_opt_short}
\left(\begin{array}{c}
         \lambda\left(\varepsilon, t\right) \\
	 \hline
	 x_{B}^{*}\left(\varepsilon, t\right)
       \end{array}
\right)
=
\left(\begin{array}{c}
        \lambda\left(\varepsilon, 0\right) \\
	\hline
	x_{B}^{*}\left(\varepsilon, 0\right)
      \end{array}
\right)
-t
\left(\begin{array}{c}
         q_{\lambda} \\
	 \hline
	 q_{x}
       \end{array}
\right),
\end{equation}
$\mu_{j}\left(\varepsilon, t\right)$ can then, by using
Equations~(\ref{eq:KKT_lagrange_id_j}),(\ref{eq:UQP_j_t_opt_short}) and 
$x_{j}^{*}\left(\varepsilon, t\right)= -\varepsilon^{j} + t$ be
expressed as
\begin{eqnarray}
\label{eq:mu_j_eps_t}
\mu_{j}\left(\varepsilon, t\right) & = & c_{j} +
  A_{j}^{T}\lambda\left(\varepsilon, t\right)
  + 2D_{B,j}^{T}x_{B}^{*}\left(\varepsilon, t\right) +
  2D_{j,j}x_{j}^{*}\left(\varepsilon, t\right)
  + 2D_{\hat{N}, j}^{T}\epsilon_{\hat{N}} \nonumber \\
  & = & c_{j} + A_{j}^{T}\lambda\left(\varepsilon, 0\right)
  + 2D_{B,j}^{T}x_{B}^{*}\left(\varepsilon, 0\right) +
  2D_{j,j}\epsilon_{j}
  + 2D_{\hat{N}, j}^{T}\epsilon_{\hat{N}} + \nonumber \\
  & & t\left(D_{j,j} - A_{j}^{T}q_{\lambda} - 2D_{B,j}^{T}q_{x}
  \right) \\
  & = & \mu_{j}\left(\varepsilon, 0\right) + t\nu
  \nonumber   
\end{eqnarray}
where
\begin{equation}
\label{def:nu}
\nu := 2D_{j,j} - A_{j}^{T}q_{\lambda} - 2D_{B,j}^{T}q_{x}
\end{equation}
and
\begin{equation}
\mu_{j}\left(\varepsilon, 0\right) :=
c_{j} + 2D_{N, j}^{T}\epsilon_{N} +
\left(A_{j}^{T} \left|\right. 2D_{B, j}^{T} \right)
\left(\begin{array}{c}
        \lambda\left(\varepsilon, 0\right) \\
	\hline
	x_{B}^{*}\left(\varepsilon, 0\right)
       \end{array}
\right) 
\end{equation}
Using Definitions~(\ref{def:sol_eps_zero_I}), (\ref{def:nu}) and elementary
algebraic manipulation
$\mu_{j}(\varepsilon,0)$ may be written as
\begin{eqnarray*}
  \mu_{j}\left(\varepsilon, 0\right) &=& c_{j} +
  \left(A_{j}^{T} \left|\right. 2D_{B, j}^{T} \right)
  M_{B}^{-1}
  \left(\begin{array}{c}
          b \\
	  \hline
	  -c_{B}
	\end{array}
  \right) + \\
  &&
  \left[2D_{N, j}^{T} -
    \left(A_{j}^{T} \left|\right. 2D_{B, j}^{T} \right)
    M_{B}^{-1}
    \left(\begin{array}{c}
            A_{N} \\
	    \hline
	    2D_{B,N}
	  \end{array}
    \right)
  \right]\epsilon_{N} 
\end{eqnarray*}
Finally, setting $\varepsilon=0$ in the above, we obtain $\mu_{j}(0, 0)$, such
that $\mu_{j}(\varepsilon, 0)$ can be written in terms of $\mu_{j}(0,0)$ as
\begin{equation}
\label{eq:mu_j_eps_zero}
\mu_{j}\left(\varepsilon, 0\right) =
  \mu_{j}\left(0,0\right) +
    \left[
    2D_{j, N} - \left(A_{j}^{T} \left| \right. 2D_{B, j}^{T} \right)
    M_{B}^{-1}
    \left(\begin{array}{c}
            A_{N} \\
	    \hline
	    2D_{B, N}
	  \end{array}
    \right)
  \right]\epsilon_{N}
\end{equation}

When $\mu_{j}\left(\varepsilon, t\right)$ becomes zero for some $t > 0$,
$\lambda\left(\varepsilon, t\right)$ and $\mu_{\hat{B}}(\varepsilon)$ satisfy
the KKT conditions of Lemma~\ref{lemma:KKT_QP(B)_epsilon}, thus
$x_{B}^{*}\left(\varepsilon, t\right)$,
$x_{j}^{*}\left(\varepsilon, t\right)$ is an optimal solution to
$(QP_{\varepsilon}(\hat{B}))$. Lemma (2.7) in~\cite{Sven} then asserts the
additional requirements of uniqueness of the solution as well as full row rank
of $A_{\hat{B}}$ for $\hat{B}$ being the new $QP_{\varepsilon}$-basis.

In the first case happening, we implicitly add the constraint
$x_{i}(\varepsilon)=-\varepsilon^{i}$
to $(UQP_{j}^{t}(\hat{B}_{\varepsilon}))$ by removing $i$ from the set $B$.
If $M_{B \setminus \{i\}}$ is regular,
we still have a unique optimal solution to
$(UQP_{j}^{t}(\hat{B}_{\varepsilon} \setminus \{i\}))$ for each value of
$t$ and Ratio Test Step 1 is
iterated. Otherwise we proceed with the Ratio Test Step 2.

 
\subsubsection{Ties in Ratio Test Step 1}
\label{sec:Ties_ratio_test_step_1}
Consider two basic variables $i_{1}, i_{2} \in B$ involved in a tie in the
unperturbed problem, setting $\varepsilon=0$ in
Equation~(\ref{eq:UQP_j_t_opt_short}), this can be expressed as
\begin{equation}
\check{t}\left(0, B\right)=
\frac{\left(\begin{array}{c}
              \lambda\left(0, 0 \right) \\
              \hline
               x_{B}^{*}\left(0, 0\right)
            \end{array}
      \right)_{x_{i_{1}}}}{q_{x_{i_{1}}}}
=
\frac{\left(\begin{array}{c}
              \lambda\left(0, 0 \right) \\
              \hline
              x_{B}^{*}\left(0, 0\right) 
            \end{array}
       \right)_{x_{i_{2}}}}{q_{x_{i_{2}}}}
\end{equation}
where
\begin{equation}
\check{t}\left(0, B\right):=\min_{i \in B: q_{x_{i}} > 0}
\frac{\left(\begin{array}{c}
               \lambda\left(0, 0\right) \\
               \hline
               x_{B}^{*}\left(0, 0\right)
            \end{array}
       \right)_{x_{i}}}{q_{x_{i}}}
\end{equation}
According to Definition~(\ref{def:QP_eps}) of the perturbed problem,
Equation~(\ref{eq:UQP_j_t_opt_short}) and
Definition~(\ref{def:sol_eps_zero_I}),
$\check{t}(\varepsilon, B)$
is defined as
\begin{eqnarray}
\label{def:t_min_eps}
\check{t}\left(\varepsilon, B\right) & := &
  \min_{i \in B: q_{x_{i}} > 0}
  \frac{\left(\begin{array}{c}
                \lambda\left(\varepsilon, 0 \right) \\
	        \hline
	        x_{B}^{*}\left(\varepsilon, 0 \right)
	      \end{array}
        \right)_{x_{i}}+ \varepsilon^{i}}{q_{x_{i}}} \\
  &=&
    \check{t}\left(0, B \right) +
  \min_{i \in B: q_{x_{i}} > 0} \px{i}{Q_{1}}{B}
\end{eqnarray}
where
\begin{eqnarray}
\label{def:p_x_i_Q_1}
\px{i}{Q_{1}}{B} &:=&
  \frac{\varepsilon^{i} -
         \left(M_{B}^{-1}
           \left(\begin{array}{c}
                    A_{N}  \\
	            \hline
	            2D_{B, N}
	         \end{array}
	   \right)
         \right)_{x_{i}}\epsilon_{N}}{q_{x_{i}}} \\
  &=&
    \frac{\varepsilon^{i} -
         \left(M_{B}^{-1}
           \left(\begin{array}{c}
                    A_{N \setminus \{j\}}  \\
	            \hline
	            2D_{B, N \setminus \{j\}}
	         \end{array}
	   \right)
         \right)_{x_{i}}\epsilon_{N \setminus \{j\}}}{q_{x_{i}}}
	 + \varepsilon^{j}
\end{eqnarray}
Therefore, in order to resolve the tie in the perturbed problem, we have 
to compare the polynomials \px{i_{1}}{Q_{1}}{B} and \px{i_{2}}{Q_{1}}{B}.
Again, as in phaseI we always have either
$\px{i_{1}}{Q_{1}}{B} < \px{i_{2}}{Q_{1}}{B}$ or
$\px{i_{1}}{Q_{1}}{B} > \px{i_{2}}{Q_{1}}{B}$, since the
$\frac{\varepsilon^{i}}{q_{x_{i}}}$ terms are unique to each
\px{i}{Q_{1}}{B}.

Ties between a basic variable $x_{i}(0)$ taking its lower bound $0$ value and
$\mu_{j}\left(0, t\right)$ 
becoming zero in the unperturbed problem, that is,
according to Equation~(\ref{eq:mu_j_eps_t}) with $\varepsilon=0$,
\begin{equation*}
\check{t}\left(0, B\right)  =
-\frac{\mu_{j}\left(0, 0\right)}{\nu}
\end{equation*}
can be resolved in the perturbed problem,
given the above equality, by comparing
\begin{equation*}
\check{t}(\varepsilon, B)-\check{t}(0, B) = \px{i}{Q_{1}}{B}
\end{equation*}
and the expression
\begin{equation*}
\frac{-\mu_{j}(\varepsilon, 0)+ \mu_{j}(0,0)}{\nu}.
\end{equation*}
Therefore, taking into account Equation~(\ref{eq:mu_j_eps_zero}),
for the latter expression above, the following two
polynomials in $\varepsilon$ have to be compared in order to resolve the tie
\begin{eqnarray}
\px{i}{Q_{1}}{B} & = & 
    \frac{\varepsilon^{i} -
         \left(M_{B}^{-1}
           \left(\begin{array}{c}
                    A_{N \setminus \{j\}}  \\
	            \hline
	            2D_{B, N \setminus \{j\}}
	         \end{array}
	   \right)
         \right)_{x_{i}}\epsilon_{N \setminus \{j\}}}{q_{x_{i}}}
	 + \varepsilon^{j} \\
\label{def:p_mu_j_Q_1}
\pmu{Q_{1}}{B} & := &
  -\frac{2D_{j, N} -
    \left(A_{j}^{T} \left| \right. 2D_{B, j}^{T} \right)
    M_{B}^{-1}
    \left(\begin{array}{c}
            A_{N} \\
	    \hline
	    2D_{B,N}
	  \end{array}
    \right)}{\nu}
  \epsilon_{N}
\nonumber \\
&=&
  -\frac{2D_{j, N \setminus \{j\}} -
    \left(A_{j}^{T} \left| \right. 2D_{B, j}^{T} \right)
    M_{B}^{-1}
    \left(\begin{array}{c}
            A_{N \setminus \{j\}} \\
	    \hline
	    2D_{B,N \setminus \{j\}}
	  \end{array}
    \right)}{\nu}
  \epsilon_{N \setminus \{j\}}
\nonumber \\
&&
+\varepsilon^{j}      
\end{eqnarray}
The term $\frac{\varepsilon^{i}}{q_{x_{i}}}$ is again unique to 
\px{i}{Q_{1}}{B}, such that the tie can always
be resolved.

\subsubsection{The maximum number of coefficient comparisons needed for the tie
resolution in Ratio Test Step 1}
The Definition~(\ref{def:p_mu_j_Q_1}) of
\pmu{Q_{1}}{B} shows that the coefficient of
$\varepsilon^{k}$ for $k \in B$ is zero, such that the maximum number of
comparisons needed in phaseI, $r_{1}$, also applies here, regardless whether we
have to consider $\mu_{j}(0, t)$ becoming zero or not. Thus
\begin{equation}
r_{2}^{(Q_{1})}:= r_{1} = \left|\{1 \ldots u_{T}(B)\} \cap N \right|
\end{equation}
holds, if $u_{T}(B)$ is defined as in Definition~(\ref{def:u_T}) and $B_{T}$ is the
set of basic variables involved in the tie in the unperturbed problem.

\subsubsection{Ratio Test Step 2}
Let $B$ be the set of basic variables after the last iteration of 
Ratio Test Step~1
and let $x_{l}(\varepsilon)$ be the leaving variable of this last iteration,
such that $\tilde{B}:=B \cup \{l\}$ is the last basis
of Ratio Test Step~1 for a given pivot. Since
$M_{B}$ is no longer regular, Equation~(\ref{eq:UQP_j_t_opt_explicit}) does
no longer
determine unique solutions to $(UQP_{j}^{t}(\hat{B_{\epsilon}}))$ for arbitrary
$t$.
Reconsidering the KKT conditions for $(QP(\hat{B}_{\epsilon}))$, that is
Equations~(\ref{eq:KKT_lagrange_id}),(\ref{eq:KKT_compl_slackness}) yields
\begin{equation}
\label{eq:QP_j_mu_opt_explicit}
M_{\hat{B}}
\left(\begin{array}{c}
         \lambda\left(\varepsilon\right) \\
	 \hline
	 x_{B}^{*}\left(\varepsilon\right) \\
	 \hline
	 x_{j}^{*}\left(\varepsilon\right)
       \end{array}
\right)
=
\left(\begin{array}{c}
        b  \\
	\hline
	-c_{B} \\
	\hline
	-c_{j}
       \end{array}
\right)
-
\left(\begin{array}{c}
        A_{\hat{N}} \\
	\hline
	2D_{B, \hat{N}} \\
	\hline
	2D_{j, \hat{N}}
       \end{array}
\right)\epsilon_{\hat{N}}
+ \mu_{j}\left(\varepsilon\right)
\left(\begin{array}{c}
        0 \\
	\hline
	0 \\
	\hline
	1
       \end{array}
\right)
\end{equation}
In case $M_{\hat{B}}$ is singular, we proceed directly to Step 3. Otherwise,
the system of linear equations above has a unique solution for each value of
$\mu_{j}\left(\varepsilon\right)$. The solutions are determined by a linear
function in $\mu_{j}\left(\varepsilon\right)$, which can be written as
\begin{equation}
\label{eq:QP_j_mu_opt_short}
\left(\begin{array}{c}
         \lambda\left(\varepsilon, \mu_{j}\left(\varepsilon\right)\right) \\
	 \hline
	 x_{\hat{B}}^{*}\left(\varepsilon, 
	   \mu_{j}\left(\varepsilon\right)\right)
       \end{array}
\right)
=
\left(\begin{array}{c}
        \lambda\left(\varepsilon, 0\right) \\
	\hline
	x_{\hat{B}}^{*}\left(\varepsilon, 0\right)
       \end{array}
\right)
+ \mu_{j}(\varepsilon)
\left(\begin{array}{c}
         p_{\lambda} \\
	 \hline
	 p_{x_{\hat{B}}}
       \end{array}
\right)
\end{equation}
with
\begin{eqnarray}
\label{def:sol_eps_zero_II}
\left(\begin{array}{c}
         \lambda\left(\varepsilon, 0\right) \\
	 \hline
	 x_{B}^{*}\left(\varepsilon, 0\right) \\
	 \hline
	 x_{j}^{*}\left(\varepsilon, 0\right)
       \end{array}
\right)
&:=&M_{\hat{B}}^{-1}
\left[
  \left(\begin{array}{c}
          b \\
	  \hline
	  -c_{B} \\
	  \hline
	  -c_{j}
	\end{array}
   \right)
   -
   \left(\begin{array}{c}
           A_{\hat{N}} \\
	   \hline
	   2D_{B, \hat{N}} \\
	   \hline
	   2D_{j, \hat{N}}
	 \end{array}
   \right)\epsilon_{\hat{N}}
\right]
\\
\left(\begin{array}{c}
        p_{\lambda} \\
	\hline
	p_{x_{B}} \\
	\hline
	p_{x_{j}}
       \end{array}
\right)
&:=&M_{\hat{B}}^{-1}
\left(\begin{array}{c}
        0  \\
	\hline
	0  \\
	\hline
	1
       \end{array}
\right).
\end{eqnarray}
Any solution
$x_{\hat{B}}^{*}\left(\varepsilon,\mu_{j}\left(\varepsilon\right)\right)$ is
feasible for $(UQP(\hat{B}))$, and it is optimal if
$\mu_{j}\left(\varepsilon\right)=0$.
Let $\check{t}_{1}(\varepsilon, \tilde{B})$ be the value of $t$
for which $M_{B}$ became singular in the last iteration of Ratio Test Step 1
of the perturbed problem, then
$x_{\hat{B}}^{*}(\varepsilon, 
\mu_{j}(\varepsilon, \check{t}_{1}(\varepsilon, \tilde{B})))$
is the current feasible solution at the beginning of Ratio Test Step 2. 

While growing $\mu_{j}(\varepsilon)$ from
$\mu_{j}(\varepsilon,\check{t}_{1}(\varepsilon, \tilde{B})
)$
towards zero,
again, either one of the remaining basic variables becomes zero or a local
minimum of the objective function is reached. In case of the latter happening
$\mu_{j}(\varepsilon)$ equals zero, we found an optimal solution
$x_{\hat{B}}^{*}\left(\varepsilon, 0\right)$ to $(UQP(\hat{B_{\varepsilon}}))$,
which by
Lemma~\ref{lemma:strict} is also an optimal solution to the constrained
problem
$QP(\hat{B_{\varepsilon}})$. Uniqueness of the solution follows from the
regularity of $M_{\hat{B}}$, which also implies that $\hat{B}$ is the new basis
in that case.

On the other hand, if some basic variable $x_{k}(\varepsilon)$ becomes zero, we
implicitly add the constraint $x_{k}(\varepsilon)=-\varepsilon^{k}$ to
$(UQP(\hat{B_{\varepsilon}}))$ by removing $k$ from $\hat{B}$. If
$M_{\hat{B} \setminus \{k\}}$ stays regular, we still obtain unique solutions
of Equation~(\ref{eq:QP_j_mu_opt_explicit}) for arbitrary values of
$\mu_{j}(\varepsilon)$. In this case Ratio Test Step 2 is iterated,
otherwise we continue with Step 3. 
 
\subsubsection{Ties in Ratio Test Step 2}
\label{sec:Ties_ratio_test_step_2}
Consider two basic variables $i_{1}, i_{2} \in \hat{B}$ involved in a tie in
the unperturbed problem, setting $\varepsilon=0$ in
Equation~(\ref{eq:QP_j_mu_opt_short}), this can be expressed as 
\begin{equation}
\check{\mu}_{j}(0, \hat{B}) =
\frac{\left(\begin{array}{c}
              \lambda\left(0,0\right) \\
              \hline
               x_{\hat{B}}^{*}\left(0,0\right)
            \end{array}
      \right)_{x_{i_{1}}}}{p_{x_{i_{1}}}}
=
\frac{\left(\begin{array}{c}
              \lambda\left(0,0\right) \\
              \hline
              x_{\hat{B}}^{*}\left(0,0\right) 
            \end{array}
       \right)_{x_{i_{2}}}}{p_{x_{i_{2}}}}
\end{equation}
where
\begin{equation}
\label{def:hat_mu_j_min_0}
  \check{\mu}_{j}(0, \hat{B}) :=
  \min_{i \in \hat{B}: p_{x_{i}} < 0}
  \frac{\left(\begin{array}{c}
                \lambda\left(0,0\right) \\
	        \hline
	        x_{\hat{B}}^{*}\left(0,0\right)
	       \end{array}
         \right)_{x_{i}}}{p_{x_{i}}} 
\end{equation}
Again, similar to ties among basic variables in Ratio Test Step 1,
by Definition~(\ref{def:QP_eps}) of the perturbed problem,
Equation~(\ref{eq:QP_j_mu_opt_short}) and
Definition~(\ref{def:sol_eps_zero_II}),
$\check{\mu}_{j}(\varepsilon, \hat{B})$ is defined as
\begin{eqnarray}
\label{def:hat_mu_j_min_eps}
\check{\mu}_{j}(\varepsilon, \hat{B}) & := &
  \min_{i \in \hat{B}: p_{x_{i}} < 0}
  \frac{\left(\begin{array}{c}
                \lambda\left(\varepsilon, 0\right) \\
	        \hline
	        x_{\hat{B}}^{*}\left(\varepsilon,0\right)
	      \end{array}
        \right)_{x_{i}}+ \varepsilon^{i}}{p_{x_{i}}} \\
  &=&
  \check{\mu}_{j}(0, \hat{B}) +
  \min_{i \in \hat{B}: p_{x_{i}} < 0} p_{x_{i}}^{(Q_{2})}
  (\varepsilon, \hat{B})
\end{eqnarray}
where
\begin{eqnarray}
\label{def:p_x_i_Q_2}
p_{x_{i}}^{(Q_{2})}(\varepsilon, \hat{B}) &:=&
  \frac{\varepsilon^{i} -
         \left(M_{\hat{B}}^{-1}
           \left(\begin{array}{c}
                    A_{\hat{N}}  \\
	            \hline
	            2D_{\hat{B}, \hat{N}}
	         \end{array}
	   \right)
         \right)_{x_{i}}\epsilon_{\hat{N}}}{p_{x_{i}}}
\end{eqnarray}
Therefore in order to resolve the tie in the perturbed problem, we have to
compare the polynomials \px{i_{1}}{Q_{2}}{\hat{B}} and
\px{i_{2}}{Q_{2}}{\hat{B}}. Again, because of the term
$\frac{\varepsilon^{i}}{p_{x_{i}}}$ we always have either
$\px{i_{1}}{Q_{2}}{\hat{B}} < \px{i_{2}}{Q_{2}}{\hat{B}}$ or
$\px{i_{1}}{Q_{2}}{\hat{B}} > \px{i_{2}}{Q_{2}}{\hat{B}}$.

For ties between a basic variable $x_{i}(0)$ and $\mu_{j}(0)$ becoming zero
in the unperturbed problem, that is
\begin{equation}
\label{eq:tie_unpert_ratio_test_step_2}
  \check{\mu}_{j}(0, \hat{B}) = \mu_{j}\left(0\right)
\end{equation}
we distinguish two cases: $\mu_{j}(0)$ may be
determined by the last iteration of Ratio Test Step~1 or by the previous
iteration in Ratio Test Step~2.

\paragraph{$\mu_{j}$ determined by the last iteration of Ratio Test Step~1:}
We have to compare $\check{\mu}_{j}(\varepsilon, \hat{B})$ and
$\mu_{j}(\varepsilon)$, given Equation~(\ref{eq:tie_unpert_ratio_test_step_2}),
or equivalently
\begin{equation*}
  \check{\mu}_{j}(\varepsilon, \hat{B}) -
  \check{\mu}_{j}(0, \hat{B})= p_{x_{i}}^{(Q_{2})}(\varepsilon, \hat{B})
\end{equation*}
and
\begin{equation*}
\mu_{j}\left(\varepsilon\right) - \mu_{j}\left(0\right)
\end{equation*}
in order to resolve the tie in the perturbed problem.
Using Equations~(\ref{eq:mu_j_eps_t}), (\ref{eq:mu_j_eps_zero}) and assuming
that $x_{l}(\varepsilon)$ was the leaving variable in Ratio Test Step 1
when $M_{\tilde{B} \setminus \{l\}}$ became singular, the latter expression
may be written as
\begin{eqnarray*}
  \mu_{j}\left(\varepsilon\right) - \mu_{j}\left(0\right) &=&
  \mu_{j}(\varepsilon, \check{t}_{1}(\varepsilon, \tilde{B})) -
  \mu_{j}(0, \check{t}_{1}(0, \tilde{B})) \\
  &=&
  \mu_{j}\left(\varepsilon, 0\right) +
  \check{t}_{1}(\varepsilon, \tilde{B})\nu -
  \mu_{j}\left(0, 0\right) -
  \check{t}_{1}(0, \tilde{B})\nu \\
  &=&
  \mu_{j}\left(\varepsilon,0\right)
  +p_{x_{l}}^{(Q_{1})}(\varepsilon, \tilde{B})\nu -
  \mu_{j}(0, 0) \\
  &=&
  \left[
      2D_{j, \tilde{N}}
        -\left(A_{j}^{T} \left| \right. 2D_{\tilde{B}, j}^{T} \right)
      M_{\tilde{B}}^{-1}
      \left(\begin{array}{c}
              A_{\tilde{N}} \\
	      \hline
	      2D_{\tilde{B}, \tilde{N}}
	    \end{array}
      \right)
   \right]\epsilon_{\tilde{N}} + \\
   && p_{x_{l}}^{(Q_{1})}(\varepsilon, \tilde{B})\nu
\end{eqnarray*}
such that \pmu{Q_{2}^{(0)}}{\hat{B}} is defined as
\begin{eqnarray}
\label{def:p_mu_j_Q_2_0}
\pmu{Q_{2}^{(0)}}{\hat{B}} &:=& 
  \left[
      2D_{j, \tilde{N}\setminus \{j\}}
        -\left(A_{j}^{T} \left| \right. 2D_{\tilde{B}, j}^{T}
       \right)
      M_{\tilde{B}}^{-1}
      \left(\begin{array}{c}
              A_{\tilde{N} \setminus \{j\}} \\
	      \hline
	      2D_{\tilde{B}, \tilde{N} \setminus \{j\}}
	    \end{array}
      \right)
   \right]\epsilon_{\tilde{N} \setminus \{j\}} + 
 \nonumber \\ 
  &&
  \frac{\varepsilon^{l} -
         \left(M_{\tilde{B}}^{-1}
           \left(\begin{array}{c}
                    A_{\tilde{N} \setminus \{j\}}  \\
	            \hline
	            2D_{\tilde{B}, \tilde{N} \setminus \{j\}}
	         \end{array}
	   \right)
         \right)_{x_{l}}\epsilon_{\tilde{N} \setminus \{j\}}}{q_{x_{l}}}\nu
\end{eqnarray}
Therefore, in order to resolve the tie, we have to compare
$p_{x_{i}}^{(Q_{2})}(\varepsilon, \hat{B})$ and
\pmu{Q_{2}^{(0)}}{\hat{B}}, again,
the term $\frac{\varepsilon^{i}}{p_{x_{i}}}$ is unique to
$p_{x_{i}}^{(Q_{2})}(\varepsilon, \hat{B})$, such that the tie can
always be resolved.

\paragraph{$\mu_{j}$ determined by previous iteration of Ratio Test Step~2:}
Let $\hat{B}^{(k)}$ denote
the set of basic variables of the current iteration and correspondingly
$\hat{B}^{(k-1)}:=\hat{B}^{(k)} \cup \{l\}$ the set of basic variables of the
previous iteration where $x_{l}$ was the leaving variable.
Again, we have to compare $\check{\mu}_{j}(\varepsilon, \hat{B})$ and
$\mu_{j}(\varepsilon)$, given Equation~(\ref{eq:tie_unpert_ratio_test_step_2}),
or equivalently
\begin{equation*}
  \check{\mu}_{j}(\varepsilon, \hat{B}^{(k)}) -
  \check{\mu}_{j}(0, \hat{B}^{(k)})=
  p_{x_{i}}^{(Q_{2})}(\varepsilon, \hat{B}^{(k)})
\end{equation*}
and
\begin{equation*}
\mu_{j}\left(\varepsilon\right) - \mu_{j}\left(0\right)
\end{equation*}
in order to resolve the tie in the perturbed problem.
Using Definitions~(\ref{def:hat_mu_j_min_0}) and~(\ref{def:hat_mu_j_min_eps})
and assuming $x_{l}$ was the leaving variable in the last iteration the
latter expression may be written as
\begin{eqnarray}
\mu_{j}\left(\varepsilon\right) - \mu_{j}\left(0\right)
&=&
\check{\mu}_{j}(\varepsilon, \hat{B}^{(k-1)})
-\check{\mu}_{j}(0, \hat{B}^{(k-1)})
\nonumber \\
&=&
p_{x_{l}}^{(Q_{2})}(\varepsilon, \hat{B}^{(k-1)})
\nonumber
\end{eqnarray}
such that \pmu{Q_{2}^{(+)}}{\hat{B}} is defined as
\begin{equation}
\label{def:p_mu_j_Q_2_+}
\pmu{Q_{2}^{(+)}}{\hat{B}^{(k)}} :=
  \frac{\varepsilon^{l} -
         \left(M_{\hat{B}^{(k-1)}}^{-1}
           \left(\begin{array}{c}
                    A_{\hat{N}^{(k-1)}}  \\
	            \hline
	            2D_{\hat{B}^{(k-1)}, \hat{N}^{(k-1)}}
	         \end{array}
	   \right)
         \right)_{x_{l}}\epsilon_{\hat{N}^{(k-1)}}}{p_{x_{l}}}
\end{equation}
Therefore, in order to resolve the tie, we have to compare
$p_{x_{i}}^{(Q_{2})}(\varepsilon, \hat{B}^{(k)})$ and
$p_{x_{l}}^{(Q_{2})}(\varepsilon, \hat{B}^{(k-1)})$, again,
the term $\frac{\varepsilon^{i}}{p_{x_{i}}}$ is unique to
$p_{x_{i}}^{(Q_{2})}(\varepsilon, \hat{B}^{(k)})$, such that the tie can
always be resolved. 

\subsubsection{The maximum number of coefficient comparisons needed for the tie
resolution in Ratio Test Step 2}
As the Definition~(\ref{def:p_mu_j_Q_2_0}) of
\pmu{Q_{2}^{(0)}}{\hat{B}} indicates
the coefficients of \pmu{Q_{2}^{(0)}}{\hat{B}} entirely depend
on the last basis $\tilde{B}$ and its headings in Ratio Test Step~1.
For all the bases
$\hat{B}$ in Ratio Test Step~2 for some given pivot step we have
\begin{equation}
\label{eq:B_hat_inclusion}
\tilde{B} \setminus \{l\} \cup \{j\} =
B \cup \{j\} =
\hat{B}^{(1)} \supset \hat{B}^{(2)} \supset \cdots \supset \hat{B}^{(s_{2}-1)}
\supset \hat{B}^{(s_{2})}
\end{equation}
For each $k \in \hat{B}^{(l)}$, $l \in \{1 \dots s_{2}\}$ the coefficient of
$\varepsilon^{k}$ in the polynomial
$p_{x_{j}}^{(Q_{2})}(\varepsilon, \hat{B})$ is zero, such that
\pmu{Q_{2}}{\hat{B}} has a different coefficient with all
the polynomials $p_{x_{i}}^{(Q_2)}(\varepsilon, \hat{B})$, $i \in \hat{B}$.
Therefore due to the uniqueness of the term $\frac{\varepsilon^{i}}{p_{x_{i}}}$
to $p_{x_{i}}^{(Q_2)}(\varepsilon, \hat{B})$, for $i \in \hat{B}$, at most 
\begin{equation}
\label{eq:max_varepsilon_exp_Q_2}
\left|\{1 \ldots u_{T}(\hat{B})\} \cap \hat{N}\right|
\end{equation}
coefficient comparisons are needed to resolve the tie, if
$\hat{B}_{T} \subseteq \hat{B}$ denotes the set of basic variable involved in a
tie. 
\subsection{The lexicographic method in the context of reduced bases}
The polynomials used in the perturbed problem to decide possible ties use
the full basis inverses $M_{B}^{-1}$ and $A_{B}^{-1}$ respectively, since these
are not directly at our disposal, we will express the full basis inverses in
terms of the reduced ones $\check{M}_{B}^{-1}$ and $\check{A}_{B}^{-1}$.
\subsubsection{Expanded basis matrix inverse QP-case}
If the basis heading is given as $\left[C, S_{B}, B_{O}, B_{S} \right]$ the
basis matrix $M_{B}$ has the following form,
\begin{equation*}
\label{def:basis_matrix_form}
M_{B}:=
\left(\begin{array}{c|c|c|c}
        0 & 0 & A_{C, B_{O}} & A_{C, B_{S}} \\
        \hline
	0 & 0 & A_{S_{B}, B_{O}} & A_{S_{B}, B_{S}} \\
	\hline
        A_{C, B_{O}}^{T} & A_{S_{B}, B_{O}}^{T} & D_{B_{O}, B_{O}}
	  & D_{B_{O}, B_{S}} \\
        \hline
        A_{C, B_{S}}^{T} & A_{S_{B}, B_{S}}^{T} & D_{B_{S}, B_{O}}
	  & D_{B_{S}, B_{S}} \\
      \end{array}
\right),
\end{equation*}
since $D_{B_{O}, B_{S}} = D_{B_{S}, B_{O}} = 0$ and
$D_{B_{S}, B_{S}} = 0$ as well as $A_{C, B_{S}}=0$, this boils down to
\begin{equation}
\label{def:basis_matrix}
M_{B}:=
\left(\begin{array}{c|c|c|c}
        0 & 0 & A_{C, B_{O}} & 0 \\
        \hline
	0 & 0 & A_{S_{B}, B_{O}} & A_{S_{B}, B_{S}} \\
	\hline
        A_{C, B_{O}}^{T} & A_{S_{B}, B_{O}}^{T} & D_{B_{O}, B_{O}}
	  & 0 \\
        \hline
        0 & A_{S_{B}, B_{S}}^{T} & 0
	  & 0 \\
      \end{array}
\right).
\end{equation}
Note, that the block $A_{S_{B}, B_{S}}$ is a signed permutation matrix with
$\pm 1$ nonzero entries, such that
\begin{equation}
\label{eq:A_S_BxB_S_inv}
A_{S_{B}, B_{S}}^{T} = A_{S_{B}, B_{S}}^{-1}
\end{equation}
holds, since $A_{S_{B}, B_{S}}$ is orthogonal.
In order to compute the blocks of $M_{B}^{-1}$ in terms of $A$, $D$ and
$\check{M}_{B}^{-1}$ we compare the corresponding
components of
\begin{equation}
\check{M}_{B}^{-1}
\left(\begin{array}{c}
        b_{C} \\
	\hline
	-c_{B_{O}}
       \end{array}
\right)
=
\left(\begin{array}{c}
        \lambda_{C} \\
	\hline
	x_{B_{O}}
      \end{array}
\right), 
\quad
M_{B}^{-1}
\left(\begin{array}{c}
        b_{C} \\
	\hline
	b_{S_{B}} \\
	\hline
	-c_{B_{O}} \\
	\hline
	-c_{B_{S}}
       \end{array}
\right)
=
\left(\begin{array}{c}
        \lambda_{C} \\
	\hline
	\lambda_{S_{B}} \\
	\hline
	x_{B_{O}}  \\
	\hline
	x_{B_{S}}
       \end{array}
\right)
\end{equation}
for any choice of $b$ and $c$. Note, that $c_{B_{S}}=0$ and by \cite{Sven},
Section 2.4, $\lambda_{S_{B}}=0$. 
For the first row of blocks of $M_{B}^{-1}$ we obtain, using $c_{B_{S}}=0$,
\begin{eqnarray*}
\left(\check{M}_{B}^{-1}\right)_{C, C} b_{C}
 -\left(\check{M}_{B}^{-1}\right)_{C, B_{O}} c_{B_{O}}
&=&   
\left(M_{B}^{-1}\right)_{C, C} b_{C}
 +\left(M_{B}^{-1}\right)_{C, S_{B}} b_{S_{B}} - \\
&& 
 \left(M_{B}^{-1}\right)_{C, B_{O}} c_{B_{O}}
\end{eqnarray*}
which yields
\begin{eqnarray}
\label{eq:M_B_inv_exp_CxC}
\left(M_{B}^{-1}\right)_{C,C} &=& \left(\check{M}_{B}^{-1}\right)_{C,C} \\
\label{eq:M_B_inv_exp_CxS_B}
\left(M_{B}^{-1}\right)_{C,S_{B}} &=& 0 \\
\left(M_{B}^{-1}\right)_{C,B_{O}}&=&\left(\check{M}_{B}^{-1}\right)_{C,B_{O}}
\nonumber
\end{eqnarray}
For the third row of blocks of $M_{B}^{-1}$ we obtain likewise
\begin{eqnarray*}
\left(\check{M}_{B}^{-1}\right)_{B_{O}, C} b_{C}
 -\left(\check{M}_{B}^{-1}\right)_{B_{O}, B_{O}} c_{B_{O}}
&=&   
\left(M_{B}^{-1}\right)_{B_{O}, C} b_{C}
 +\left(M_{B}^{-1}\right)_{B_{O}, S_{B}} b_{S_{B}} - \\
&& 
 \left(M_{B}^{-1}\right)_{B_{O}, B_{O}} c_{B_{O}}
\end{eqnarray*}
which yields
\begin{eqnarray}
\label{eq:M_B_inv_exp_B_OxC}
\left(M_{B}^{-1}\right)_{B_{O},C} &=&
  \left(\check{M}_{B}^{-1}\right)_{B_{O},C} \\
\label{eq:M_B_inv_exp_B_OxS_B}
\left(M_{B}^{-1}\right)_{B_{O},S_{B}} &=& 0 \\
\label{eq:M_B_inv_exp_B_OxB_O}
\left(M_{B}^{-1}\right)_{B_{O},B_{O}}&=&
  \left(\check{M}_{B}^{-1}\right)_{B_{O},B_{O}}
\end{eqnarray}
For the fourth row of blocks of $M_{B}^{-1}$ we use the fact that
$A_{S_{B},B_{S}}$ is regular, therefore using
Equation~(\ref{eq:A_S_BxB_S_inv}) 
\begin{equation}
\label{eq:x_B_S}
x_{B_{S}} = A_{S_{B},B_{S}}^{T}\left(b_{S_{B}} - 
A_{S_{B}, B_{O}}x_{B_{O}}\right)
\end{equation}
must hold by definition of the slack variables. Therefore comparing
corresponding components in
\begin{eqnarray*}
\lefteqn{A_{S_{B},B_{S}}^{T}\left(b_{S_{B}} - 
A_{S_{B}, B_{O}}
\left[\left(\check{M}_{B}^{-1}\right)_{B_{O}, C}b_{C}
  - \left(\check{M}_{B}^{-1}\right)_{B_{O}, B_{O}} c_{B_{O}}\right]\right)
= } \\
& & \quad \quad ,\quad \quad \quad \quad \quad
\left(M_{B}^{-1}\right)_{B_{S}, C} b_{C}
  +\left(M_{B}^{-1}\right)_{B_{S}, S_{B}} b_{S_{B}}
  -\left(M_{B}^{-1}\right)_{B_{S}, B_{O}} c_{B_{O}} 
\end{eqnarray*}
yields
\begin{eqnarray}
\label{eq:M_B_inv_exp_B_SxC}
\left(M_{B}^{-1}\right)_{B_{S}, C} &=&
  \alpha\left(\check{M}_{B}^{-1}\right)_{B_{O},C} \\
\label{eq:M_B_inv_exp_B_SxS_B}
\left(M_{B}^{-1}\right)_{B_{S}, S_{B}} &=&
  A_{S_{B}, B_{S}}^{T} \\
\label{eq:M_B_inv_exp_B_SxB_O}
\left(M_{B}^{-1}\right)_{B_{S}, B_{O}} &=&
 \alpha\left(\check{M}_{B}^{-1}\right)_{B_{O},B_{O}}
\end{eqnarray}
if we define $\alpha$ as
\begin{equation}
\label{def:alpha}
\alpha := -A_{S_{B}, B_{S}}^{T}A_{S_{B}, B_{O}} 
\end{equation}
For the second row we take into account that $\lambda_{S_{B}}=0$
\begin{equation*}
\left(M_{B}^{-1}\right)_{S_{B}, C} b_{C}
  +\left(M_{B}^{-1}\right)_{S_{B}, S_{B}} b_{S_{B}}
  -\left(M_{B}^{-1}\right)_{S_{B}, B_{O}} c_{B_{O}}
= 0
\end{equation*}
this yields, using Equations~(\ref{eq:M_B_inv_exp_CxS_B})
and~(\ref{eq:M_B_inv_exp_B_OxS_B}) and the fact that $M_{B}^{-1}$ is symmetric, 
\begin{equation}
\label{eq:M_B_inv_exp_S_BxS_B}
\left(M_{B}^{-1}\right)_{S_{B}, S_{B}} = 0
\end{equation}
In order to obtain the last yet unknown block
$\left(M_{B}^{-1}\right)_{B_{S}, B_{S}}$
we multiply the last row of blocks of $M_{B}^{-1}$ by
the second column of blocks of $M_{B}$ yielding
\begin{equation*}
\alpha\left(\check{M}_{B}^{-1}\right)_{B_{O}, B_{O}} A_{S_{B}, B_{O}}^{T}
  + \left(M_{B}^{-1}\right)_{B_{S}, B_{S}} A_{S_{B}, B_{S}}^{T}
= 0
\end{equation*}
using Equation~(\ref{eq:A_S_BxB_S_inv}) and
Definition~(\ref{def:alpha}) we obtain
\begin{equation}
\label{eq:M_B_inv_exp_B_SxB_S}
\left(M_{B}^{-1}\right)_{B_{S}, B_{S}} =
  \alpha\left(\check{M}_{B}^{-1}\right)_{B_{O}, B_{O}}\alpha^{T}
\end{equation}
Collecting the different blocks, given by 
Equations~(\ref{eq:M_B_inv_exp_CxC}), (\ref{eq:M_B_inv_exp_CxS_B}),
(\ref{eq:M_B_inv_exp_S_BxS_B}), (\ref{eq:M_B_inv_exp_B_OxC}),
(\ref{eq:M_B_inv_exp_B_OxS_B}), (\ref{eq:M_B_inv_exp_B_OxB_O}),
(\ref{eq:M_B_inv_exp_B_SxC}), (\ref{eq:M_B_inv_exp_B_SxS_B}),
(\ref{eq:M_B_inv_exp_B_SxB_O}), and~(\ref{eq:M_B_inv_exp_B_SxB_S}),
and taking into account Equation~(\ref{eq:A_S_BxB_S_inv}),
we can finally express $M_{B}^{-1}$ in terms
of $\check{M}_{B}^{-1}$, $A$ and $D$, given the basis heading
$\left[C, S_{B}, B_{O}, B_{S}\right]$, as
\begin{equation}
\label{eq:M_B_inv_exp}
M_{B}^{-1}=
\left(\begin{array}{c|c|c|c}
        \left(\check{M}_{B}^{-1}\right)_{C,C} &
	0 &
	\left(\check{M}_{B}^{-1}\right)_{C,B_{O}} &
	 \left(\check{M}_{B}^{-1}\right)_{C, B_{O}}\alpha^{T} \\
	\hline
	0 &
	0 &
	0 &
	A_{S_{B},B_{S}} \\
	\hline
	\left(\check{M}_{B}^{-1}\right)_{B_{O}, C} &
	0 &
	\left(\check{M}_{B}^{-1}\right)_{B_{O}, B_{O}} &
          \left(\check{M}_{B}^{-1}\right)_{B_{O},B_{O}}\alpha^{T} \\
	\hline
	\alpha\left(\check{M}_{B}^{-1}\right)_{B_{O},
	C} &
	A_{S_{B}, B_{S}}^{T} &
	\alpha\left(\check{M}_{B}^{-1}\right)_{B_{O},
	B_{O}} &
	\alpha\left(\check{M}_{B}^{-1}\right)_{B_{O}, B_{O}}\alpha^{T}
      \end{array}
\right)
\end{equation}
where
\begin{equation*}
\alpha=-A_{S_{B}, B_{S}}^{T}A_{S_{B}, B_{O}}
\end{equation*}

\subsubsection{Expanded basis matrix inverse LP-case}
If the basis heading is given as $\left[B_{O}, B_{S} \right]$ the
basis matrix $A_{B}$ has the following form,
\begin{equation}
A_{B}:=
\left(\begin{array}{c|c}
        A_{C, B_{O}} & A_{C, B_{S}} \\
	\hline
	A_{S_{B}, B_{O}} & A_{S_{B}, B_{S}}
       \end{array}
\right).
\end{equation}
Again, we compare corresponding components of
\begin{equation}
\check{A}_{B}^{-1}b_{C}, \quad \quad
A_{B}^{-1}
\left(\begin{array}{c}
        b_{C} \\
	\hline
	b_{S_{B}}
       \end{array}
\right) 
\end{equation}
For the first row of blocks of $A_{B}^{-1}$ we obtain,
\begin{equation*}
\left(A_{B}^{-1}\right)_{C, B_{O}}b_{C}
  + \left(A_{B}^{-1}\right)_{C, B_{S}}b_{S_{B}} = \check{A}_{B}^{-1}b_{C}
\end{equation*}
which yields,
\begin{eqnarray}
\label{eq:A_B_inv_exp_CxB_O}
\left(A_{B}^{-1}\right)_{C, B_{O}} &=&\check{A}_{B}^{-1} \\
\label{eq:A_B_inv_exp_CxB_S}
\left(A_{B}^{-1}\right)_{C, B_{S}} &=& 0
\end{eqnarray}
For the second row of blocks of $A_{B}^{-1}$ we obtain,
using Equation~(\ref{eq:x_B_S}),
\begin{equation*}
\left(A_{B}^{-1}\right)_{S_{B}, B_{O}} b_{C}
  + \left(A_{B}^{-1}\right)_{S_{B}, B_{S}} b_{S_{B}}
=
A_{S_{B}, B_{S}}^{T}\left(b_{S_{B}} - A_{S_{B}, B_{O}}
  \check{A}_{B}^{-1} b_{C} \right)
\end{equation*}
which yields
\begin{eqnarray}
\label{eq:A_B_inv_exp_S_BxB_O}
\left(A_{B}^{-1}\right)_{S_{B}, B_{O}}
&=&
-A_{S_{B}, B_{S}}^{T}A_{S_{B}, B_{O}}\check{A}_{B}^{-1} \\
\label{eq:A_B_inv_exp_S_BxB_S}
\left(A_{B}^{-1}\right)_{S_{B}, B_{S}}
&=&
A_{S_{B}, B_{S}}^{T}
\end{eqnarray}
Collecting the blocks given by Equations~(\ref{eq:A_B_inv_exp_CxB_O}),
(\ref{eq:A_B_inv_exp_CxB_S}), (\ref{eq:A_B_inv_exp_S_BxB_O})
and~(\ref{eq:A_B_inv_exp_S_BxB_S}) and using
Definition~(\ref{def:alpha}) we obtain $A_{B}^{-1}$ in terms of
$\check{A}_{B}^{-1}$ and $A$ as
\begin{equation}
\label{eq:A_B_inv_exp}
A_{B}^{-1}=
\left(\begin{array}{c|c}
        \check{A}_{B}^{-1} & 0 \\
	\hline
	\alpha\check{A}_{B}^{-1} & A_{S_{B}, B_{S}}^{T}
      \end{array}
\right)
\end{equation}
where
\begin{equation*}
\alpha = -A_{S_{B}, B_{S}}^{T}A_{S_{B}, B_{O}}
\end{equation*}

\section{Evaluating coefficients of the tie breaking polynomials}
In order to compute coefficients of the tie breaking polynomials we will need to
reference entries of the block matrices involved, for technical reasons these
block matrices may be permuted. We therefore introduce the following
permutations
\begin{equation}
\beta_{O}: B_{O}  \rightarrow  B_{O}, \quad
\beta_{S}: B_{S} \rightarrow  B_{S}
\end{equation}
\begin{equation}
\gamma_{C}: E \cup S_{N} \rightarrow  E \cup S_{N}, \quad
\gamma_{S_{B}}: S_{B} \rightarrow  S_{B} 
\end{equation}
where the permutations are defined with respect to the headings in ascending
order.

An expression that will be often encountered in the next subsections is the
following one, given $i \in B_{S}$ we want to compute
$(\alpha)_{\beta_{S}(i)}$ as a subexpression,
\begin{eqnarray}
\left(\alpha\right)_{\beta_{S}(i)}
&=&
-\left(A_{S_{B}, B_{S}}^{T}\right)_{\beta_{S}(i)}A_{S_{B}, B_{O}}
\nonumber \\
&=&
-A_{\sigma(i), i}\left(A_{S_{B}, B_{O}}\right)_{\gamma_{S_{B}}(\sigma(i))}
\nonumber \\
&=&
\label{eq:alpha_beta_S}
-A_{\sigma(i), i}A_{\sigma(i), B_{O}}
\end{eqnarray}

\subsection{PhaseI}
According to Section~\ref{sec:Res_ties_phaseI} the polynomials
$\tilde{p}_{x_{i}}^{(L)}(\varepsilon, B)$ and
$\tilde{p}_{x_{i}}^{(Q)}(\varepsilon, B)$ are equal such that considering
\begin{equation}
\label{eq:p_x_i_tilde_ref}
\tilde{p}_{x_{i}}^{(L)}\left(\varepsilon, B\right) := 
  \frac{\varepsilon^{i}
  - \left(A_{B}^{-1}\tilde{A}_{N}\right)_{x_{i}}
  \epsilon_{N}}{q_{x_{i}}}
= 
\frac{\varepsilon^{i}
- \left(A_{B}^{-1}\tilde{A}_{\hat{N}}\right)_{x_{i}}
  \epsilon_{\hat{N}}}{q_{x_{i}}}
+ \varepsilon^{j}
\end{equation}
in light of Equation~(\ref{eq:A_B_inv_exp})
will be sufficient for the LP-case as well as the QP-case
in phaseI when evaluating coefficients.
We will only consider the coefficients
$\varepsilon^{k}$ for $k \in \hat{N}= N \setminus \{j\}$ in
$\tilde{p}_{x_{i}}^{(L)}(\varepsilon, B)$,
since the other cases $k=j$ and $k \in B$
are trivial. Furthermore we only evaluate entities that are not evaluated in the
unperturbed problem, such that, taking into account the
Definition~(\ref{def:epsilon}) of $\epsilon$, we merely consider
the subexpression $(A_{B}^{-1}\tilde{A}_{\hat{N}})_{x_{i}}$. The correct value
of the coefficient is obtained by scaling the subexpression with the factor
$q_{x_{i}}^{-1}$.  
We will distinguish the two
possibilities $i \in B_{O}$ and $i \in B_{S}$ for $x_{i}$ as well as the
various possibilities for $k \in \hat{N}$ in phaseI. 
\subsubsection{LP/QP-case: $\tilde{p}_{x_{i}}^{(L)}(\varepsilon, B)$}
\paragraph{$\mathbf{i \in B_{O}}$:}
Assuming $i \in B_{O}$ we distinguish
according to Equation~(\ref{eq:A_B_inv_exp})
and the definition of $\tilde{p}_{x_{i}}^{(L)}(\varepsilon, B)$ the
following cases for $k \in \hat{N}$:
\begin{enumerate}
\item $k \in \hat{N} \cap S$:
\begin{eqnarray}
 (A_{B}^{-1}\tilde{A}_{k})_{x_{i}} &=&
  (A_{B}^{-1})_{x_{i}, B_{O} \cup B_{S}}\tilde{A}_{C \cup S_{B}, k}
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k} +
  (A_{B}^{-1})_{x_{i}, B_{S}}\tilde{A}_{S_{B}, k} 
  \nonumber \\
  &=&  
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k} 
  \nonumber \\
  &=&
  \left(\check{A}_{B}^{-1}\right)_{\beta_{O}(i)}\tilde{A}_{C, k}
  \nonumber \\
  &=&
  \left(\check{A}_{B}^{-1}\right)_{\beta_{O}(i), \gamma_{C}(\sigma(k))}
  \tilde{A}_{\sigma(k), k}
\end{eqnarray}
\item $k \in \hat{N} \cap art \setminus \{\tilde{a}^{s}\}$:
\begin{eqnarray}
  (A_{B}^{-1}\tilde{A}_{k})_{x_{i}} &=&
  (A_{B}^{-1})_{x_{i}, B_{O} \cup B_{S}}\tilde{A}_{C \cup S_{B}, k}
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k} +
  (A_{B}^{-1})_{x_{i}, B_{S}}\tilde{A}_{S_{B}, k} 
  \nonumber \\ 
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k} 
  \nonumber \\ 
  &=&
  \left(\check{A}_{B}^{-1}\right)_{\beta_{O}(i)}\tilde{A}_{C, k}
  \nonumber \\
  &=&
  \left(\check{A}_{B}^{-1}\right)_{\beta_{O}(i), \gamma_{C}(\sigma(k))}
  \tilde{A}_{\sigma(k), k}    
\end{eqnarray}
\item $\tilde{A}_{k}=\tilde{a}^{s}$:
\begin{eqnarray}
  (A_{B}^{-1}\tilde{A}_{k})_{x_{i}} &=& 
  (A_{B}^{-1})_{x_{i}, B_{O} \cup B_{S}} \tilde{a}_{C \cup S_{B}}^{s}
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{a}_{C}^{s} +
  (A_{B}^{-1})_{x_{i}, B_{S}}\tilde{a}_{S_{B}}^{s} 
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{a}_{C}^{s}
  \nonumber \\
  &=&
  \left(\check{A}_{B}^{-1}\right)_{\beta_{O}(i)}\tilde{a}_{C}^{s} 
  \nonumber \\
  &=&
  \left(\check{A}_{B}^{-1}\right)_{\beta_{O}(i), E}\tilde{a}_{E}^{s}
  +\left(\check{A}_{B}^{-1}\right)_{\beta_{O}(i), S_{N}}\tilde{a}_{S_{N}}^{s}
  \nonumber \\
  &=&
  \left(\check{A}_{B}^{-1}\right)_{\beta_{O}(i), S_{N}}\tilde{a}_{S_N}^{s}
\end{eqnarray}
\item $k \in \hat{N} \cap O$:
\begin{eqnarray}
  (A_{B}^{-1}\tilde{A}_{k})_{x_{i}} &=&
  (A_{B}^{-1})_{x_{i}, B_{O} \cup B_{S}}\tilde{A}_{C \cup S_{B}, k}
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k} +
  (A_{B}^{-1})_{x_{i}, B_{S}}\tilde{A}_{S_{B}, k}
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k}
  \nonumber \\  
  &=&
  \left(\check{A}_{B}^{-1}\right)_{\beta_{O}(i)}\tilde{A}_{C,k} 
\end{eqnarray}
\end{enumerate}

\paragraph{$\mathbf{i \in B_{S}}$:}
Assuming $i \in B_{S}$ we distinguish
according to Equations~(\ref{eq:A_B_inv_exp})
and the definition of $\tilde{p}_{x_{i}}^{(L)}(\varepsilon, B)$
the following cases for $k \in \hat{N}$:
\begin{enumerate}
\item $k \in \hat{N} \cap S$:
\begin{eqnarray}
  (A_{B}^{-1}\tilde{A}_{k})_{x_{i}} &=& 
  (A_{B}^{-1})_{x_{i}, B_{O} \cup B_{S}}\tilde{A}_{C \cup S_{B}, k}
  \nonumber \\
  &=& 
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k} +
  (A_{B}^{-1})_{x_{i}, B_{S}}\tilde{A}_{S_{B}, k}
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k}
  \nonumber \\ 
  &=&
  -\left(\alpha\check{A}_{B}^{-1}\right)_{\beta_{S}(i)}\tilde{A}_{C, k}
  \nonumber \\
  &=&
  -\left(\alpha\check{A}_{B}^{-1}\right)_{\beta_{S}(i), \gamma_{C}(\sigma(k))}
  \tilde{A}_{\sigma(k), k}
  \nonumber \\
  &=&
  -\left(\alpha\right)_{\beta_{S}(i)}
  \left(\check{A}_{B}^{-1}\right)_{\bullet, \gamma_{C}(\sigma(k))}
  \tilde{A}_{\sigma(k), k}
  \nonumber
\end{eqnarray}
Using Equation~(\ref{eq:alpha_beta_S}) we obtain
\begin{equation}
(A_{B}^{-1}\tilde{A}_{k})_{x_{i}} =
  -\tilde{A}_{\sigma(i), i}\tilde{A}_{\sigma(i), B_{O}}
  \left(\check{A}_{B}^{-1}\right)_{\bullet, \gamma_{C}(\sigma(k))}
  \tilde{A}_{\sigma(k), k}
\end{equation}

\item $k \in \hat{N} \cap art \setminus \{\tilde{a}^{s}\}$:
\begin{eqnarray}
  (A_{B}^{-1}\tilde{A}_{k})_{x_{i}} &=& 
  (A_{B}^{-1})_{x_{i}, B_{O} \cup B_{S}}\tilde{A}_{C \cup S_{B}, k}
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k} +
  (A_{B}^{-1})_{x_{i}, B_{S}}\tilde{A}_{S_{B}, k} 
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k}
  \nonumber \\ 
  &=&
  -\left(\alpha\check{A}_{B}^{-1}\right)_{\beta_{S}(i)}\tilde{A}_{C, k}
  \nonumber \\
  &=&
  -\left(\alpha\check{A}_{B}^{-1}\right)_{\beta_{S}(i), \gamma_{C}(\sigma(k))}
  \tilde{A}_{\sigma(k), k}
  \nonumber \\
  &=&
  -\left(\alpha\right)_{\beta_{S}(i)}
  \left(\check{A}_{B}^{-1}\right)_{\bullet, \gamma_{C}(\sigma(k))}
  \tilde{A}_{\sigma(k), k}
  \nonumber
\end{eqnarray}
Using Equation~(\ref{eq:alpha_beta_S}) we obtain
\begin{equation}
(A_{B}^{-1}\tilde{A}_{k})_{x_{i}} =
  -\tilde{A}_{\sigma(i), i}\tilde{A}_{\sigma(i), B_{O}}
  \left(\check{A}_{B}^{-1}\right)_{\bullet, \gamma_{C}(\sigma(k))}
  \tilde{A}_{\sigma(k), k}
\end{equation}
\item $\tilde{A}_{k}=\tilde{a}^{s}$:
\begin{eqnarray}
  (A_{B}^{-1}\tilde{A}_{k})_{x_{i}} &=& 
  (A_{B}^{-1})_{x_{i}, B_{O} \cup B_{S}}\tilde{a}_{C \cup S_{B}}^{s}
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{a}_{C}^{s} +
  (A_{B}^{-1})_{x_{i}, B_{S}}\tilde{a}_{S_{B}}^{s}
  \nonumber \\
  &=&
  -(\alpha\check{A}_{B}^{-1})_{\beta_{S}(i)}\tilde{a}_{C}^{s} +
  (A_{S_{B}, B_{S}}^{T})_{\beta_{S}(i)}\tilde{a}_{S_{B}}^{s}
  \nonumber \\ 
  &=&
  -(\alpha\check{A}_{B}^{-1})_{\beta_{S}(i), E}\tilde{a}_{E}^{s}
  -(\alpha\check{A}_{B}^{-1})_{\beta_{S}(i), S_{N}}\tilde{a}_{S_{N}}^{s}
  + \tilde{A}_{\sigma(i), i}\tilde{a}_{\sigma(i)}^{s}
  \nonumber \\
  &=&
  -(\alpha\check{A}_{B}^{-1})_{\beta_{S}(i), S_{N}}\tilde{a}_{S_{N}}^{s}
  + \tilde{A}_{\sigma(i), i}\tilde{a}_{\sigma(i)}^{s}
  \nonumber  
\end{eqnarray}
Using Equation~(\ref{eq:alpha_beta_S}) we obtain
\begin{equation}
(A_{B}^{-1}\tilde{A}_{k})_{x_{i}} =
-\tilde{A}_{\sigma(i), i}\tilde{A}_{\sigma(i), B_{O}}
\left(\check{A}_{B}^{-1}\right)_{\bullet, S_{N}}\tilde{a}_{S_{N}}^{s}
+\tilde{A}_{\sigma(i), i}\tilde{a}_{\sigma(i)}^{s} 
\end{equation}
\item $k \in \hat{N} \cap O$:
\begin{eqnarray}
  (A_{B}^{-1}\tilde{A}_{k})_{x_{i}} &=& 
  (A_{B}^{-1})_{x_{i}, B_{O} \cup B_{S}}\tilde{A}_{C \cup S_{B}, k}
  \nonumber \\
  &=&
  (A_{B}^{-1})_{x_{i}, B_{O}}\tilde{A}_{C, k} +
  (A_{B}^{-1})_{x_{i}, B_{S}}\tilde{A}_{S_{B}, k}
  \nonumber \\
  &=&
  -(\alpha\check{A}_{B}^{-1})_{\beta_{S}(i)}\tilde{A}_{C, k}
  + (A_{S_{B}, B_{S}}^{T})_{\beta_{S}(i)}\tilde{A}_{S_{B}, k}
  \nonumber \\
  &=&
  -\left(\alpha\right)_{\beta_{S}(i)}\check{A}_{B}^{-1}\tilde{A}_{C,k}
  +\tilde{A}_{\sigma(i),i}\tilde{A}_{\sigma(i),k}
  \nonumber
\end{eqnarray}
Using Equation~(\ref{eq:alpha_beta_S}) we obtain
\begin{equation}
  (A_{B}^{-1}\tilde{A}_{k})_{x_{i}} =
  -\tilde{A}_{\sigma(i), i}\tilde{A}_{\sigma(i), B_{O}}
  \check{A}_{B}^{-1}\tilde{A}_{C, k}
  +\tilde{A}_{\sigma(i), i}\tilde{A}_{\sigma(i), k}
\end{equation}
\end{enumerate}

\subsection{PhaseII}
According to Sections~\ref{sec:Ties_ratio_test_step_1}
and~\ref{sec:Ties_ratio_test_step_2} we have in the QP-case
to consider the polynomials $p_{x_{i}}^{(Q_{1})}(\varepsilon, B)$,
\pmu{Q_{1}}{B} and
$p_{x_{i}}^{(Q_{2})}(\varepsilon, \hat{B})$ as well as
\pmu{Q_{2}^{(0)}}{\hat{B}} and \pmu{Q_{2}^{(+)}}{\hat{B}} in light of
Equation~(\ref{eq:M_B_inv_exp}). The LP-case in phaseII can be omitted,
since only LP-type ties can occur in the LP-case
and these have already been treated in the last section. 

\subsubsection{Ratio Test Step 1:
$p_{x_{i}}^{(Q_{1})}(\varepsilon, B)$}
For ease of reference, we restate the Definition~(\ref{def:p_x_i_Q_1}),
of $p_{x_{i}}^{(Q_{1})}(\varepsilon, B)$
\begin{eqnarray*}
p_{x_{i}}^{(Q_{1})}\left(\varepsilon, B\right) &:=&
  \frac{\varepsilon^{i} -
         \left(M_{B}^{-1}
           \left(\begin{array}{c}
                    A_{N}  \\
	            \hline
	            2D_{B, N}
	         \end{array}
	   \right)
         \right)_{x_{i}}\epsilon_{N}}{q_{x_{i}}}
\\
&=&
\frac{\varepsilon^{i} -
         \left(M_{B}^{-1}
           \left(\begin{array}{c}
                    A_{\hat{N}}  \\
	            \hline
	            2D_{B, \hat{N}}
	         \end{array}
	   \right)
         \right)_{x_{i}}\epsilon_{\hat{N}}}{q_{x_{i}}}
+ \varepsilon^{j}
\end{eqnarray*}
Again, we will only consider the coefficients
$\varepsilon^{k}$ for $k \in \hat{N}= N \setminus \{j\}$ in
$p_{x_{i}}^{(Q_{1})}(\varepsilon, B)$, since the other cases $k=j$ and $k \in B$
are trivial. Furthermore we only evaluate entities that are not evaluated in the
unperturbed problem, such that, taking into account the
Definition~(\ref{def:epsilon}) of $\epsilon$, we merely consider
the subexpression
\begin{equation}
\label{def:e_x_i_Q_1}
e_{x_{i}}^{(Q_{1})}(B):=
\left(M_{B}^{-1}
           \left(\begin{array}{c}
                    A_{\hat{N}}  \\
	            \hline
	            2D_{B, \hat{N}}
	         \end{array}
	   \right)
         \right)_{x_{i}}
\end{equation}
The correct value of the coefficient is obtained by scaling the subexpression
with the factor $q_{x_{i}}^{-1}$.
According to Equation~(\ref{eq:M_B_inv_exp}) and the definition of
$p_{x_{i}}^{(Q_{1})}(\varepsilon, B)$ we distinguish $i \in B_{O}$ and
$i \in B_{S}$.

\paragraph{$\mathbf{i \in B_{O}}$:}
Assuming $i \in B_{O}$ we distinguish
according to Definition of $p_{x_{i}}^{(Q_{1})}(\varepsilon, B)$
the following cases for $k \in \hat{N}$:
\begin{enumerate}
\item $k \in \hat{N} \cap S$:
\begin{eqnarray}
\label{eq:r1_i_B_O_k_N_S}
\lefteqn{\left(M_{B}^{-1}
           \left(\begin{array}{c}
                   A_{k} \\
	           \hline
	           2D_{B, k}
	         \end{array}
           \right)
         \right)_{x_{i}}
=} \nonumber \\
&&
\left(M_{B}^{-1}\right)_{x_{i}, C \cup S_{B}}A_{C \cup S_{B}, k}
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{O} \cup B_{S}}D_{B_{O} \cup B_{S}, k}
\nonumber \\
&=&
\left(M_{B}^{-1}\right)_{x_{i}, C}A_{C, k}
+\left(M_{B}^{-1}\right)_{x_{i}, S_{B}}A_{S_{B}, k}
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{O}}D_{B_{O}, k}
\nonumber \\
&&
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{S}}D_{B_{S}, k}
\nonumber \\
&&\begin{minipage}{9cm}
because of $\left(M_{B}^{-1}\right)_{B_{O}, S_{B}}=0$, $D_{B_{O}, k}=0$
for $k \in N \cap S$ and $D_{B_{S},k}=0$ this yields 
\end{minipage}
\nonumber \\
&=&
\left(M_{B}^{-1}\right)_{x_{i}, C}A_{C, k}
\nonumber \\
&=&
\left(\check{M}_{B}^{-1}\right)_{\beta_{O}(i)}A_{C, k}
\nonumber \\
&=&
\left(\check{M}_{B}^{-1}\right)_{\beta_{O}(i), \gamma_{C}(\sigma(k))}
  A_{\sigma(k), k}
\end{eqnarray}

\item $k \in \hat{N} \cap O$:
\begin{eqnarray}
\label{eq:r1_i_B_O_k_N_O}
\lefteqn{\left(M_{B}^{-1}
           \left(\begin{array}{c}
                   A_{k} \\
	           \hline
	           2D_{B, k}
	         \end{array}
           \right)
         \right)_{x_{i}}
=} \nonumber \\
&&
\left(M_{B}^{-1}\right)_{x_{i}, C \cup S_{B}}A_{C \cup S_{B}, k}
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{O} \cup B_{S}}D_{B_{O} \cup B_{S}, k}
\nonumber \\
&=&
\left(M_{B}^{-1}\right)_{x_{i}, C}A_{C, k}
+\left(M_{B}^{-1}\right)_{x_{i}, S_{B}}A_{S_{B}, k}
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{O}}D_{B_{O}, k}
\nonumber \\
&&
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{S}}D_{B_{S}, k}
\nonumber \\
&&\begin{minipage}{9cm}
because of $\left(M_{B}^{-1}\right)_{B_{O}, S_{B}}=0$ and
$D_{B_{S},k}=0$ this yields 
\end{minipage}
\nonumber \\
&=&
\left(M_{B}^{-1}\right)_{x_{i}, C}A_{C, k}
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{O}}D_{B_{O}, k}
\nonumber \\
&=&
\left(\check{M}_{B}^{-1}\right)_{\beta_{O}(i)}A_{C,k}
+2\left(\check{M}_{B}^{-1}\right)_{\beta_{O}(i)}D_{B_{O}, k}
\nonumber \\
&=&
\left(\check{M}_{B}^{-1}\right)_{\beta_{O}(i)}
\left(\begin{array}{c}
        A_{C, k} \\
	\hline
	2D_{B_{O}, k}
      \end{array}
\right)
\end{eqnarray}
\end{enumerate}


\paragraph{$\mathbf{i \in B_{S}}$:}
Assuming $i \in B_{S}$ we distinguish
according to Definition of $p_{x_{i}}^{(Q_{1})}(\varepsilon, B)$
the following two cases for $k \in \hat{N}$:

\begin{enumerate}
\item $k \in \hat{N} \cap S$:
\begin{eqnarray}
\label{eq:r1_i_B_S_k_N_S}
\lefteqn{\left(M_{B}^{-1}
           \left(\begin{array}{c}
                   A_{k} \\
	           \hline
	           2D_{B, k}
	         \end{array}
           \right)
         \right)_{x_{i}}
=} \nonumber \\
&&
\left(M_{B}^{-1}\right)_{x_{i}, C \cup S_{B}}A_{C \cup S_{B}, k}
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{O} \cup B_{S}}D_{B_{O} \cup B_{S}, k}
\nonumber \\
&=&
\left(M_{B}^{-1}\right)_{x_{i}, C}A_{C, k}
+\left(M_{B}^{-1}\right)_{x_{i}, S_{B}}A_{S_{B}, k}
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{O}}D_{B_{O}, k}
\nonumber \\
&&
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{S}}D_{B_{S}, k}
\nonumber \\
&&\begin{minipage}{9cm}
because of $A_{S_{B},k}=0$ and $D_{B_{O}, k}=0$ for
$k \in N \cap S$ and $D_{B_{S}, k}=0$ this yields
\end{minipage}
\nonumber \\
&=&
\left(M_{B}^{-1}\right)_{x_{i}, C}A_{C, k}
\nonumber \\
&=&
\left(\check{M}_{B}^{-1}\right)_{\beta_{S}(i)}A_{C, k}
\nonumber \\
&=&
\left(\check{M}_{B}^{-1}\right)_{\beta_{S}(i), \gamma_{C}(\sigma(k))}
  A_{\sigma(k), k}
\end{eqnarray}

\item $k \in \hat{N} \cap O$:
\begin{eqnarray}
\lefteqn{\left(M_{B}^{-1}
           \left(\begin{array}{c}
                   A_{k} \\
	           \hline
	           2D_{B, k}
	         \end{array}
           \right)
         \right)_{x_{i}}
=} \nonumber \\
&&
\left(M_{B}^{-1}\right)_{x_{i}, C \cup S_{B}}A_{C \cup S_{B}, k}
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{O} \cup B_{S}}D_{B_{O} \cup B_{S}, k}
\nonumber \\
&=&
\left(M_{B}^{-1}\right)_{x_{i}, C}A_{C, k}
+\left(M_{B}^{-1}\right)_{x_{i}, S_{B}}A_{S_{B}, k}
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{O}}D_{B_{O}, k}
\nonumber \\
&&
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{S}}D_{B_{S}, k}
\nonumber \\
&&\begin{minipage}{8cm}
because of $D_{B_{S}, k}=0$ this yields
\end{minipage}
\nonumber \\
&=&
\left(M_{B}^{-1}\right)_{x_{i}, C}A_{C, k}
+\left(M_{B}^{-1}\right)_{x_{i}, S_{B}}A_{S_{B}, k}
+2\left(M_{B}^{-1}\right)_{x_{i}, B_{O}}D_{B_{O}, k}
\nonumber \\
&=&
\left(\alpha\left(\check{M}_{B}^{-1}\right)_{B_{O}, C}\right)_{\beta_{S}(i)}
  A_{C, k}
+\left(A_{S_{B}, B_{S}}^{T}\right)_{\beta_{S}(i)}A_{S_{B},k}
\nonumber \\
&&
+2\left(\alpha\left(\check{M}_{B}^{-1}\right)_{B_{O}, B_{O}}\right)_{
  \beta_{S}(i)}D_{B_{O},k}
\nonumber \\
&=&
\left(\alpha\right)_{\beta_{S}(i)}\left(\check{M}_{B}^{-1}\right)_{B_{O}, C}
  A_{C, k}
+2\left(\alpha\right)_{\beta_{S}(i)}\left(\check{M}_{B}^{-1}\right)_{B_{O},
  B_{O}}D_{B_{O}, k}
\nonumber \\
&&
+A_{\sigma(i), i}A_{\gamma_{S_{B}}(\sigma(i)), k}
\nonumber \\
&=&
\left(\alpha\right)_{\beta_{S}(i)}\left(\check{M}_{B}^{-1}\right)_{B_{O},
  C \cup B_{O}}
\left(\begin{array}{c}
        A_{C,k} \\
	\hline
	2D_{B_{O},k}
       \end{array}
\right)
+A_{\sigma(i), i}A_{\gamma_{S_{B}}(\sigma(i)), k}
\nonumber
\end{eqnarray}
Using Equation~(\ref{eq:alpha_beta_S}) we obtain
\begin{eqnarray}
\label{eq:r1_i_B_S_k_N_O}
\left(M_{B}^{-1}
           \left(\begin{array}{c}
                   A_{k} \\
	           \hline
	           2D_{B, k}
	         \end{array}
           \right)
\right)_{x_{i}}
&=&
-A_{\sigma(i),i}A_{\sigma(i), B_{O}}\left(\check{M}_{B}^{-1}\right)_{B_{O},
  C \cup B_{O}}
\left(\begin{array}{c}
        A_{C,k} \\
	\hline
	2D_{B_{O},k}
       \end{array}
\right)
\nonumber \\
&&
+A_{\sigma(i), i}A_{\gamma_{S_{B}}(\sigma(i)), k}
\end{eqnarray}
\end{enumerate}

\subsubsection{Ratio Test Step 1:
\pmu{Q_{1}}{B}}
For ease of reference, we restate the Definition~(\ref{def:p_mu_j_Q_1}),
of \pmu{Q_{1}}{B}
\begin{eqnarray*}
\pmu{Q_{1}}{B} &:=& 
  -\frac{2D_{j, \hat{N}} -
    \left(A_{j}^{T} \left| \right. 2D_{B, j}^{T} \right)
    M_{B}^{-1}
    \left(\begin{array}{c}
            A_{\hat{N}} \\
	    \hline
	    2D_{B,\hat{N}}
	  \end{array}
    \right)}{\nu}
  \epsilon_{\hat{N}}
  +\varepsilon^{j}
\\
&=&
  -\frac{2D_{j, \hat{N}} -
    \left(q_{\lambda}^{T} \left| \right. q_{x}^{T} \right)
    \left(\begin{array}{c}
            A_{\hat{N}} \\
	    \hline
	    2D_{B,\hat{N}}
	  \end{array}
    \right)}{\nu}
  \epsilon_{\hat{N}}
  +\varepsilon^{j}
\end{eqnarray*}
Again, we will only consider the coefficients
$\varepsilon^{k}$ for $k \in \hat{N}= N \setminus \{j\}$ in
\pmu{Q_{1}}{B}, since the other cases $k=j$ and $k \in B$
are trivial. Furthermore we only evaluate entities that are not evaluated in the
unperturbed problem, such that, taking into account the
Definition~(\ref{def:epsilon}) of $\epsilon$
and the fact that $j$ and $B$ remain constant during an iteration of Ratio Test
Step~1 of a given pivot step, 
we merely consider the subexpression
\begin{equation}
\label{def:e_mu_j_Q_1}
e_{\mu_{j}}^{(Q_{1})}(B):=
2D_{j, \hat{N}} -
    \left(q_{\lambda}^{T} \left| \right. q_{x}^{T} \right)
    \left(\begin{array}{c}
            A_{\hat{N}} \\
	    \hline
	    2D_{B,\hat{N}}
	  \end{array}
    \right)
\end{equation}
The correct value of the coefficient is obtained by scaling the subexpression
with the factor $\nu^{-1}$.
We shall first compute the different components of
$\left(q_{\lambda}^{T} \left|\right. q_{x}^{T}\right)$ in terms of
$\check{M}_{B}^{-1}$.

\begin{eqnarray}
\label{eq:q_C}
q_{\lambda_{C}}
&=&
\left(M_{B}^{-1}\right)_{C,C}A_{C,j}
+\left(M_{B}^{-1}\right)_{C, S_{B}}A_{S_{B}, j}
+2\left(M_{B}^{-1}\right)_{C, B_{O}}D_{B_{O}, j}
\nonumber \\
&&
+2\left(M_{B}^{-1}\right)_{C, B_{S}}D_{B_{S}, j}
\nonumber \\
&&\begin{minipage}{8cm}
because of $D_{B_{S},j}=0$ and $\left(M_{B}^{-1}\right)_{C, S_{B}}=0$ this
yields
\end{minipage}
\nonumber \\
&=&
\left(\check{M}_{B}^{-1}\right)_{C,C}A_{C,j}
+2\left(\check{M}_{B}^{-1}\right)_{C, B_{O}}D_{B_{O}, j}
\nonumber \\
&=&
\left(\check{M}_{B}^{-1}\right)_{C}
\left(\begin{array}{c}
        A_{C, j} \\
	\hline
	2D_{B_{O}, j}
      \end{array}
\right)       
\end{eqnarray}

\begin{eqnarray}
q_{\lambda_{S_{B}}}
&=&
\left(M_{B}^{-1}\right)_{S_{B},C}A_{S_{B},j}
+\left(M_{B}^{-1}\right)_{S_{B}, S_{B}}A_{S_{B}, j}
+2\left(M_{B}^{-1}\right)_{S_{B}, B_{O}}D_{B_{O}, j}
\nonumber \\
&&
+2\left(M_{B}^{-1}\right)_{S_{B}, B_{S}}D_{B_{S}, j}
\nonumber \\
&&\begin{minipage}{8cm}
because of $D_{B_{S},j}=0$ and $\left(M_{B}^{-1}\right)_{S_{B}, C}=0$,
$\left(M_{B}^{-1}\right)_{S_{B}, S_{B}}=0$ and 
$\left(M_{B}^{-1}\right)_{S_{B}, B_{O}}=0$
this yields
\end{minipage}
\nonumber \\
&=&
0
\end{eqnarray}

\begin{eqnarray}
\label{eq:q_B_O}
q_{x_{B_{O}}}
&=&
\left(M_{B}^{-1}\right)_{B_{O},C}A_{C,j}
+\left(M_{B}^{-1}\right)_{B_{O}, S_{B}}A_{S_{B}, j}
+2\left(M_{B}^{-1}\right)_{B_{O}, B_{O}}D_{B_{O}, j}
\nonumber \\
&&
+2\left(M_{B}^{-1}\right)_{B_{O}, B_{S}}D_{B_{S}, j}
\nonumber \\
&&\begin{minipage}{8cm}
because of $D_{B_{S},j}=0$ and $\left(M_{B}^{-1}\right)_{B_{O}, S_{B}}=0$,
this yields
\end{minipage}
\nonumber \\
&=&
\left(\check{M}_{B}^{-1}\right)_{B_{O}, C}A_{C,j}
+2\left(\check{M}_{B}^{-1}\right)_{B_{O}, B_{O}}D_{B_{O}, j}
\nonumber \\
&=&
\left(\check{M}_{B}^{-1}\right)_{B_{O}}
\left(\begin{array}{c}
        A_{C, j} \\
	\hline
	2D_{B_{O}, j}
      \end{array}
\right)       
\end{eqnarray}

\begin{eqnarray}
q_{x_{B_{S}}}
&=&
\left(M_{B}^{-1}\right)_{B_{S},C}A_{C,j}
+\left(M_{B}^{-1}\right)_{B_{S}, S_{B}}A_{S_{B}, j}
+2\left(M_{B}^{-1}\right)_{B_{S}, B_{O}}D_{B_{O}, j}
\nonumber \\
&&
+2\left(M_{B}^{-1}\right)_{B_{S}, B_{S}}D_{B_{S}, j}
\nonumber \\
&&\begin{minipage}{8cm}
because of $D_{B_{S},j}=0$ this yields
\end{minipage}
\nonumber \\
&=&
\alpha\left(\check{M}_{B}^{-1}\right)_{B_{O}, C}A_{C, j}
+A_{S_{B}, B_{S}}^{T}A_{S_{B}, j}
+2\alpha\left(\check{M}_{B}^{-1}\right)_{B_{O}, B_{O}}D_{B_{O},j}
\nonumber \\
&=&
\alpha\left(\check{M}_{B}^{-1}\right)_{B_{O}}
\left(\begin{array}{c}
        A_{C,j} \\
	\hline
	2D_{B_{O}, j}
       \end{array}
\right)
+A_{S_{B}, B_{S}}^{T}A_{S_{B}, j}
\nonumber
\end{eqnarray}
Using the definition of $\alpha$ and $q_{x_{B_{O}}}$ this can be written as
\begin{equation}
q_{x_{B_{S}}}=
A_{S_{B}, B_{S}}^{T}A_{S_{B}, B_{O}}q_{x_{B_{O}}}
+A_{S_{B}, B_{S}}^{T}A_{S_{B}, j}
\end{equation}
We are now enabled to compute the coefficients of
\begin{eqnarray}
    \left(A_{j}^{T} \left| \right. 2D_{B, j}^{T} \right)
    M_{B}^{-1}
    \left(\begin{array}{c}
            A_{\hat{N}} \\
	    \hline
	    2D_{B,\hat{N}}
	  \end{array}
    \right)
&=&
    \left(q_{\lambda}^{T} \left| \right. q_{x}^{T} \right)
    \left(\begin{array}{c}
            A_{\hat{N}} \\
	    \hline
	    2D_{B,\hat{N}}
	  \end{array}
    \right)
\nonumber \\
&=&
\left(q_{\lambda_{C}}^{T}\left|\right.
      q_{\lambda_{S_{B}}}^{T}\left|\right.
      q_{x_{B_{O}}}^{T}\left|\right.
      q_{x_{B_{S}}}^{T}
\right)
\left(\begin{array}{c}
        A_{C, \hat{N}} \\
	\hline
	A_{S_{B}, \hat{N}} \\
	\hline
	2D_{B_{O}, \hat{N}} \\
	\hline
	2D_{B_{S}, \hat{N}}
      \end{array}
\right)
\nonumber \\
&&\begin{minipage}{6cm}
because of $D_{B_{S}, \hat{N}}=0$ and $q_{\lambda_{S_{B}}}=0$ this yields
\end{minipage}
\nonumber \\
&=&
q_{\lambda_{C}}^{T}A_{C, \hat{N}} + 2q_{x_{B_{O}}}^{T}D_{B_{O},\hat{N}}
\nonumber \\
&=&
\left(q_{\lambda_{C}}^{T}\left|\right.q_{x_{B_{O}}}^{T}\right)
\left(\begin{array}{c}
        A_{C, \hat{N}} \\
	\hline
	2D_{B_{O}, \hat{N}}
      \end{array}
\right)                         
\end{eqnarray}
According to Equation~(\ref{eq:M_B_inv_exp}) and the definition of
\pmu{Q_{1}}{B} we distinguish $j \in O \cap N$ and
$j \in S \cap N$.
\paragraph{$\mathbf{j \in O \cap N}$:}
Assuming $j \in O \cap N$ we distinguish according to the definition of
\pmu{Q_{1}}{B} the following two cases for $k \in
\hat{N}$:
\begin{enumerate}
\item $k \in \hat{N} \cap O$:
\begin{eqnarray}
\label{eq:r1_j_O_N_k_N_O}
    2D_{j, k}
    -\left(q_{\lambda}^{T} \left| \right. q_{x}^{T} \right)
    \left(\begin{array}{c}
            A_{k} \\
	    \hline
	    2D_{B,k}
	  \end{array}
    \right)
&=&
2D_{j, k} - q_{\lambda_{C}}^{T}A_{C, k} - 2q_{x_{B_{O}}}^{T}D_{B_{O},k}
\nonumber \\
&=&
2D_{j, k}
-\left(q_{\lambda_{C}}^{T}\left|\right. q_{x_{B_{O}}}^{T}\right)
\left(\begin{array}{c}
        A_{C, k} \\
	\hline
	2D_{B_{O}, k}
      \end{array}
\right)
\end{eqnarray}
\item $k \in \hat{N} \cap S$:
\begin{eqnarray}
\label{eq:r1_j_O_N_k_N_S}
    2D_{j,k}
    -\left(q_{\lambda}^{T} \left| \right. q_{x}^{T} \right)
    \left(\begin{array}{c}
            A_{k} \\
	    \hline
	    2D_{B, k}
	  \end{array}
    \right)
&=&
2D_{j,k} - q_{\lambda_{C}}^{T}A_{C, k} - 2q_{x_{B_{O}}}^{T}D_{B_{O},k}
\nonumber \\
&&\begin{minipage}{5cm}
Because of $D_{B_{O},k}=0$, $D_{j,k}=0$ for $k \in \hat{N} \cap S$
\end{minipage}
\nonumber \\
&=&
-q_{\lambda_{C}}^{T}A_{C, k}
\nonumber \\
&=&
-\left(q_{\lambda_{C}}\right)_{\gamma_{C}(\sigma(k))}A_{\sigma(k),k}
\end{eqnarray}
\end{enumerate}

\paragraph{$\mathbf{j \in S \cap N}$:}
Assuming $j \in S \cap N$ we distinguish according to the definition of
\pmu{Q_{1}}{B} the following cases for $k \in \hat{N}$:
\begin{enumerate}
\item $k \in \hat{N} \cap O:$
\begin{eqnarray}
\label{eq:r1_j_S_N_k_N_O}
    2D_{j,k}
    -\left(q_{\lambda}^{T} \left| \right. q_{x}^{T} \right)
    \left(\begin{array}{c}
            A_{k} \\
	    \hline
	    2D_{B, k}
	  \end{array}
    \right)
&=&
2D_{j,k} - q_{\lambda_{C}}^{T}A_{C, k} - 2q_{x_{B_{O}}}^{T}D_{B_{O},k}
\nonumber \\
&&\begin{minipage}{5cm}
Because of $D_{j,k}=0$ for $j \in S \cap N$
\end{minipage}
\nonumber \\
&=&
- q_{\lambda_{C}}^{T}A_{C, k} - 2q_{x_{B_{O}}}^{T}D_{B_{O},k}
\nonumber \\
&=&
-\left(q_{\lambda_{C}}^{T}\left|\right. q_{x_{B_{O}}}^{T}\right)
\left(\begin{array}{c}
        A_{C,k} \\
	\hline
	2D_{B_{O},k}
      \end{array}
\right)
\end{eqnarray}

\item $k \in \hat{N} \cap S:$
\begin{eqnarray}
\label{eq:r1_j_S_N_k_N_S}
    2D_{j,k}
    -\left(q_{\lambda}^{T} \left| \right. q_{x}^{T} \right)
    \left(\begin{array}{c}
            A_{k} \\
	    \hline
	    2D_{B, k}
	  \end{array}
    \right)
&=&
2D_{j,k} - q_{\lambda_{C}}^{T}A_{C, k} - 2q_{x_{B_{O}}}^{T}D_{B_{O},k}
\nonumber \\
&&\begin{minipage}{5cm}
Because of $D_{B_{O},k}=0$, $D_{j,k}=0$ for $k \in \hat{N} \cap S$
\end{minipage}
\nonumber \\
&=&
-q_{\lambda_{C}}^{T}A_{C,k}
\nonumber \\
&=&
-\left(q_{\lambda_{C}}\right)_{\gamma_{C}(\sigma(k))}A_{\sigma(k),k}
\end{eqnarray}.
\end{enumerate}

\subsubsection{Ratio Test Step 2: \px{i}{Q_{2}}{\hat{B}}}
For ease of reference, we restate the Definition~(\ref{def:p_x_i_Q_2}),
of $p_{x_{i}}^{(Q_{2})}(\varepsilon, \hat{B})$
\begin{eqnarray*}
\px{i}{Q_{2}}{\hat{B}} &:=&
  \frac{\varepsilon^{i} -
         \left(M_{\hat{B}}^{-1}
           \left(\begin{array}{c}
                    A_{\hat{N}}  \\
	            \hline
	            2D_{\hat{B}, \hat{N}}
	         \end{array}
	   \right)
         \right)_{x_{i}}\epsilon_{\hat{N}}}{p_{x_{i}}}
\end{eqnarray*}
Again, we will only consider the coefficients
$\varepsilon^{k}$ for $k \in \hat{N}= N \setminus \{j\}$ in
\px{i}{Q_{2}}{\hat{B}}, since the other case $k \in \hat{B}$
is trivial. Furthermore we only evaluate entities that are not evaluated in the
unperturbed problem, such that, taking into account the
Definition~(\ref{def:epsilon}) of $\epsilon$, 
we merely consider the subexpression
\begin{equation*}
\left(
  M_{\hat{B}}^{-1}
  \left(\begin{array}{c}
          A_{\hat{N}}  \\
          \hline
          2D_{\hat{B}, \hat{N}}
        \end{array}
  \right)
\right)_{x_{i}}
\end{equation*}
The correct value of the coefficient is obtained by scaling the subexpression
with the factor $p_{x_{i}}^{-1}$.
Since the above subexpression and the corresponding subexpression
in~(\ref{def:e_x_i_Q_1}) for the polynomial \px{i}{Q_{1}}{B} as
functions differ only in the sets $B$ and $\hat{B}$ and their respective
headings, we list the expressions without their derivations.

According to Equation~(\ref{eq:M_B_inv_exp}) and the definition of
\px{i}{Q_{2}}{\hat{B}} we distinguish $i \in \hat{B}_{O}$ and
$i \in \hat{B}_{S}$.
  
\paragraph{$\mathbf{i \in \hat{B}_{O}}$:}
\begin{enumerate}
\item $k \in \hat{N} \cap S$:
According to Equation~(\ref{eq:r1_i_B_O_k_N_S}) and the appropriate changes
neccessary we obtain
\begin{equation}
\label{eq:r2_i_B_O_k_N_S}
\left(
  M_{\hat{B}}^{-1}
  \left(\begin{array}{c}
          A_{k} \\
	  \hline
	  2D_{\hat{B}, k}
	\end{array}
  \right)
\right)_{x_{i}}
=
\left(\check{M}_{\hat{B}}^{-1}\right)_{\hat{\beta}_{O}(i),
\hat{\gamma}_{\hat{C}}(\sigma(k))}
A_{\sigma(k), k}
\end{equation}
\item $k \in \hat{N} \cap O$:
According to Equation~(\ref{eq:r1_i_B_O_k_N_O}) and the appropriate changes
neccessary we obtain
\begin{equation}
\label{eq:r2_i_B_O_k_N_O}
\left(
  M_{\hat{B}}^{-1}
  \left(\begin{array}{c}
          A_{k} \\
	  \hline
	  2D_{\hat{B}, k}
	\end{array}
  \right)
\right)_{x_{i}}
=
\left(\check{M}_{\hat{B}}^{-1}\right)_{\hat{\beta}_{O}(i)}
\left(\begin{array}{c}
        A_{\hat{C}, k} \\
	\hline
	2D_{\hat{B}_{O}, k}
      \end{array}
\right)
\end{equation}
\end{enumerate}

\paragraph{$\mathbf{i \in \hat{B}_{S}}$:}
\begin{enumerate}
\item $k \in \hat{N} \cap S$:
According to Equation~(\ref{eq:r1_i_B_S_k_N_S}) and the appropriate changes
neccessary we obtain
\begin{equation}
\label{eq:r2_i_B_S_k_N_S}
\left(
  M_{\hat{B}}^{-1}
  \left(\begin{array}{c}
          A_{k} \\
	  \hline
	  2D_{\hat{B}, k}
	\end{array}
  \right)
\right)_{x_{i}}
=
\left(\check{M}_{\hat{B}}^{-1}\right)_{\hat{\beta}_{S}(i),
\hat{\gamma}_{\hat{C}}(\sigma(k))}
  A_{\sigma(k), k}
\end{equation}
\item $k \in \hat{N} \cap O$:
According to Equation~(\ref{eq:r1_i_B_S_k_N_O}) and the appropriate changes
neccessary we obtain
\begin{eqnarray}
\label{eq:r2_i_B_S_k_N_O}
\left(
  M_{\hat{B}}^{-1}
  \left(\begin{array}{c}
          A_{k} \\
	  \hline
	  2D_{\hat{B}, k}
	\end{array}
  \right)
\right)_{x_{i}}
&=&
-A_{\sigma(i),i}A_{\sigma(i), \hat{B}_{O}}
\left(\check{M}_{\hat{B}}^{-1}\right)_{\hat{B}_{O}}
\left(\begin{array}{c}
        A_{\hat{C},k} \\
	\hline
	2D_{\hat{B}_{O},k}
       \end{array}
\right)
\nonumber \\
&&
+A_{\sigma(i), i}A_{\hat{\gamma}_{S_{\hat{B}}}(\sigma(i)), k}
\end{eqnarray}
\end{enumerate}

\subsubsection{Ratio Test Step 2:
\pmu{Q_{2}^{(0)}}{\hat{B}}}
For ease of reference, we restate the Definition~(\ref{def:p_mu_j_Q_2_0}),
of \pmu{Q_{2}^{(0)}}{\hat{B}}

\begin{eqnarray}
\pmu{Q_{2}^{(0)}}{\hat{B}} &:=& 
  \left[
      2D_{j, \tilde{N} \setminus \{j\}} 
        -\left(A_{j}^{T} \left| \right. 2D_{\tilde{B}, j}^{T}
        \right)
      M_{\tilde{B}}^{-1}
      \left(\begin{array}{c}
              A_{\tilde{N} \setminus \{j\}} \\
	      \hline
	      2D_{\tilde{B}, \tilde{N} \setminus \{j\}}
	    \end{array}
      \right)
   \right]\epsilon_{\tilde{N} \setminus \{j\}} +
\nonumber \\ 
  &&
  \frac{\varepsilon^{l} -
         \left(M_{\tilde{B}}^{-1}
           \left(\begin{array}{c}
                    A_{\tilde{N} \setminus \{j\}}  \\
	            \hline
	            2D_{\tilde{B}, \tilde{N} \setminus \{j\}}
	         \end{array}
	   \right)
         \right)_{x_{l}}\epsilon_{\tilde{N} \setminus \{j\}}}
        {\tilde{q}_{x_{l}}}\tilde{\nu}
\nonumber \\
&=&
  \left[
      2D_{j, \tilde{N} \setminus \{j\}}
      - \left(\tilde{q}_{\lambda}^{T} \left| \right. \tilde{q}_{x}^{T}\right)
      \left(\begin{array}{c}
              A_{\tilde{N} \setminus \{j\}} \\
	      \hline
	      2D_{\tilde{B}, \tilde{N} \setminus \{j\}}
	    \end{array}
      \right)
   \right]\epsilon_{\tilde{N} \setminus \{j\}} +
\nonumber \\ 
  &&
  \frac{\varepsilon^{l} -
         \left(M_{\tilde{B}}^{-1}
           \left(\begin{array}{c}
                    A_{\tilde{N} \setminus \{j\}}  \\
	            \hline
	            2D_{\tilde{B}, \tilde{N} \setminus \{j\}}
	         \end{array}
	   \right)
         \right)_{x_{l}}\epsilon_{\tilde{N} \setminus \{j\}}}
	{\tilde{q}_{x_{l}}}\tilde{\nu}
\nonumber \\
&=&
  \left[
      2D_{j, \tilde{N} \setminus \{j\}}
      -\left(
         \left(\tilde{q}_{\lambda}^{T} \left| \right. \tilde{q}_{x}^{T}\right)
         + \frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
	 \left(M_{\tilde{B}}^{-1}\right)_{x_{l}}
       \right)
      \left(\begin{array}{c}
              A_{\tilde{N} \setminus \{j\}} \\
	      \hline
	      2D_{\tilde{B}, \tilde{N} \setminus \{j\}}
	    \end{array}
      \right)
   \right]\epsilon_{\tilde{N} \setminus \{j\}} +
\nonumber \\
  &&
\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}\varepsilon^{l}
\end{eqnarray}
Since the coefficients of \pmu{Q_{2}^{(0)}}{\hat{B}} depend on
the last basis $\tilde{B}$ and its headings in the Ratio Test Step~1 we need
to store these coefficients in case we need to resolve a tie between basic
variables and $\mu_{j}$ becoming zero in Ratio Test Step~2.
Again, we will only consider the coefficients
$\varepsilon^{k}$ for $k \in \hat{N}= N \setminus \{j\}$ in
\pmu{Q_{2}^{(0)}}{\hat{B}}, since the other case $k \in \hat{B}$
is trivial. Furthermore we only evaluate entities that are not evaluated in the
unperturbed problem, such that, taking into account the
Definition~(\ref{def:epsilon}) of $\epsilon$, 
we merely consider the subexpression
\begin{equation*}
-2D_{j, \hat{N}}
+\left(
   \left(\tilde{q}_{\lambda}^{T} \left| \right. \tilde{q}_{x}^{T}\right)
     + \frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
     \left(M_{\tilde{B}}^{-1}\right)_{x_{l}}
   \right)
   \left(\begin{array}{c}
              A_{\hat{N}} \\
	      \hline
	      2D_{\tilde{B}, \hat{N}}
	 \end{array}
   \right)
=
-e_{\mu_{j}}^{(Q_{1})}(\tilde{B})
+\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}e_{x_{l}}^{(Q_{1})}(\tilde{B})
\end{equation*}
as a linear combination of $e_{\mu_{j}}^{(Q_{1})}(\tilde{B})$ and
$e_{x_{l}}^{(Q_{1})}(\tilde{B})$ defined by
Definitions~(\ref{def:e_mu_j_Q_1}) and~(\ref{def:e_x_i_Q_1}).
According to the Definition of
\pmu{Q_{2}^{(0)}}{\hat{B}} we distinguish $j \in O \cap \tilde{N}$
and $j \in S \cap \tilde{N}$ as well as $l \in \tilde{B}_{O}$ and
$l \in \tilde{B}_{S}$.

\paragraph{$\mathbf{l \in \tilde{B}_{O} \wedge j \in O \cap \tilde{N}}$:}
\begin{enumerate}
\item $k \in \tilde{N} \cap S$:
According to Equations~(\ref{eq:r1_j_O_N_k_N_S})
and~(\ref{eq:r1_i_B_O_k_N_S}) and the appropriate changes neccessary we obtain
\begin{eqnarray}
\lefteqn{
2D_{j,k}-\left(
          \left(\tilde{q}_{\lambda}^{T}\left|\right. \tilde{q}_{x}^{T}\right)
	  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
	  \left(M_{\tilde{B}}^{-1}\right)_{x_{l}}
	\right)
\left(\begin{array}{c}
        A_{k} \\
	\hline
	2D_{\tilde{B},k}
      \end{array}
\right)
=}
\nonumber \\
&&
-\left(\tilde{q}_{\lambda_{\tilde{C}}}\right)_{\tilde{\gamma}_{\tilde{C}}
 (\sigma(k))}A_{\sigma(k),k}
-\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
 \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{O}(l),
 \tilde{\gamma}_{\tilde{C}}(\sigma(k))}A_{\sigma(k), k}
\nonumber \\
&=&
-\left(
  \left(\tilde{q}_{\lambda_{\tilde{C}}}\right)_{\tilde{\gamma}_{\tilde{C}}
  (\sigma(k))}
  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
   \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{O}(l),
   \tilde{\gamma}_{\tilde{C}}(\sigma(k))}
\right)
A_{\sigma(k), k}
\end{eqnarray}

\item $k \in \tilde{N} \cap O$:
According to Equations~(\ref{eq:r1_j_O_N_k_N_O})
and~(\ref{eq:r1_i_B_O_k_N_O}) and the appropriate changes neccessary we obtain
\begin{eqnarray}
\lefteqn{
2D_{j,k}-\left(
          \left(\tilde{q}_{\lambda}^{T}\left|\right. \tilde{q}_{x}^{T}\right)
	  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
	  \left(M_{\tilde{B}}^{-1}\right)_{x_{l}}
	\right)
\left(\begin{array}{c}
        A_{k} \\
	\hline
	2D_{\tilde{B},k}
      \end{array}
\right)
=}
\nonumber \\
&&
2D_{j, k}
-\left(\tilde{q}_{\lambda_{\tilde{C}}}^{T}\left|\right.
  \tilde{q}_{x_{\tilde{B}_{O}}}^{T}\right)
\left(\begin{array}{c}
        A_{\tilde{C}, k} \\
	\hline
	2D_{\tilde{B}_{O}, k}
      \end{array}
\right)
-\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
\left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{O}(l)}
\left(\begin{array}{c}
        A_{\tilde{C}, k} \\
	\hline
	2D_{\tilde{B}_{O}, k}
      \end{array}
\right)
\nonumber \\
&=&
2D_{j, k}
-\left(
  \left(\tilde{q}_{\lambda_{\tilde{C}}}^{T}\left|\right.
  \tilde{q}_{x_{\tilde{B}_{O}}}^{T}\right)
  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
  \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{O}(l)}
\right)
\left(\begin{array}{c}
        A_{\tilde{C}, k} \\
	\hline
	2D_{\tilde{B}_{O}, k}
      \end{array}
\right) 
\end{eqnarray}
\end{enumerate}

\paragraph{$\mathbf{l \in \tilde{B}_{O} \wedge j \in S \cap \tilde{N}}$:}
\begin{enumerate}
\item $k \in \tilde{N} \cap S$:
According to Equations~(\ref{eq:r1_j_S_N_k_N_S})
and~(\ref{eq:r1_i_B_O_k_N_S}) and the appropriate changes neccessary we obtain
\begin{eqnarray}
\lefteqn{
2D_{j,k}-\left(
          \left(\tilde{q}_{\lambda}^{T}\left|\right. \tilde{q}_{x}^{T}\right)
	  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
	  \left(M_{\tilde{B}}^{-1}\right)_{x_{l}}
	\right)
\left(\begin{array}{c}
        A_{k} \\
	\hline
	2D_{\tilde{B},k}
      \end{array}
\right)
=}
\nonumber \\
&&
-\left(\tilde{q}_{\lambda_{\tilde{C}}}\right)_{\tilde{\gamma}_{\tilde{C}}
  (\sigma(k))}A_{\sigma(k),k}
-\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
 \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{O}(l),
 \tilde{\gamma}_{\tilde{C}}(\sigma(k))}
  A_{\sigma(k), k}
\nonumber \\
&=&
-\left(
 \left(\tilde{q}_{\lambda_{\tilde{C}}}\right)_{\tilde{\gamma}_{\tilde{C}}
 (\sigma(k))}
+\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
 \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{O}(l),
 \tilde{\gamma}_{\tilde{C}}(\sigma(k))}
\right)
A_{\sigma(k), k}
\end{eqnarray}

\item $k \in \tilde{N} \cap O$:
According to Equations~(\ref{eq:r1_j_S_N_k_N_O})
and~(\ref{eq:r1_i_B_O_k_N_O}) and the appropriate changes neccessary we obtain
\begin{eqnarray}
\lefteqn{
2D_{j,k}-\left(
          \left(\tilde{q}_{\lambda}^{T}\left|\right. \tilde{q}_{x}^{T}\right)
	  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
	  \left(M_{\tilde{B}}^{-1}\right)_{x_{l}}
	\right)
\left(\begin{array}{c}
        A_{k} \\
	\hline
	2D_{\tilde{B},k}
      \end{array}
\right)
=}
\nonumber \\
&&
-\left(\tilde{q}_{\lambda_{\tilde{C}}}^{T}\left|\right.
 \tilde{q}_{x_{\tilde{B}_{O}}}^{T}\right)
\left(\begin{array}{c}
        A_{\tilde{C},k} \\
	\hline
	2D_{\tilde{B}_{O},k}
      \end{array}
\right)
-\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
\left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{O}(l)}
\left(\begin{array}{c}
        A_{\tilde{C}, k} \\
	\hline
	2D_{\tilde{B}_{O}, k}
      \end{array}
\right)
\nonumber \\
&=&
-\left(
 \left(\tilde{q}_{\lambda_{\tilde{C}}}^{T}\left|\right.
  \tilde{q}_{x_{\tilde{B}_{O}}}^{T}\right)
+\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
\left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{O}(l)}
\right)
\left(\begin{array}{c}
        A_{\tilde{C}, k} \\
	\hline
	2D_{\tilde{B}_{O}, k}
      \end{array}
\right)
\end{eqnarray}
\end{enumerate}

\paragraph{$\mathbf{l \in \tilde{B}_{S} \wedge j \in O \cap \tilde{N}}$:}
\begin{enumerate}
\item $k \in \tilde{N} \cap S$:
According to Equations~(\ref{eq:r1_j_O_N_k_N_S})
and~(\ref{eq:r1_i_B_S_k_N_S}) and the appropriate changes neccessary we obtain
\begin{eqnarray}
\lefteqn{
2D_{j,k}-\left(
          \left(\tilde{q}_{\lambda}^{T}\left|\right. \tilde{q}_{x}^{T}\right)
	  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
	  \left(M_{\tilde{B}}^{-1}\right)_{x_{l}}
	\right)
\left(\begin{array}{c}
        A_{k} \\
	\hline
	2D_{\tilde{B},k}
      \end{array}
\right)
=}
\nonumber \\
&&
-\left(\tilde{q}_{\lambda_{\tilde{C}}}\right)_{\tilde{\gamma}_{\tilde{C}}
  (\sigma(k))}A_{\sigma(k),k}
-\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
 \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{S}(l),
  \tilde{\gamma}_{\tilde{C}}(\sigma(k))}A_{\sigma(k), k}
\nonumber \\
&=&
-\left(
  \left(\tilde{q}_{\lambda_{\tilde{C}}}\right)_{\tilde{\gamma}_{\tilde{C}}
   (\sigma(k))}
  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
   \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{S}(l),
   \tilde{\gamma}_{\tilde{C}}(\sigma(k))}
\right)
A_{\sigma(k), k}    
\end{eqnarray}

\item $k \in \tilde{N} \cap O$:
According to Equations~(\ref{eq:r1_j_O_N_k_N_O})
and~(\ref{eq:r1_i_B_S_k_N_O}) and the appropriate changes neccessary we obtain
\begin{eqnarray}
\lefteqn{
2D_{j,k}-\left(
          \left(\tilde{q}_{\lambda}^{T}\left|\right. \tilde{q}_{x}^{T}\right)
	  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
	  \left(M_{\tilde{B}}^{-1}\right)_{x_{l}}
	\right)
\left(\begin{array}{c}
        A_{k} \\
	\hline
	2D_{\tilde{B},k}
      \end{array}
\right)
=}
\nonumber \\
&&
2D_{j, k}
-\left(\tilde{q}_{\lambda_{\tilde{C}}}^{T}\left|\right.
  \tilde{q}_{x_{\tilde{B}_{O}}}^{T}\right)
\left(\begin{array}{c}
        A_{\tilde{C}, k} \\
	\hline
	2D_{\tilde{B}_{O}, k}
      \end{array}
\right)
\nonumber \\
&&
-\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}A_{\sigma(l),l}
\left(
  -A_{\sigma(l), \tilde{B}_{O}}
    \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{B}_{O}}
  \left(\begin{array}{c}
          A_{\tilde{C},k} \\
	  \hline
	  2D_{\tilde{B}_{O},k}
         \end{array}
  \right)
  +A_{\tilde{\gamma}_{S_{\tilde{B}}}(\sigma(l)), k}
\right)
\nonumber \\
&=&
2D_{j, k}
-\left(
  \left(\tilde{q}_{\lambda_{\tilde{C}}}^{T}\left|\right.
  \tilde{q}_{x_{\tilde{B}_{O}}}^{T}\right)
 -\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
   A_{\sigma(l),l}A_{\sigma(l), \tilde{B}_{O}}
  \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{B}_{O}}
\right)
\left(\begin{array}{c}
        A_{\tilde{C},k} \\
	\hline
	2D_{\tilde{B}_{O},k}
       \end{array}
\right)
\nonumber \\
&&
-\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}A_{\sigma(l),l}
  A_{\tilde{\gamma}_{S_{\tilde{B}}}(\sigma(l)), k}
\end{eqnarray}
\end{enumerate}

\paragraph{$\mathbf{l \in \tilde{B}_{S} \wedge j \in S \cap \tilde{N}}$:}
\begin{enumerate}
\item $k \in \tilde{N} \cap S$:
According to Equations~(\ref{eq:r1_j_S_N_k_N_S})
and~(\ref{eq:r1_i_B_S_k_N_S}) and the appropriate changes neccessary we obtain
\begin{eqnarray}
\lefteqn{
2D_{j,k}-\left(
          \left(\tilde{q}_{\lambda}^{T}\left|\right. \tilde{q}_{x}^{T}\right)
	  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
	  \left(M_{\tilde{B}}^{-1}\right)_{x_{l}}
	\right)
\left(\begin{array}{c}
        A_{k} \\
	\hline
	2D_{\tilde{B},k}
      \end{array}
\right)
=}
\nonumber \\
&&
-\left(\tilde{q}_{\lambda_{\tilde{C}}}\right)_{\tilde{\gamma}_{\tilde{C}}
 (\sigma(k))}A_{\sigma(k),k}
-\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
  \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{S}(l),
  \tilde{\gamma}_{\tilde{C}}(\sigma(k))}A_{\sigma(k), k}
\nonumber \\
&=&
-\left(
  \left(\tilde{q}_{\lambda_{\tilde{C}}}\right)_{\tilde{\gamma}_{\tilde{C}}
   (\sigma(k))}
  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}} 
  \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{\beta}_{S}(l),
  \tilde{\gamma}_{\tilde{C}}(\sigma(k))}
\right)
A_{\sigma(k), k}  
\end{eqnarray}

\item $k \in \tilde{N} \cap O$:
According to Equations~(\ref{eq:r1_j_S_N_k_N_O})
and~(\ref{eq:r1_i_B_S_k_N_O}) and the appropriate changes neccessary we obtain
\begin{eqnarray}
\lefteqn{
2D_{j,k}-\left(
          \left(\tilde{q}_{\lambda}^{T}\left|\right. \tilde{q}_{x}^{T}\right)
	  +\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}
	  \left(M_{\tilde{B}}^{-1}\right)_{x_{l}}
	\right)
\left(\begin{array}{c}
        A_{k} \\
	\hline
	2D_{\tilde{B},k}
      \end{array}
\right)
=}
\nonumber \\
&&
-\left(\tilde{q}_{\lambda_{\tilde{C}}}^{T}\left|\right.
  \tilde{q}_{x_{\tilde{B}_{O}}}^{T}\right)
\left(\begin{array}{c}
        A_{\tilde{C},k} \\
	\hline
	2D_{\tilde{B}_{O},k}
      \end{array}
\right)
\nonumber \\
&&
-\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}A_{\sigma(l),l}
\left(
  -A_{\sigma(l), \tilde{B}_{O}}
  \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{B}_{O}}
  \left(\begin{array}{c}
          A_{\tilde{C},k} \\
	  \hline
	  2D_{\tilde{B}_{O},k}
        \end{array}
  \right)
  +A_{\tilde{\gamma}_{S_{\tilde{B}}}(\sigma(l)), k}
\right)
\nonumber \\
&=&
-\left(
  \left(\tilde{q}_{\lambda_{\tilde{C}}}^{T}\left|\right.
    \tilde{q}_{x_{\tilde{B}_{O}}}^{T}\right)
  -\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}A_{\sigma(l),l}
   A_{\sigma(l), \tilde{B}_{O}}
   \left(\check{M}_{\tilde{B}}^{-1}\right)_{\tilde{B}_{O}}
\right)
\left(\begin{array}{c}
        A_{\tilde{C},k} \\
	\hline
	2D_{\tilde{B}_{O},k}
      \end{array}
\right)
\nonumber \\
&&
 -\frac{\tilde{\nu}}{\tilde{q}_{x_{l}}}A_{\sigma(l),l}
 A_{\tilde{\gamma}_{S_{\tilde{B}}}(\sigma(l)), k}
\end{eqnarray}
\end{enumerate}

\subsubsection{Ratio Test Step 2:
\pmu{Q_{2}^{(+)}}{\hat{B}}}
For ease of reference, we restate the Definition~(\ref{def:p_mu_j_Q_2_+}),
of \pmu{Q_{2}^{(+)}}{\hat{B}}

\begin{equation}
\pmu{Q_{2}^{(+)}}{\hat{B}^{(k)}} :=
  \frac{\varepsilon^{l} -
         \left(M_{\hat{B}^{(k-1)}}^{-1}
           \left(\begin{array}{c}
                    A_{\hat{N}^{(k-1)}}  \\
	            \hline
	            2D_{\hat{B}^{(k-1)}, \hat{N}^{(k-1)}}
	         \end{array}
	   \right)
         \right)_{x_{l}}\epsilon_{\hat{N}^{(k-1)}}}{p_{x_{l}}}
\end{equation}

\section{Ratio Tests for the perturbed problem}
The setup of the auxiliary problem excepted, Ratio Test Step~1 and Ratio Test
Step~2 are the only parts of the algorithm that differ for the unperturbed and
perturbed problem.
In this section we present a pseudocode description of the ratio tests needed
for Ratio Test Step~1 and Ratio Test Step~2. We will only consider the most
general cases for which Ratio Test Step~1 and Ratio Test Step~2 occur,
that is for both ratio test steps we consider the QP-case with
inequalities only. Furthermore we will compute the coefficients of the involved
polynomials $\pmu{Q_{1}}{B}$, $\px{i}{Q_{1}}{B}$ and $\px{i}{Q_{2}}{\hat{B}}$
only when needed. We denote by $\check{t}(\varepsilon, B)[k]$,
$k \in O \cup S$, the coefficient of $\varepsilon^{k}$ in the polynomial
$\check{t}(\varepsilon, B)$ defined by Definition~(\ref{def:t_min_eps}), such
that $\check{t}(\varepsilon, B)[0]=\check{t}(0, B)$. Similarly, we denote by
$\check{\mu}_{j}(\varepsilon, \hat{B})[k]$, $k \in O \cup S$, the coefficient
of $\varepsilon^{k}$ in the polynomial $\check{\mu}_{j}(\varepsilon, \hat{B})$
defined by Definition~(\ref{def:hat_mu_j_min_eps}), such that
$\check{\mu}_{j}(\varepsilon, \hat{B})[0]=\check{\mu}_{j}(0, \hat{B})$.
\marginpar{variable index issue: indices start with $0$,  $0 \in O \cup S$}

\subsection{Ratio Test Step 1}
Since the Ratio Test Step~1 compares according to
Equation~(\ref{eq:mu_j_eps_t})
and Definition~(\ref{def:t_min_eps}) the smallest $t$,
$\check{t}(\varepsilon, B)$, such that some basic variable is leaving, and
$t=-\frac{\mu_{j}(\varepsilon,0)}{\nu}$ such that $\mu_{j}(\varepsilon,t)=0$.
For reasons of efficiency we factored out the most common case, that is, the
computation of $\check{t}(0, B)$ and $\mu_{j}(0, 0)$. 
We distinguish three cases with respect to $\check{t}(0, B)$ and
$\mu_{j}(0, t)$, supposing that $T_{k}$ with
$\emptyset \subset T_{k} \subseteq B$, denotes the set of candidate
leaving variables after consideration of of
coefficients $\check{t}(\varepsilon, B)[j]$, $0 \leq j \leq k$:

\begin{algorithm}
\caption{Perturbed Ratio Test 1, zero}
\label{alg:ratio_test_step_1_0}
\begin{algorithmic}
\Function{ratio\_test\_1\_0\_t\_i}{}
\State $T_{k}^{\prime} \gets \emptyset,
  \quad x_{min} \gets 1, \quad  q_{min} \gets 0$
\ForAll{$i \gets 0,  \left|B_{O}\right| - 1$}
    \If{$q_{B_{O}}[i] > 0$}
        \If{$x_{min}*q_{B_{O}}[i] < x_{B_{O}}[i]*q_{min}$}
            \State $x_{min} \gets x_{B_{O}}[i],
	      \quad q_{min} \gets q_{B_{O}}[i],
	      \quad T_{k}^{\prime} \gets \{B_{O}[i]\}$
        \ElsIf{$x_{min}*q_{B_{O}}[i] = x_{B_{O}}[i]*q_{min}$}
            \State $T_{k}^{\prime} \gets T_{k}^{\prime} \cup \{B_{O}[i]\}$	 
        \EndIf
    \EndIf
\EndFor
\ForAll{$i \gets 0, \left|B_{S}\right| - 1$}
    \If{$q_{B_{S}}[i] > 0$}
        \If{$x_{min}*q_{B_{S}}[i] < x_{B_{S}}[i]*q_{min}$}
            \State $x_{min} \gets x_{B_{S}}[i],
	      \quad q_{min} \gets q_{B_{S}}[i],
	      \quad T_{k}^{\prime} \gets \{B_{S}[i]\}$
        \ElsIf{$x_{min}*q_{B_{S}}[i] = x_{B_{S}}[i]*q_{min}$}
            \State $T_{k}^{\prime} \gets T_{k}^{\prime} \cup \{B_{S}[i]\}$
	\EndIf	
    \EndIf 
\EndFor
\State \textbf{return} $T_{k}^{\prime}$
\EndFunction
%\Function{ratio\_test\_1\_0\_t\_j}{}
%\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{itemize}
\item $-\frac{\mu_{j}(0, 0)}{\nu} < \check{t}(0, B)$:
According to Equation~(\ref{eq:mu_j_eps_t}) and
Definition~(\ref{def:t_min_eps}) we then have
$-\frac{\mu_{j}(\varepsilon, 0)}{\nu} < \check{t}(\varepsilon, B)$ and a local
optimum is found, according to Lemma~2.7 $B \cup \{j\}$ is the new basis.

\item $-\frac{\mu_{j}(0, 0)}{\nu} = \check{t}(0, B)$:
According to Equation~(\ref{eq:mu_j_eps_t}) and
Definition~(\ref{def:t_min_eps})
both $-\frac{\mu_{j}(\varepsilon, 0)}{\nu} < \check{t}(\varepsilon, B)$ and
$-\frac{\mu_{j}(\varepsilon, 0)}{\nu} > \check{t}(\varepsilon, B)$ are
possible.
We continue comparing coefficients of $\mu_{j}(\varepsilon, 0)[k]$ and
$\check{t}(\varepsilon, B)[k]$, $1 \leq k \leq \left|O \cup S \right|$
until the equality no longer holds.  
If $-\frac{\mu_{j}(\varepsilon, 0)}{\nu} < \check{t}(\varepsilon, B)$
a local optimum is found and according to Lemma~2.7 $B \cup \{j\}$ is the new
basis,
if $-\frac{\mu_{j}(\varepsilon, 0)}{\nu} > \check{t}(\varepsilon, B)$
we continue computing coefficients
$\check{t}(\varepsilon, B)[k]$, $1 \leq k \leq \left|O \cup S \right|$, until
$\left|T_{k}\right|=1$. $T_{k}$ then contains the index of the leaving
variable.
 
\item $-\frac{\mu_{j}(0, 0)}{\nu} > \check{t}(0, B)$:
According to Equation~(\ref{eq:mu_j_eps_t}) and
Definition~(\ref{def:t_min_eps}) we then have
$-\frac{\mu_{j}(\varepsilon, 0)}{\nu} > \check{t}(\varepsilon, B)$. If
$\left|T_{k}\right| > 1$ we continue computing coefficients
$\check{t}(\varepsilon, B)[k]$, $1 \leq k \leq \left|O \cup S \right|$, until
$\left|T_{k}\right|=1$. $T_{k}$ then contains the index of the leaving
variable.
\end{itemize}
\begin{algorithm}
\caption{Perturbed Ratio Test 1}
\label{alg:ratio_test_step_1_pert}
\begin{algorithmic}
\Function{ratio\_test\_1}{}
\State $ratio\_test\_1\_\_q$
\Comment{Initializes global $q_{B_{O}}$ and $q_{B_{S}}$}
\State $(T_{k}, c_{min}, q_{min}) \gets RATIO\_TEST\_1\_0\_T\_I$
\State $(c_{j,k}, \nu) \gets RATIO\_TEST\_1\_0\_T\_J$
\If{$c_{j,k}*q_{min} < \nu * c_{min}$}
  \Comment{$-\frac{\mu_{j}(0, 0)}{\nu}<\check{t}(0, B)$}
  \State \textbf{return} $\emptyset$
\ElsIf{$c_{j,k}*q_{min} > \nu * c_{min} \wedge \left|T_{k}\right| =1$}
  \Comment{$-\frac{\mu_{j}(0, 0)}{\nu}>\check{t}(0, B)
    \wedge \left|T_{k}\right|=1$}
  \State \textbf{return} $T_{k}$
\Else
  \State $k \gets 1, \quad leaving \gets c_{j,k}*q_{min} > \nu * c_{min}$
  \Repeat
    \State $T_{k}^{\prime} \gets \emptyset,
      \quad c_{min} \gets 1,
      \quad q_{min} \gets 0$
    \ForAll{$i \in T_{k}$}
      \State $c_{x_{i,k}} \gets e_{x_{i}}^{(Q_{1})}
        (\varepsilon, \hat{B})[k]$
      \If{$i < n$} \Comment{$x_{i}$ is original variable}
        \If{$c_{min}*q_{B_{O}}[\beta_{O}[i]]<c_{x_{i,k}}*q_{min}$}
	  \State $c_{min} \gets c_{x_{i,k}},
            \quad q_{min} \gets q_{B_{O}}[\beta_{O}[i]],
            \quad T_{k}^{\prime} \gets \{i\}$
	\ElsIf{$c_{min}*q_{B_{O}}[\beta_{O}[i]]=c_{x_{i,k}}*q_{min}$}
	  \State $T_{k}^{\prime} \gets T_{k}^{\prime} \cup \{i\}$
	\EndIf
      \Else \Comment{$x_{i}$ is slack variable}
	\If{$c_{min}*q_{B_{S}}[\beta_{S}[i]]<c_{x_{i,k}}*q_{min}$}
	  \State $c_{min} \gets c_{x_{i,k}},
            \quad q_{min} \gets q_{B_{S}}[\beta_{S}[i]],
	    \quad T_{k}^{\prime} \gets \{i\}$
	\ElsIf{$c_{min}*q_{B_{S}}[\beta_{S}[i]]=c_{x_{i,k}}*q_{min}$}
	  \State $T_{k}^{\prime} \gets T_{k}^{\prime} \cup \{i\}$
	\EndIf
      \EndIf
    \EndFor
    \If{$ \neg leaving$}
      \State $c_{j,k} \gets e_{\mu_{j}}^{(Q_{1})}(\varepsilon, 0)[k]$
      \If{$c_{j,k} * q_{min} < \nu *c_{min}$}
        \State \textbf{return} $\emptyset$
      \EndIf
      \State $leaving \gets c_{j,k} * q_{min} > \nu *c_{min}$
    \EndIf 
    \State $k \gets k+1, \quad T_{k} \gets T_{k}^{\prime}$
  \Until{$\left|T_{k}\right|=1 \wedge leaving$}
  \State \textbf{return} $T_{k}$
\EndIf    
\EndFunction
\end{algorithmic}
\end{algorithm}
The function that computes $\check{t}(0, B)$ is outlined in
Algorithm~(\ref{alg:ratio_test_step_1_0}), the keeping of the set of candidate
leaving variables $T_{0}$ is the only part in which it differs from the
unperturbed variant.
The function that computes $\mu_{j}(0,0)$ is omitted here, since it already
occurs in the unperturbed problem.
The function that performs the actual Ratio Test Step~1 by comparing
$-\frac{\mu_{j}(\varepsilon, 0)}{\nu}$ and $\check{t}(\varepsilon,B)$
coefficient by coefficient is outlined in
Algorithm~(\ref{alg:ratio_test_step_1_pert}). It returns the unique index of
the leaving variable if
$-\frac{\mu_{j}(\varepsilon, 0)}{\nu} > \check{t}(\varepsilon,B)$ and the empty
set otherwise. Note, that by the remarks of
Section~(\ref{sec:Ties_ratio_test_step_1}) \px{i}{Q_{1}}{B} is unique and
either $\px{i}{Q_{1}}{B} < \pmu{Q_{1}}{B}$ or
$\px{i}{Q_{1}}{B} > \pmu{Q_{1}}{B}$
holds, such that Algorithm~(\ref{alg:ratio_test_step_1_pert}) terminates.
Note, that there is opportunity for improvement; we could distinguish the cases
$\neg leaving \wedge \left|T_{k}\right|=1$, where the index of the potentially
leaving variable $x_{i}$ is known and no minimum among basic variables has to
be determined in order to compute the next coefficient of \px{i}{Q_{1}}{B}, and
$\neg leaving \wedge \left|T_{k}\right|>1$, where the next coefficient of
\px{i}{Q_{1}}{B} is to be computed as minimum over the index set $T_{k}$.

\subsection{Ratio Test Step 2}
Since the Ratio Test Step~2 determines according to
Equation~(\ref{eq:QP_j_mu_opt_short}) the absolute
$\mu_{j}(\varepsilon)$ for which some
basic variable is leaving, supposing that $T_{k}$ with 
$\emptyset  \subset T_{k} \subseteq \hat{B}$, denotes the set 
of candidate leaving variables after consideration of coefficients
$\check{\mu}_{j}(\varepsilon, \hat{B})[j]$, 
$0 \leq j \leq k$,
we distinguish three cases with respect to
$\check{\mu}_{j}(0, \hat{B})$:
\begin{algorithm}
\caption{Perturbed Ratio Test 2, zero}
\label{alg:ratio_test_step_2_0}
\begin{algorithmic}
\Function{ratio\_test\_2\_0}{}
\State $T_{0} \gets \emptyset,
  \quad x_{min} \gets 1, \quad  p_{min} \gets 0$
\ForAll{$i \gets 0,  \left|B_{O}\right| - 1$}
    \If{$p_{B_{O}}[i] < 0$}
        \If{$x_{min}*p_{B_{O}}[i] < x_{B_{O}}[i]*p_{min}$}
            \State $x_{min} \gets x_{B_{O}}[i],
	      \quad p_{min} \gets p_{B_{O}}[i],
	      \quad T_{0} \gets \{B_{O}[i]\}$
        \ElsIf{$x_{min}*p_{B_{O}}[i] = x_{B_{O}}[i]*p_{min}$}
            \State $T_{0} \gets T_{0} \cup \{B_{O}[i]\}$	 
        \EndIf
    \EndIf 
\EndFor
\ForAll{$i \gets 0, \left|B_{S}\right| - 1$}
    \If{$p_{B_{S}}[i] < 0$}
        \If{$x_{min}*p_{B_{S}}[i] < x_{B_{S}}[i]*p_{min}$}
            \State $x_{min} \gets x_{B_{S}}[i],
	      \quad p_{min} \gets p_{B_{S}}[i],
	      \quad T_{0} \gets \{B_{S}[i]\}$
        \ElsIf{$x_{min}*p_{B_{S}}[i] = x_{B_{S}}[i]*p_{min}$}
            \State $T_{0} \gets T_{0} \cup \{B_{S}[i]\}$
	\EndIf	
    \EndIf 
\EndFor
\State \textbf{return} $(T_{0}, x_{min}, p_{min})$
\EndFunction
\end{algorithmic}
\end{algorithm}
\begin{itemize}
\item $\check{\mu}_{j}(0, \hat{B}) > 0$:
According to Definition~(\ref{def:hat_mu_j_min_eps})
$\check{\mu}_{j}(\varepsilon, \hat{B}) > 0$ then holds, so we found an optimal
solution $x_{\hat{B}}^{*}(\varepsilon, 0)$ to $(UQP(\hat{B}_{\varepsilon}))$
which by Lemma~(\ref{lemma:strict}) is also an optimal solution to
$QP(\hat{B}_{\varepsilon})$.

\item $\check{\mu}_{j}(0, \hat{B}) = 0$:
According to Definition~(\ref{def:hat_mu_j_min_eps}) and
Definition~(\ref{def:p_x_i_Q_2}) both
$\check{\mu}_{j}(\varepsilon, \hat{B}) > 0$ and
$\check{\mu}_{j}(\varepsilon, \hat{B}) < 0$ are possible.
We compute coefficients $\check{\mu}_{j}(\varepsilon, \hat{B})[k]$,
$1 \leq k \leq \left|O \cup S\right|$ until the sign of
$\check{\mu}_{j}(\varepsilon, \hat{B})$ is known. 
If $\check{\mu}_{j}(\varepsilon, \hat{B}) > 0$, we found an optimal solution
$x_{\hat{B}}^{*}(\varepsilon, \hat{B})$ to $UQP(\hat{B}_{\varepsilon})$,
which again by Lemma~(\ref{lemma:strict}) is also an optimal solution to
$QP(\hat{B}_{\varepsilon})$,
if $\check{\mu}_{j}(\varepsilon, \hat{B}) < 0$, we continue computing
coefficients $\check{\mu}_{j}(\varepsilon, \hat{B})[k]$ until
$\left|T_{k}\right|=1$. $T_{k}$ then contains the index of the leaving
variable.

\item $\check{\mu}_{j}(0, \hat{B}) < 0$:
According to Definition~(\ref{def:hat_mu_j_min_eps})
$\check{\mu}_{j}(\varepsilon, \hat{B}) < 0$ then holds, so we compute
coefficients $\check{\mu}_{j}(\varepsilon, \hat{B})[k]$,
$1 \leq k \leq \left|O \cup S\right|$ until $\left|T_{k}\right|=1$.
$T_{k}$ then contains the index of the leaving
variable.
\end{itemize}

\begin{algorithm}
\caption{Perturbed Ratio Test 2}
\label{alg:ratio_test_step_2_pert}
\begin{algorithmic}
\Function{ratio\_test\_2}{}
\State $ratio\_test\_2\_\_p$
\Comment{Initializes global $p_{B_{O}}$ and $p_{B_{S}}$}
\State $(T_{k}, c_{min}, p_{min}) \gets RATIO\_TEST\_2\_0$
\If{$c_{min} < 0$}
    \Comment{$\check{\mu}_{j}(\varepsilon, \hat{B}) > 0$}
    \State \textbf{return} $\emptyset$
\ElsIf{$c_{min} > 0 \wedge \left|T_{k}\right|=1$}
    \State \textbf{return} $T_{k}$
\Else
    \Comment{$\check{\mu}_{j}(\varepsilon, \hat{B}) \leq 0$}   
    \State $k \gets 1$
    \Repeat
        \State $T_{k}^{\prime} \gets \emptyset,
	  \quad c_{min} \gets 1,
	  \quad p_{min} \gets 0$
        \ForAll{$i \in T_{k}$}
            \State $c_{x_{i,k}} \gets e_{x_{i}}^{(Q_{2})}
	      (\varepsilon, \hat{B})[k]$
	    \If{$i < n$} \Comment{$x_{i}$ is original variable}
	        \If{$c_{min}*p_{B_{O}}[\beta_{O}[i]]<c_{x_{i,k}}*p_{min}$}
	            \State $c_{min} \gets c_{x_{i,k}},
		      \quad p_{min} \gets p_{B_{O}}[\beta_{O}[i]],
		      \quad T_{k}^{\prime} \gets \{i\}$
	        \ElsIf{$c_{min}*p_{B_{O}}[\beta_{O}[i]]=c_{x_{i,k}}*p_{min}$}
	            \State $T_{k}^{\prime} \gets T_{k}^{\prime} \cup \{i\}$
	        \EndIf
	    \Else \Comment{$x_{i}$ is slack variable}
	        \If{$c_{min}*p_{B_{S}}[\beta_{S}[i]]<c_{x_{i,k}}*p_{min}$}
	            \State $c_{min} \gets c_{x_{i,k}},
		      \quad p_{min} \gets p_{B_{S}}[\beta_{S}[i]],
		      \quad T_{k}^{\prime} \gets \{i\}$
	        \ElsIf{$c_{min}*p_{B_{S}}[\beta_{S}[i]]=c_{x_{i,k}}*p_{min}$}
	            \State $T_{k}^{\prime} \gets T_{k}^{\prime} \cup \{i\}$
	        \EndIf
	    \EndIf
        \EndFor
        \State $k \gets k+1$
        \State $T_{k} \gets T_{k}^{\prime}$ 
    \Until{$\left|T_{k}\right|=1 \wedge c_{min} > 0 \vee c_{min}<0$}
    \If{$c_{min} < 0$}
        \Comment{$\check{\mu}_{j}(\varepsilon, \hat{B}) > 0$}
        \State \textbf{return} $\emptyset$
    \Else
        \Comment{$\check{\mu}_{j}(\varepsilon, \hat{B}) < 0$}
        \State \textbf{return} $T_{k}$
    \EndIf
\EndIf    
\EndFunction
\end{algorithmic}
\end{algorithm}
The function that computes $\check{\mu}_{j}(0, \hat{B})$ is outlined in
Algorithm~(\ref{alg:ratio_test_step_2_0}), the keeping of the set of
candidate leaving variables $T_{0}$ excepted, it does not differ from the
unperturbed variant. 
The function that computes $\check{\mu}_{j}(\varepsilon, \hat{B})$, based on
the value of $\check{\mu}_{j}(0, \hat{B})$, is outlined
in Algorithm~(\ref{alg:ratio_test_step_2_pert}). It returns the unique index of
the leaving variable if $\check{\mu}_{j}(\varepsilon, \hat{B})<0$ and the empty
set otherwise.
Again, by the remarks of
Section~(\ref{sec:Ties_ratio_test_step_1}) \px{i}{Q_{1}}{\hat{B}} is unique and
either $\px{i}{Q_{2}}{\hat{B}} < 0$ or $\px{i}{Q_{2}}{\hat{B}} > 0$
holds, such that Algorithm~(\ref{alg:ratio_test_step_1_pert}) terminates.
Note, that there is opportunity for improvement here as well;
we could distinguish the cases $\left|T_{k}\right|=1$, where the index of
the potentially leaving variable $x_{i}$ is known and no minimum among basic
variables has to be determined in order to compute the next coefficient of
\px{i}{Q_{2}}{\hat{B}}, and
$\left|T_{k}\right|>1$, where the next coefficient of
\px{i}{Q_{2}}{\hat{B}} is to be computed as minimum over the index set $T_{k}$.

\begin{thebibliography}{99}
\bibitem{Sven} S. Sch\"{o}nherr Quadratic Programming in Geometric Optimization:
Theory, Implementation, and Applications, Dissertation, Diss. ETH No 14738, ETH
Z\"{u}rich, Institute of Theoretical Computer Science, 2002.
\bibitem{Chvatal} Va\v{s}ek Chv\'{a}tal. \textit{Linear Programming}. W. H. Freeman and Company,
New York, Chapter 8, 1983 
\end{thebibliography}
\end{document}
