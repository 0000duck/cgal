\chapter{Approximate Spatial Searching}

\section{Introduction}

The {\bf approximate spatial searching} package implements
exact and approximate distance browsing
by providing implementations of algorithms supporting

\begin{itemize} 

\item
both nearest and furthest neighbour searching

\item
both exact and approximate searching

\item 
(approximate) $k$-nearest and $k$-furthest neighbour searching

\item 
(approximate) incremental nearest and incremental furthest neighbour searching

\item
query items representing points and spatial objects.

\end{itemize}

In these searching problems a set $P$ of data points in $d$-dimensional
space is given.
These points are preprocessed into a $k$-$d$ tree data structure, so that given
any query item $q$ the points of $P$ can be browsed efficiently.
The approximate spatial searching package is designed for data sets that are small enough to store
the search structure in main memory (in contrast to approaches
from databases that assume that the data reside in secondary storage).

\subsection{Incremental Nearest Neighbour Searching and Distance Browsing}

Spatial searching supports browsing through a collection of spatial objects
stored in a spatial data structure on the basis of their distances to an arbitrary spatial
query object. The first approach is one that makes use of a $k$-nearest neighbour
algorithm, where $k$ is know prior to the invocation of the algorithm.
Hence, the number of nearest neighbours has to be
guessed. If the guess is too large redundant computations are performed.
If the number is too small the computation has to be  
reinvoked for a larger number of neighbours, thereby performing redundant computations.
The second approach is incremental in the sense that having obtained
the $k$ nearest neighbours, the $k$ + 1$^{st}$ neighbour can be obtained without
having to calculate the $k$ + 1 nearest neighbour from scratch.
The incremental approach is useful when processing queries where
one but not all of the conditions involves spatial proximity (e.g. the nearest city to Paris with
population greater than a million).

\subsection{Furthest Neighbour Searching}

With relatively minor modifications, nearest neighbour searching algorithms can be
used to find the furthest object from the query object. Furthest neighbour searching is invoked if
a boolean \ccc{Search_nearest} is set to false in the constructor of the searching classes.
If this boolean is set to true, or is not set, nearest neighbour searching is invoked.

\subsection{Range Searching}

Range queries are supported by using incremental nearest neighbour search
using iso-rectangles as query item, and using a $L1$-distance between iso-rectangles and points.
This distance is defined such that all points contained in a query item have distance zero
to the query. Hence, an incremental nearest neighbour search will report first all points
contained in the query item.  

\subsection{Approximate Searching}

The approximate spatial searching package supports both exact and approximate browsing, by
specifying an approximation factor $\epsilon \geq 0$ with the query.

\subsection{The $k$-$d$ tree}

Bentley \cite{b-mbstu-75} introduced the $k$-$d$ tree as a generalization of the binary
search tree in higher dimensions. $k$-$d$ trees hierarchically decompose space into a
relatively small number of rectangles such that no rectangle contains too many input objects.
For our purposes, a {\it rectangle} in real $d$ dimensional space, $\R^d$, is the product of $d$ closed
intervals on the coordinate axes.
$k$-$d$ trees are obtained by partitioning point sets in $\R^d$ using
($d$-1)-dimensional hyperplanes.
Each node in the tree is split into two children by one such separating hyperplane.

Each internal node of the $k$-$d$ tree is associated with a rectangle
and a hyperplane orthogonal to
one of the coordinate axis, which splits the rectangle into two parts.
Therefore, such a hyperplane, defined by a splitting dimension
and a splitting value, is called a separator.
These two parts are then associated
with the two child nodes in the tree. The process of partitioning space continues until the number of data
points in the rectangle falls below some given threshold. The rectangles associated with the leaf nodes
are called {\it buckets}, and they define a subdivision of the space into rectangles.
Data points are only stored in the leaf nodes of the tree, not in the internal nodes.

Friedmann, Bentley and Finkel \cite{fbf-afbml-77} described the standard
search algorithm to find the $k$th nearest neighbour by searching a $k$-$d$ tree recursively.

When encountering a node of the $k$-$d$ tree the algorithm first visits the child that is closest
to the query point. On return, if the rectangle containing  the other child lies within
1/ (1+$\epsilon$) times the distance to the $k$th nearest neighbours so far, then
the other child is visited recursively.
Priority search \cite{am-annqf-93} visits the nodes in increasing order of distance from
the queue with help of a priority queue.
The search stops when the distance of the query point to the nearest nodes
exceeds the distance to the nearest point found with a factor 1/ (1+$\epsilon$).
Priority search supports next neighbour search, standard search does not.

\subsection {Splitting Rules}

The approximate spatial searching package provides the following different splitting rules,
which determine how a separating hyperplane is selected:

\begin{itemize}

\item \ccc{Midpoint_of_rectangle}

This splitting rule cuts a rectangle through its midpoint orthogonal
to the longest side.

\item \ccc{Midpoint_of_max_spread}

This splitting rule cuts a rectangle through $Mind+Maxd/2$ orthogonal
to the dimension with the maximum point spread $[Mind,Maxd]$.

\item \ccc{Sliding_midpoint}

This is a modification of the midpoint of rectangle splitting rule.
It first attempts to perform a midpoint of rectangle split as
described above. If data points lie on both sides of the separating
plane the sliding midpoint rule computes the same separator as
the midpoint of rectangle rule. If the data points lie only on one
side it avoids this by sliding the separator, computed by
the midpoint of rectangle rule, to the nearest datapoint.

\item \ccc{Median_of_rectangle}

The splitting dimension is the dimension of the longest side of the rectangle.
The splitting value is defined by the median of the coordinates of the data points
along this dimension.

\item \ccc{Median_of_max_spread}

The splitting dimension is the dimension of the longest side of the rectangle.
The splitting value is defined by the median of the coordinates of the data points
along this dimension.

\item \ccc{Fair}

This splitting rule is a compromise between the median of rectangle splitting rule
and the midpoint of rectangle splitting rule. This splitting rule maintains an upper
bound on the maximal allowed ratio of the longest and shortest side of
a rectangle (the value of this upper bound is set in the constructor of the
fair splitting rule). Among the splits that satisfy this bound, it selects
the one in which the points have the largest spread.
It then splits the points in the most even manner possible, subject
to maintaining the bound on the ratio of the resulting rectangles.

\item \ccc{Sliding_fair}

This splitting rule is a compromise between the fair splitting rule
and the sliding midpoint rule.
Sliding fair-split is based on the theory that there are
two types of splits that are good: balanced splits that
produce fat rectangles, and unbalanced splits provided
the rectangle with fewer points is fat.

Also, this splitting rule maintains an upper
bound on the maximal allowed ratio of the longest and shortest side of
a rectangle (the value of this upper bound is set in the constructor of the
fair splitting rule). Among the splits that satisfy this bound, it selects
the one one in which the points have the largest spread.
It then considers the most extreme cuts that would be allowed by the
aspect ratio bound. This is done by dividing the longest side of
the rectangle by the aspect ratio bound. If the median cut lies
between these extreme cuts, then we use the median cut. If not,
then consider the extreme cut that is closer to the median.
If all the points lie to one side of this cut, then we slide the cut
until it hits the first point.
This may violate the aspect ratio bound, but will never generate empty cells.

\end{itemize}

Also, a user may provide an implementation of his own
splitting rule.

\section{Software Design}

\subsection{Classes}

The approximate spatial searching package consists of the following classes:

\begin{itemize}

\item
The class \ccc{Kd_tree_rectangle} implements $d$-dimensional iso-rectangles, 
methods to compute bounding boxes
of point sets and methods to split iso-rectangles.

\item
The classes \ccc{Kd_tree} and \ccc{Kd_tree_node} implement the $k$-$d$ tree.

\item
The class \ccc{Kd_tree_traits_point} provides parameters for the construction of the $k$-$d$ tree.

\item
The class \ccc{Plane_separator} implements a separator.

\item 
The class \ccc{Point_container} is a point container providing a method, that given a separator
splits a point set. Also \ccc{Point_container} provides methods that support the implementation
of splitting rules.

\item
The function object classes \ccc{Midpoint_of_rectangle}, \ccc{Midpoint_of_max_spread},
\ccc{Sliding_midpoint}, \ccc{Median_of_rectangle}, \ccc{Median_of_max_spread}, \ccc{Median_of_max_spread},
\ccc{Fair} and \ccc{Sliding_fair} implement the splitting rules.

\item
The class \ccc{Weighted_Minkowski_distance} implements a weighted $L_p$-distance for $d$-dimensional points.

\item
The class \ccc{L1_distance_rectangle_point} implements a $L1$ distance for $d$-dimensional
iso-rectangles and points. 

\item
The class \ccc{General_standard_search} implements the standard search strategy for general distances
like the $L1$ distance for iso-rectangles.

\item
The class \ccc{General_priority_search} implements the priority search strategy for general distances
like the $L1$ distance for iso-rectangles.

\item
The class \ccc{Orthogonal_standard_search} implements the standard search strategy for orthogonal distances
like a weighted $L_p$ distance.

\item
The class \ccc{Orthogonal_priority_search} implements the priority search strategy for general distances
like the $L1$ distance for iso-rectangles.

\end{itemize}

\begin{ccTexOnly}

\begin{figure} [t]
  \begin{center}
  \leavevmode
  \vspace*{6cm}
  \hspace*{-2cm}
  \scalebox{.7}{\includegraphics{Fig1.eps}}
  \end{center}
  \vspace*{-8cm}
  \caption{Overview of use of traits classes.}
  \label{ASPAS:Fig1}
\end{figure}

\end{ccTexOnly}

%for html
\lcHtml{\label{ASPAS:Fig1}}
\begin{ccHtmlOnly}
<P>
<center><img border=0 src="Fig1.gif" alt=" "><br>
Overview of use of traits classes</center>
\end{ccHtmlOnly}

% \subsection{Concepts}

% The approximate spatial searching package supports the following concepts:

% \begin{itemize}

% \item
% QueryItem

% \item
% Separator

% \item
% TreeTraits

% \item
% GeneralDistance

% \item
% OrthogonalDistance

% \end{itemize}

\subsection{Use of traits classes}

Figure \ref{ASPAS:Fig1} shows an overview of the use of the traits classes.

The parameter \ccc{NT} should provide a number type.

The parameter \ccc{Item} should provide an implementation of a $d$-dimensional point, 
for example \ccc{CGAL::Point_d}.

The parameter \ccc{Query_item} should provide an implementation a spatial object
as specified by the concept \ccc{CGAL::QueryItem}
for example \ccc{CGAL::Kd_tree_rectangle}, that implements $d$-dimensional iso rectangles.

The parameter \ccc{Separator} should provide an implementation of a $d-1$-dimensional
subspace as specified by the concept \ccc{CGAL::Separator}.

The parameter \ccc{Traits} should provide an implementation of the concept \ccc{CGAL::TreeTraits}
specifying the parameters and the splitting rule used in the construction of a $k$-$d$ tree.

The parameter \ccc{Distance} should provide an implementation of a distance.
For the implementation of nearest neighbour searching with efficient incremental
distance computation this distance class should meet the requirements of the concept
\ccc{CGAL::OrthogonalDistance}. Otherwise the distance class has only to meet the
requirements of the concept \ccc{CGAL::GeneralDistance}.

\section{Example Programs}

The first example program illustrates searching for the nearest and the farthest neighbour using the
same $k$-$d$ tree.
The way the $k$-$d$ tree is build is defined by the traits variable \ccc{tr(bucket_size, s, 3.0 true)}.
In the example the \ccc{bucket_size} is set to 10.
Hence, each leaf nodes stores at most 10 points.
The strategy for splitting the nodes is defined by $s$.
Some rules use a maximal aspect ratio to define
the maximal allowed ratio between the largest and smallest side of a rectangle.
This aspect ratio is set to 3.0. The boolean value true indicates that
extended internal nodes are used.

The nearest neighbour is searched using orthogonal standard search and
the farthest neighhour is searched using general standard search, because the
incremental distance update technique works only for nearest neighbour searching.

In this example the user provides an implementation of 3-dimensional points and an
implementation of the Euclidean distance.

\ccIncludeExampleCode{ExampleA.C}

The second example program illustrates approximate nearest neighbour searching
using orthogonal standard search using the point class \ccc{CGAL::Point_d}
and the distance class \ccc{CGAL::Weighted_Minkowski_distance}.
 
\ccIncludeExampleCode{ExampleB.C}

The third example program illustrates range querying using general priority search.
A range query is defined by a $d$-dimensional iso-rectangle implemented by
the class \ccc{CGAL::Kd_tree_rectangle}. The appropriate distance is defined by
the class \ccc{CGAL::L1_distance_rectangle_point}.

\ccIncludeExampleCode{ExampleC.C}

The fourth example program illustrates browsing for $4$-dimensional points with
a positive first coordinate using orthogonal priority search
using the point class \ccc{CGAL::Point_d}
and the distance class \ccc{CGAL::Weighted_Minkowski_distance}.
 

\ccIncludeExampleCode{ExampleD.C}


