\chapter{Spatial Searching}

\section{Introduction}

The {\bf spatial searching} package implements
exact and approximate distance browsing
by providing implementations of algorithms supporting

\begin{itemize} 

\item
both nearest and furthest neighbor searching

\item
both exact and approximate searching

\item
(approximate) range searching

\item 
(approximate) $k$-nearest and $k$-furthest neighbor searching

\item 
(approximate) incremental nearest and incremental furthest neighbor searching

\item
query items representing points and spatial objects.

\end{itemize}

In these searching problems a set $P$ of data points in $d$-dimensional
space is given.
The points can be represented by Cartesian coordinates or homogeneous coordinates.
These points are preprocessed into a $k$-$d$ tree data structure, so that given
any query item $q$ the points of $P$ can be browsed efficiently.
The approximate spatial searching package is designed for data sets that are small enough to store
the search structure in main memory (in contrast to approaches
from databases that assume that the data reside in secondary storage).

\subsection{Spatial Searching}

Spatial searching supports browsing through a collection of $d$-dimensional spatial objects
stored in a spatial data structure on the basis of their distances to a
query object. The query object may be a point or an arbitrary spatial object, e.g a 
$d$-dimensional sphere. The objects in the spatial data structure are $d$-dimensional points.
 
Spatial searching is supported in several ways. 
The first approach is $k$-{\bf nearest neighbor searching} that makes use of a $k$-nearest neighbor
algorithm, where $k$ is known prior to the invocation of the algorithm.
Hence, the number of nearest neighbors has to be
guessed. If the guess is too large redundant computations are performed.
If the number is too small the computation has to be  
reinvoked for a larger number of neighbors, thereby performing redundant computations.
The second approach is {\bf incremental nearest neighbor searching} in the sense that having obtained
the $k$ nearest neighbors, the $k$ + 1$^{st}$ neighbor can be obtained without
having to calculate the $k$ + 1 nearest neighbor from scratch.
The incremental approach is useful when processing queries where
one but not all of the conditions involves spatial proximity (e.g. the nearest city to Paris with
population greater than a million).

Spatial searching typically consists of a preprocessing phase and a searching phase. 
In the preprocessing phase one builds a search structure 
and in the searching phase 
one makes the queries. 
In the preprocessing phase the user builds a $k$-$d$ tree data structure storing the spatial data.
In the searching phase the user invokes a searching method to browse the spatial data.

With relatively minor modifications, nearest neighbor searching algorithms can be
used to find the furthest object from the query object. 
Therefore, {\bf furthest neighbor searching} is also supported
by the spatial searching package.

The execution time for exact neighbor searching can be reduced by relaxing
the requirement that the neighbors should be computed exactly.
If the distances of two objects to the query object are approximately the same,
instead of computing the nearest/furthest neighbor exactly, one of these objects may
be returned as the approximate nearest/furthest neighbor. I.e., given some non-negative constant
$\epsilon$ the distance of an object returned as an approximate $k$-nearest neighbor
must not be larger than $(1+\epsilon)r$, where
$r$ denotes the distance to the real $k^{th}$ nearest neighbor.
Similar the distance of an approximate $k$-furthest neighbor must not be smaller than $r/(1+\epsilon)$. 
Obviously, for $\epsilon=0$ we get the exact result, and the larger $\epsilon$ is, the less exact the result.

{\bf Range searching}
is supported for range queries defined by $d$-dimensional objects enclosing a region. 
Approximate range searching is supported using fuzzy $d$-dimensional objects. The fuzziness of the query object 
is specified by a parameter $\epsilon$ denoting
a maximal allowed distance to the boundary of a query object. 
If the distance to the the boundary is at
least $\epsilon$
points inside the object
are always reported and 
points outside the object are never reported. Points within distance $\epsilon$ to the 
boundary may be or may be not reported.  

\subsection{The $k$-$d$ tree}
\label{KDT_section}

Bentley \cite{b-mbstu-75} introduced the $k$-$d$ tree as a generalization of the binary
search tree in higher dimensions. $k$-$d$ trees hierarchically decompose space into a
relatively small number of rectangles such that no rectangle contains too many input objects.
For our purposes, a {\it rectangle} in real $d$ dimensional space, $\R^d$, is the product of $d$ closed
intervals on the coordinate axes.
$k$-$d$ trees are obtained by partitioning point sets in $\R^d$ using
($d$-1)-dimensional hyperplanes.
Each node in the tree is split into two children by one such separating hyperplane.

Each internal node of the $k$-$d$ tree is associated with a rectangle
and a hyperplane orthogonal to
one of the coordinate axis, which splits the rectangle into two parts.
Therefore, such a hyperplane, defined by a splitting dimension
and a splitting value, is called a separator.
These two parts are then associated
with the two child nodes in the tree. The process of partitioning space continues until the number of data
points in the rectangle falls below some given threshold. The rectangles associated with the leaf nodes
are called {\it buckets}, and they define a subdivision of the space into rectangles.
Data points are only stored in the leaf nodes of the tree, not in the internal nodes.

Friedmann, Bentley and Finkel \cite{fbf-afbml-77} described the standard
search algorithm to find the $k$th nearest neighbor by searching a $k$-$d$ tree recursively.

When encountering a node of the tree, the algorithm first visits the child that is closest
to the query point. On return, if the rectangle containing  the other child lies within
1/ (1+$\epsilon$) times the distance to the $k$th nearest neighbors so far, then
the other child is visited recursively.
Priority search \cite{am-annqf-93} visits the nodes in increasing order of distance from
the queue with help of a priority queue.
The search stops when the distance of the query point to the nearest nodes
exceeds the distance to the nearest point found with a factor 1/ (1+$\epsilon$).
Priority search supports next neighbor search, standard search does not.

In order to speed-up the internal distance computations in nearest neighbor searching
in high dimensional space, the approximate searching package supports orthogonal searching. Orthogonal
searching implements the efficient incremental distance computation
technique introduced by Arya and Mount \cite{am-afvq-93}.
Orthogonal searching works only for nearest neighbor queries using query items representing
points. Also the use of a Minkowski distance is required.

To speed up distance computations also transformed
distances are used instead of the distance itself. 
For instance for the Euclidean distance, to avoid the expensive computation
of square roots, squared distances are used instead of the Euclidean distance itself. 

\section{Example Programs}

We give five examples. 
The first example illustrates nearest neighbor searching.
The second is an example of approximate furthest neighbor searching using a $d$-dimensional
iso-rectangle as an query object.
Approximate range
searching is illustrated by the third example.
The fourth example illustrates distance browsing and the last example illustrates 
nearest and furthest neighbour searching using
a user defined point and distance class.

\subsection{Example of Nearest Neighbor Searching}

The first example illustrates nearest neighbor searching. The random data points are preprocessed
in a $k$-$d$ tree. For each of the random query points its nearest neighbor is obtained.
In this example
the Euclidean distance is used by default. To avoid the expensive computation
of square roots, the nearest neighbor searching algorithm computes
squared distances instead of the Euclidean distance itself. 
Finally, if the Euclidean distance is reported the square root is taken.

\ccIncludeExampleCode{Nearest_neighbor_searching.C}

\subsection{Example of General Neighbor Searching}

The second example program illustrates approximate nearest and furthest neighbor searching
using 4-dimensional Cartesian coordinates.
Five approximate nearest and furthest neighbors of
the query rectangle $[0.1,0.2]^4$ are computed.
 
\ccIncludeExampleCode{General_neighbor_searching.C}

\subsection{Example of a Range Query}

The third example program illustrates approximate range querying for
4-dimensional fuzzy iso-rectangles and spheres
using homogeneous coordinates.

\ccIncludeExampleCode{Fuzzy_range_query.C}


\subsection{Example of distance browsing}

The fourth example program illustrates distance browsing for $4$-dimensional points with
a positive first coordinate using orthogonal priority search.

 
\ccIncludeExampleCode{Distance_browsing.C}


\subsection{Example illustrating use of user defined point and distance class}

In this example the user provides an implementation of 3-dimensional points and an
implementation of the Euclidean distance.

\ccIncludeExampleCode{User_defined_point_and_distance.C}

\section{Classes}

A user of the approximate spatial searching package should consult the reference
pages of the following classes

\begin{itemize}

\item
The class \ccc{Kd_tree} implementing the $k$-$d$ tree.

\item
The class \ccc{Kd_tree_traits_point} providing parameters for the construction of the $k$-$d$ tree.

\item
The class \ccc{Weighted_Minkowski_distance} implementing a weighted $L_p$-distance for $d$-dimensional points.

\item
The class \ccc{L1_distance_rectangle_point} implementing a $L1$ distance for $d$-dimensional
iso-rectangles and points. 

\item
The class \ccc{L2_distance_sphere_point} implementing a $L2$ distance for $d$-dimensional
spheres and points. 

\item
The class \ccc{General_standard_search} implementing the standard search strategy for general distances
like the $L1$ distance for iso-rectangles.

\item
The class \ccc{General_priority_search} implementing the priority search strategy for general distances
like the $L1$ distance for iso-rectangles.

\item
The class \ccc{Orthogonal_standard_search} implementing the standard search strategy for orthogonal distances
like a weighted $L_p$ distance. Requires the use of extended nodes in the $k$-$d$ tree and supports
only approximate nearest neighbor searching for point queries.

\item
The class \ccc{Orthogonal_priority_search} implementing the priority search strategy for general distances
like the $L1$ distance for iso-rectangles. Requires the use of extended nodes in the $k$-$d$ tree
and supports
only approximate nearest neighbor searching for point queries.

\item
If a user wants to define a distance class the part of the reference page of the class
\ccc{Kd_tree_rectangle} that is not marked as advanced section.
 
\end{itemize}

\section{Use of traits classes}

\begin{figure}[t]
\begin{ccTexOnly}
\begin{center}
\leavevmode
\vspace*{6cm}
\hspace*{-2cm}
\scalebox{.7}{\includegraphics{Fig1.eps}}
\end{center}
\vspace*{-8cm}
\end{ccTexOnly}
\caption{Overview of use of traits classes.
\label{ASPAS:Fig1}}
\end{figure}

\begin{ccHtmlOnly}

<P>
<center>
<img border=0 src="./Fig1.gif" alt=" "><br> 
Overview of use of traits classes.</center>
\end{ccHtmlOnly}

\begin{ccTexOnly}
Figure \ref{ASPAS:Fig1} shows an overview of the use of the traits classes.
\end{ccTexOnly}

The parameter \ccc{NT} should provide a number type.

The parameter \ccc{Item} should provide an implementation of a $d$-dimensional point, 
for example \ccc{CGAL::Point_d}.

The parameter \ccc{Query_item} should provide an implementation a spatial object
as specified by the concept \ccc{CGAL::QueryItem}
for example \ccc{CGAL::Kd_tree_rectangle}, that implements $d$-dimensional iso rectangles.

The parameter \ccc{Separator} should provide an implementation of a $d-1$-dimensional
subspace as specified by the concept \ccc{CGAL::Separator}.

The parameter \ccc{Traits} should provide an implementation of the concept \ccc{CGAL::TreeTraits}
specifying the parameters and the splitting rule used in the construction of a $k$-$d$ tree.

The parameter \ccc{Distance} should provide an implementation of a distance.
For the implementation of nearest neighbor searching with efficient incremental
distance computation this distance class should meet the requirements of the concept
\ccc{CGAL::OrthogonalDistance}. Otherwise the distance class has only to meet the
requirements of the concept \ccc{CGAL::GeneralDistance}.


\section{Splitting Rules}

Instead of using the default splitting rule \ccc{Sliding_midpoint} described below,
an advanced user may, depending upon the data, select 
using an instance from the enumeration \ccc{Split_rules}
one from the following splitting rules,
which determine how a separating hyperplane is selected:

\begin{itemize}

\item \ccc{Midpoint_of_rectangle}

This splitting rule cuts a rectangle through its midpoint orthogonal
to the longest side.

\item \ccc{Midpoint_of_max_spread}

This splitting rule cuts a rectangle through $(Mind+Maxd)/2$ orthogonal
to the dimension with the maximum point spread $[Mind,Maxd]$.

\item \ccc{Sliding_midpoint}

This is a modification of the midpoint of rectangle splitting rule.
It first attempts to perform a midpoint of rectangle split as
described above. If data points lie on both sides of the separating
plane the sliding midpoint rule computes the same separator as
the midpoint of rectangle rule. If the data points lie only on one
side it avoids this by sliding the separator, computed by
the midpoint of rectangle rule, to the nearest datapoint.

\item \ccc{Median_of_rectangle}

The splitting dimension is the dimension of the longest side of the rectangle.
The splitting value is defined by the median of the coordinates of the data points
along this dimension.

\item \ccc{Median_of_max_spread}

The splitting dimension is the dimension of the longest side of the rectangle.
The splitting value is defined by the median of the coordinates of the data points
along this dimension.

\item \ccc{Fair}

This splitting rule is a compromise between the median of rectangle splitting rule
and the midpoint of rectangle splitting rule. This splitting rule maintains an upper
bound on the maximal allowed ratio of the longest and shortest side of
a rectangle (the value of this upper bound is set in the constructor of the
fair splitting rule). Among the splits that satisfy this bound, it selects
the one in which the points have the largest spread.
It then splits the points in the most even manner possible, subject
to maintaining the bound on the ratio of the resulting rectangles.

\item \ccc{Sliding_fair}

This splitting rule is a compromise between the fair splitting rule
and the sliding midpoint rule.
Sliding fair-split is based on the theory that there are
two types of splits that are good: balanced splits that
produce fat rectangles, and unbalanced splits provided
the rectangle with fewer points is fat.

Also, this splitting rule maintains an upper
bound on the maximal allowed ratio of the longest and shortest side of
a rectangle (the value of this upper bound is set in the constructor of the
fair splitting rule). Among the splits that satisfy this bound, it selects
the one one in which the points have the largest spread.
It then considers the most extreme cuts that would be allowed by the
aspect ratio bound. This is done by dividing the longest side of
the rectangle by the aspect ratio bound. If the median cut lies
between these extreme cuts, then we use the median cut. If not,
then consider the extreme cut that is closer to the median.
If all the points lie to one side of this cut, then we slide the cut
until it hits the first point.
This may violate the aspect ratio bound, but will never generate empty cells.

\end{itemize}

Also, a user may provide an implementation of his own
splitting rule.

\section{Implementation}

The following classes are only of interest for modifying the implementation of the
approximate spatial searching package. Their reference pages are described as advanced sections.

\begin{itemize}

\item
The class \ccc{Kd_tree_rectangle} implements $d$-dimensional iso-rectangles, 
methods to compute bounding boxes
of point sets and methods to split iso-rectangles.

\item
The class \ccc{Kd_tree_node} implements $k$-$d$ tree nodes.

\item
The class \ccc{Plane_separator} implements a separator.

\item 
The class \ccc{Point_container} is a point container providing a method, that given a separator
splits a point set. Also \ccc{Point_container} provides methods that support the implementation
of splitting rules.

\item
The function object classes \ccc{Midpoint_of_rectangle}, \ccc{Midpoint_of_max_spread},
\ccc{Sliding_midpoint}, \ccc{Median_of_rectangle}, \ccc{Median_of_max_spread}, \ccc{Median_of_max_spread},
\ccc{Fair} and \ccc{Sliding_fair} implement the splitting rules.

\end{itemize}
